{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "12.03 toy to mnist colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "igLHoZPbUwXk",
        "outputId": "2e06ae8c-687c-436f-a263-b829c1ac76ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "%pylab inline\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np\n",
        "from random import randint, seed\n",
        "\n",
        "# Flag to enable execution on GPU\n",
        "# device = torch.device('cpu')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "cuda = torch.cuda.is_available()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['randint', 'seed']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpfpprCfvc2r",
        "colab_type": "code",
        "outputId": "301a6bdd-83b7-499e-e3e2-71d44c5784b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emsSbOzJLwCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Loading the MNIST dataset\n",
        "train_set = MNIST('./data/MNIST', download=True, train=True, transform=ToTensor())\n",
        "test_set = MNIST('./data/MNIST', download=True, train=False, transform=ToTensor())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hTHGDGBxUwXu",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "n_train_samples = len(train_set) # number of train samples\n",
        "n_test_samples = len(test_set) # number of test samples\n",
        "\n",
        "np.random.seed(1234)\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "# generate samples\n",
        "seed(1234)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Initialization of the data loader\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZEzcIfE-UwYP",
        "colab": {}
      },
      "source": [
        "from torch.nn.functional import softplus, softmax\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, n_inputs, n_hidden, n_classes, neg_slope=0.02):\n",
        "        super(MLP, self).__init__()\n",
        "        self.n_inputs = n_inputs,\n",
        "        self.n_hidden = n_hidden,\n",
        "        self.n_classes = n_classes\n",
        "        \n",
        "        self.layers = []\n",
        "        self.num_neurons = [n_inputs] + n_hidden + [n_classes]\n",
        "        self.models = {}\n",
        "        for i in range(len(self.num_neurons) - 2):\n",
        "            self.layers.append(nn.Linear(self.num_neurons[i], self.num_neurons[i+1]))\n",
        "            self.layers.append(nn.LeakyReLU(negative_slope=neg_slope))\n",
        "            self.models['Linear{}'.format(i)] = nn.Sequential(*self.layers)\n",
        "            \n",
        "\n",
        "        self.layers.append(nn.Linear(self.num_neurons[i+1], self.num_neurons[i+2]))\n",
        "        self.models['Output'] = nn.Sequential(*self.layers)\n",
        "        self.full_model = self.models['Output']\n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self, x, exitLayer=None): \n",
        "        if exitLayer is not None:\n",
        "            out = self.models[exitLayer](x)\n",
        "        else:\n",
        "            out = self.full_model(x)\n",
        "        return out\n",
        "'''\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, z_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        self.z_dim = z_dim\n",
        "        \n",
        "        # Vanilla MLP\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(10, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, z_dim*2),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0),-1) # Flatten the input\n",
        "        params = self.net(x)\n",
        "        \n",
        "        mu, sigma = params[:,:self.z_dim], params[:,self.z_dim:]\n",
        "        sigma = softplus(sigma) + 1e-7  # Make sigma always positive\n",
        "        \n",
        "        return Independent(Normal(loc=mu, scale=sigma), 1) # Return a factorized Normal distribution\n",
        "'''\n",
        "\n",
        "\n",
        "class VAE(nn.Module):\n",
        "\n",
        "    def __init__(self, x_dim, y_dim, z_dim=6):\n",
        "        super(VAE, self).__init__()\n",
        "        self.K = z_dim\n",
        "\n",
        "        self.encode = nn.Sequential(\n",
        "            nn.Linear(x_dim, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, 2*self.K))\n",
        "\n",
        "        self.decode = nn.Sequential(\n",
        "                nn.Linear(self.K, y_dim))\n",
        "\n",
        "    def forward(self, x, num_sample=1):\n",
        "        if x.dim() > 2 : x = x.view(x.size(0),-1)\n",
        "\n",
        "        statistics = self.encode(x)\n",
        "        mu = statistics[:,:self.K]\n",
        "        std = softplus(statistics[:,self.K:]-5,beta=1)\n",
        "\n",
        "        encoding = self.reparametrize_n(mu, std, num_sample)\n",
        "        logit = self.decode(encoding)\n",
        "\n",
        "        if num_sample == 1 : pass\n",
        "        elif num_sample > 1 : logit = softmax(logit, dim=2).mean(0)\n",
        "\n",
        "        return (mu, std), logit, encoding\n",
        "\n",
        "    def reparametrize_n(self, mu, std, n=1):\n",
        "        # reference :\n",
        "        # http://pytorch.org/docs/0.3.1/_modules/torch/distributions.html#Distribution.sample_n\n",
        "        def expand(v):\n",
        "            if isinstance(v, Number):\n",
        "                return torch.Tensor([v]).expand(n, 1)\n",
        "            else:\n",
        "                return v.expand(n, *v.size())\n",
        "\n",
        "        if n != 1 :\n",
        "            mu = expand(mu)\n",
        "            std = expand(std)\n",
        "\n",
        "        eps = Variable(std.data.new(std.size()).normal_().to(device))\n",
        "\n",
        "        return mu + eps * std\n",
        "\n",
        "    def weight_init(self):\n",
        "        for m in self._modules:\n",
        "            xavier_init(self._modules[m])\n",
        "\n",
        "\n",
        "def xavier_init(ms):\n",
        "    for m in ms :\n",
        "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "            nn.init.xavier_uniform(m.weight,gain=nn.init.calculate_gain('relu'))\n",
        "            m.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tfwUDM2_UwYV",
        "colab": {}
      },
      "source": [
        "def get_named_layers(net):\n",
        "    conv2d_idx = 0\n",
        "    convT2d_idx = 0\n",
        "    linear_idx = 0\n",
        "    batchnorm2d_idx = 0\n",
        "    named_layers = {}\n",
        "    for mod in net.modules():\n",
        "        if isinstance(mod, torch.nn.Conv2d):\n",
        "            layer_name = 'Conv2d{}_{}-{}'.format(\n",
        "                conv2d_idx, mod.in_channels, mod.out_channels\n",
        "            )\n",
        "            named_layers[layer_name] = mod\n",
        "            conv2d_idx += 1\n",
        "        elif isinstance(mod, torch.nn.ConvTranspose2d):\n",
        "            layer_name = 'ConvT2d{}_{}-{}'.format(\n",
        "                conv2d_idx, mod.in_channels, mod.out_channels\n",
        "            )\n",
        "            named_layers[layer_name] = mod\n",
        "            convT2d_idx += 1\n",
        "        elif isinstance(mod, torch.nn.BatchNorm2d):\n",
        "            layer_name = 'BatchNorm2D{}_{}'.format(\n",
        "                batchnorm2d_idx, mod.num_features)\n",
        "            named_layers[layer_name] = mod\n",
        "            batchnorm2d_idx += 1\n",
        "        elif isinstance(mod, torch.nn.Linear):\n",
        "            layer_name = 'Linear{}_{}-{}'.format(\n",
        "                linear_idx, mod.in_features, mod.out_features\n",
        "            )\n",
        "            named_layers[layer_name] = mod\n",
        "            linear_idx += 1\n",
        "    return named_layers\n",
        "\n",
        "def accuracy(predictions, targets, mnist=True):\n",
        "    if mnist:\n",
        "        accuracy = (predictions.argmax(dim=1) == targets).type(torch.FloatTensor).mean().item()\n",
        "    else:\n",
        "        accuracy = (predictions.argmax(dim=1) == targets.argmax(dim=1)).type(torch.FloatTensor).mean().item()\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_mtR59A78PA",
        "colab_type": "code",
        "outputId": "1cf47c8a-aa1c-482a-905e-6302639a5191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Single time define the testing set. Keep it fixed until the end\n",
        "xs = []\n",
        "ys = []\n",
        "\n",
        "for x, y in test_loader:\n",
        "    xs.append(x)\n",
        "    ys.append(y)\n",
        "\n",
        "xs = torch.cat(xs, 0)\n",
        "ys = torch.cat(ys, 0)\n",
        "\n",
        "X_test, y_test = torch.tensor(xs, requires_grad=False).flatten(start_dim=1).to(device), torch.tensor(ys, requires_grad=False).type(torch.LongTensor).to(device)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GeHMyJCMUwYZ",
        "outputId": "e11b6055-6906-420d-eab0-f03772a4430e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "dnn_hidden_units = [1024, 512, 256, 128, 64]\n",
        "dnn_input_units = X_test.shape[-1]\n",
        "dnn_output_units = 10 #y.shape[-1] if y.ndim > 1 else 1\n",
        "\n",
        "# MLP_object = VAE(dnn_input_units, dnn_output_units).to(device)\n",
        "MLP_object = MLP(dnn_input_units, dnn_hidden_units, dnn_output_units)\n",
        "get_named_layers(MLP_object)\n",
        "#MLP_object.parameters()\n",
        "#print(MLP_object.models)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Linear0_784-1024': Linear(in_features=784, out_features=1024, bias=True),\n",
              " 'Linear1_1024-512': Linear(in_features=1024, out_features=512, bias=True),\n",
              " 'Linear2_512-256': Linear(in_features=512, out_features=256, bias=True),\n",
              " 'Linear3_256-128': Linear(in_features=256, out_features=128, bias=True),\n",
              " 'Linear4_128-64': Linear(in_features=128, out_features=64, bias=True),\n",
              " 'Linear5_64-10': Linear(in_features=64, out_features=10, bias=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xr1RbbhZpvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "#Calculate real MI throughout training\n",
        "def calc_mutual_information(hidden):\n",
        "    n_neurons = hidden.shape[-1]\n",
        "  \n",
        "    # discretization \n",
        "    n_bins = 30\n",
        "    bins = np.linspace(-1, 1, n_bins+1)\n",
        "    indices = np.digitize(hidden, bins)\n",
        "    \n",
        "    # initialize pdfs\n",
        "    pdf_x = Counter(); pdf_y = Counter(); pdf_t = Counter(); pdf_xt = Counter(); pdf_yt = Counter()\n",
        "\n",
        "    for i in range(n_train_samples):\n",
        "        pdf_x[x_train_int[i]] += 1/float(n_train_samples)\n",
        "        pdf_y[y_train[i,0]] += 1/float(n_train_samples)      \n",
        "        pdf_xt[(x_train_int[i],)+tuple(indices[i,:])] += 1/float(n_train_samples)\n",
        "        pdf_yt[(y_train[i,0],)+tuple(indices[i,:])] += 1/float(n_train_samples)\n",
        "        pdf_t[tuple(indices[i,:])] += 1/float(n_train_samples)\n",
        "    \n",
        "    # calcuate encoder mutual information I(X;T)\n",
        "    mi_xt = 0\n",
        "    for i in pdf_xt:\n",
        "        # P(x,t), P(x) and P(t)\n",
        "        p_xt = pdf_xt[i]; p_x = pdf_x[i[0]]; p_t = pdf_t[i[1:]]\n",
        "        # I(X;T)\n",
        "        mi_xt += p_xt * np.log(p_xt / p_x / p_t)\n",
        " \n",
        "    # calculate decoder mutual information I(T;Y)\n",
        "    mi_ty = 0\n",
        "    for i in pdf_yt:\n",
        "        # P(t,y), P(t) and P(y)\n",
        "        p_yt = pdf_yt[i]; p_t = pdf_t[i[1:]]; p_y = pdf_y[i[0]]\n",
        "        # I(T;Y)\n",
        "        try:\n",
        "          mi_ty += p_yt * np.log(p_yt / p_t / p_y)\n",
        "        except ZeroDivisionError:\n",
        "          mi_ty += p_yt * np.log(p_yt / (p_t + 1e-5) / (p_y + 1e-5))\n",
        "            \n",
        "    return mi_xt, mi_ty\n",
        "\n",
        "# get mutual information for all hidden layers\n",
        "def get_mutual_information(hidden):\n",
        "    mi_xt_list = []; mi_ty_list = []\n",
        "    # for hidden in hiddens:\n",
        "    if True:\n",
        "        mi_xt, mi_ty = calc_mutual_information(hidden)\n",
        "        mi_xt_list.append(mi_xt)\n",
        "        mi_ty_list.append(mi_ty)\n",
        "    return mi_xt_list, mi_ty_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u_OKUCe-UwYf",
        "outputId": "7825deaa-0725-4e33-9e45-fa5e744e572e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def train_encoder(z_dim = 6, enc_type='MLP', layer='Linear3', weight_decay=0, num_epochs=10, eval_freq=1, beta=1):\n",
        "  \n",
        "    if enc_type == 'MLP':\n",
        "        Net = MLP(dnn_input_units, dnn_hidden_units, dnn_output_units).to(device)\n",
        "    elif enc_type =='VAE':\n",
        "        Net = VAE(dnn_input_units, dnn_output_units, z_dim).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(Net.parameters(), lr=3e-3, weight_decay=weight_decay)#, momentum=0.2)\n",
        "\n",
        "    # X_test, Y_test = torch.tensor(x_test, requires_grad=False).float().to(device), torch.tensor(y_test, requires_grad=False).float().to(device)\n",
        "    accuracy_evaluation = {'train': [], 'test': []}\n",
        "    loss_evaluation = {'train': [], 'test': []}\n",
        "    mi_xt_all = []; mi_ty_all = []; epochs = []\n",
        "    start_time = time.time()\n",
        "    max_accuracy = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for X_train, y_train in train_loader:\n",
        "\n",
        "            X_train, y_train = X_train.flatten(start_dim=1).to(device), y_train.to(device)\n",
        "        \n",
        "            optimizer.zero_grad()\n",
        "            if enc_type =='VAE':\n",
        "                (mu, std), out, z_train = Net(X_train)\n",
        "                class_loss = criterion(out, y_train).div(math.log(2))\n",
        "                info_loss = -0.5 * (1 + 2 * std.log() - mu.pow(2) - std.pow(2)).sum(1).mean().div(math.log(2))\n",
        "                loss = class_loss + beta * info_loss\n",
        "            else:\n",
        "                out = Net(X_train)\n",
        "                loss = criterion(out, y_train)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if epoch % eval_freq == 0 or epoch == num_epochs - 1:\n",
        "\n",
        "                # if enc_type =='MLP':\n",
        "                #     mi_xt, mi_ty = get_mutual_information(Net.models[layer](X_train).cpu().data.numpy())\n",
        "                # else:\n",
        "                #     mi_xt, mi_ty = get_mutual_information(z_train.cpu().data.numpy())\n",
        "                # mi_xt_all.append(mi_xt)\n",
        "                # mi_ty_all.append(mi_ty)\n",
        "\n",
        "                print('\\n'+'#'*30)\n",
        "                print('Training epoch - %d/%d' % (epoch+1, num_epochs))\n",
        "\n",
        "                if enc_type == 'VAE':\n",
        "                    (mu, std), out_test, z_test = Net(X_test)\n",
        "                    test_class_loss = criterion(out, y_train).div(math.log(2))\n",
        "                    test_info_loss = -0.5 * (1 + 2 * std.log() - mu.pow(2) - std.pow(2)).sum(1).mean().div(math.log(2))\n",
        "                    test_loss = test_class_loss + beta * test_info_loss\n",
        "                else:\n",
        "                    out_test = Net(X_test)\n",
        "                    test_loss = criterion(out_test, y_test)\n",
        "                test_accuracy = accuracy(out_test, y_test)\n",
        "                if test_accuracy > max_accuracy:\n",
        "                    max_accuracy = test_accuracy\n",
        "\n",
        "                print('Train: Accuracy - %0.3f, Loss - %0.3f' % (accuracy(out, y_train), loss))\n",
        "                print('Test: Accuracy - %0.3f, Loss - %0.3f' % (test_accuracy, test_loss))\n",
        "                # print('I(X, %s) - %s' % (layer, mi_xt))\n",
        "                # print('I(%s, Y) - %s' % (layer, mi_ty))\n",
        "                print('Elapse time: ', time.time() - start_time)\n",
        "                print('#'*30,'\\n')\n",
        "                if test_accuracy == 1 and test_loss == 0:\n",
        "                    break\n",
        "\n",
        "    return Net, max_accuracy\n",
        "Encoder, performance = train_encoder(enc_type='VAE', beta=)#, weight_decay=0.01)\n",
        "print('Best achieved performance: ', performance)\n",
        "print(Encoder)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 57%|█████▋    | 533/938 [00:21<00:06, 63.50it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "##############################\n",
            "Training epoch - 1/10\n",
            "Train: Accuracy - 0.938, Loss - 0.430\n",
            "Test: Accuracy - 0.962, Loss - 0.438\n",
            "Elapse time:  13.203227996826172\n",
            "############################## \n",
            "\n",
            "\n",
            "##############################\n",
            "Training epoch - 2/10\n",
            "Train: Accuracy - 0.969, Loss - 0.281\n",
            "Test: Accuracy - 0.968, Loss - 0.275\n",
            "Elapse time:  26.172807931900024\n",
            "############################## \n",
            "\n",
            "\n",
            "##############################\n",
            "Training epoch - 3/10\n",
            "Train: Accuracy - 0.938, Loss - 0.455\n",
            "Test: Accuracy - 0.969, Loss - 0.458\n",
            "Elapse time:  39.14405846595764\n",
            "############################## \n",
            "\n",
            "\n",
            "##############################\n",
            "Training epoch - 4/10\n",
            "Train: Accuracy - 1.000, Loss - 0.127\n",
            "Test: Accuracy - 0.973, Loss - 0.135\n",
            "Elapse time:  52.232301235198975\n",
            "############################## \n",
            "\n",
            "\n",
            "##############################\n",
            "Training epoch - 5/10\n",
            "Train: Accuracy - 1.000, Loss - 0.162\n",
            "Test: Accuracy - 0.975, Loss - 0.163\n",
            "Elapse time:  65.23678660392761\n",
            "############################## \n",
            "\n",
            "\n",
            "##############################\n",
            "Training epoch - 6/10\n",
            "Train: Accuracy - 1.000, Loss - 0.175\n",
            "Test: Accuracy - 0.971, Loss - 0.177\n",
            "Elapse time:  78.37709927558899\n",
            "############################## \n",
            "\n",
            "\n",
            "##############################\n",
            "Training epoch - 7/10\n",
            "Train: Accuracy - 1.000, Loss - 0.123\n",
            "Test: Accuracy - 0.972, Loss - 0.119\n",
            "Elapse time:  91.25242805480957\n",
            "############################## \n",
            "\n",
            "\n",
            "##############################\n",
            "Training epoch - 8/10\n",
            "Train: Accuracy - 1.000, Loss - 0.132\n",
            "Test: Accuracy - 0.971, Loss - 0.131\n",
            "Elapse time:  104.2206802368164\n",
            "############################## \n",
            "\n",
            "\n",
            "##############################\n",
            "Training epoch - 9/10\n",
            "Train: Accuracy - 1.000, Loss - 0.114\n",
            "Test: Accuracy - 0.970, Loss - 0.121\n",
            "Elapse time:  117.19670128822327\n",
            "############################## \n",
            "\n",
            "\n",
            "##############################\n",
            "Training epoch - 10/10\n",
            "Train: Accuracy - 0.969, Loss - 0.248\n",
            "Test: Accuracy - 0.973, Loss - 0.250\n",
            "Elapse time:  130.19382214546204\n",
            "############################## \n",
            "\n",
            "Best achieved performance:  0.9746999740600586\n",
            "VAE(\n",
            "  (encode): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=1024, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=1024, out_features=12, bias=True)\n",
            "  )\n",
            "  (decode): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z3qZ1W8XUwYr",
        "colab": {}
      },
      "source": [
        "# Neural approximation of MI starts here\n",
        "# Auxiliary network for mutual information estimation\n",
        "class MIEstimator(nn.Module):\n",
        "    def __init__(self, size1, size2):\n",
        "        super(MIEstimator, self).__init__()\n",
        "        \n",
        "        # Vanilla MLP\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(size1 + size2, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, 1),\n",
        "        )\n",
        "    \n",
        "    # Gradient for JSD mutual information estimation and EB-based estimation\n",
        "    def forward(self, x1, x2):\n",
        "        # breakpoint()\n",
        "        pos = self.net(torch.cat([x1, x2], 1)) #Positive Samples \n",
        "        neg = self.net(torch.cat([torch.roll(x1, 1, 0), x2], 1)) #Predictions for shuffled (negative) samples from p(z1)p(z2)\n",
        "        #breakpoint()\n",
        "        return -softplus(-pos).mean() - softplus(neg).mean(), pos.mean() - neg.exp().mean() + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4rHCT2r8YuyO",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Subset\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "class Scheduler:\n",
        "    def __call__(self, **kwargs):\n",
        "        raise NotImplemented()\n",
        "\n",
        "class LinearScheduler(Scheduler):\n",
        "    def __init__(self, start_value, end_value, n_iterations, start_iteration=0):\n",
        "        self.start_value = start_value\n",
        "        self.end_value = end_value\n",
        "        self.n_iterations = n_iterations\n",
        "        self.start_iteration = start_iteration\n",
        "        self.m = (end_value - start_value) / n_iterations\n",
        "\n",
        "    def __call__(self, iteration):\n",
        "        if iteration > self.start_iteration + self.n_iterations:\n",
        "            return self.end_value\n",
        "        elif iteration <= self.start_iteration:\n",
        "            return self.start_value\n",
        "        else:\n",
        "            return (iteration - self.start_iteration) * self.m + self.start_value\n",
        "\n",
        "class ExponentialScheduler(LinearScheduler):\n",
        "    def __init__(self, start_value, end_value, n_iterations, start_iteration=0, base=10):\n",
        "        self.base = base\n",
        "\n",
        "        super(ExponentialScheduler, self).__init__(start_value=math.log(start_value, base),\n",
        "                                                   end_value=math.log(end_value, base),\n",
        "                                                   n_iterations=n_iterations,\n",
        "                                                   start_iteration=start_iteration)\n",
        "\n",
        "    def __call__(self, iteration):\n",
        "        linear_value = super(ExponentialScheduler, self).__call__(iteration)\n",
        "        return self.base ** linear_value\n",
        "\n",
        "def split(dataset, size, split_type):\n",
        "    if split_type == 'Random':\n",
        "        data_split, _ = torch.utils.data.random_split(dataset, [size, len(dataset) - size])\n",
        "    elif split_type == 'Balanced':\n",
        "        class_ids = {}\n",
        "        for idx, (_, y) in enumerate(dataset):\n",
        "            if y not in class_ids:\n",
        "                class_ids[y] = []\n",
        "            class_ids[y].append(idx)\n",
        "\n",
        "        ids_per_class = size // len(class_ids)\n",
        "\n",
        "        selected_ids = []\n",
        "\n",
        "        for ids in class_ids.values():\n",
        "            selected_ids += list(np.random.choice(ids, min(ids_per_class, len(ids)), replace=False))\n",
        "        data_split = torch.utils.data.Subset(dataset, selected_ids)\n",
        "\n",
        "    return data_split\n",
        "\n",
        "\n",
        "class EmbeddedDataset:\n",
        "    BLOCK_SIZE = 256\n",
        "\n",
        "    def __init__(self, base_dataset, encoder, enc_type, cuda=True):\n",
        "        if cuda:\n",
        "            encoder = encoder.cuda()\n",
        "        self.means, self.target = self._embed(encoder, base_dataset, cuda)\n",
        "\n",
        "    def _embed(self, encoder, dataset, cuda):\n",
        "        encoder.eval()\n",
        "\n",
        "        data_loader = torch.utils.data.DataLoader(\n",
        "            dataset,\n",
        "            batch_size=self.BLOCK_SIZE,\n",
        "            shuffle=False)\n",
        "\n",
        "        ys = []\n",
        "        reps = []\n",
        "        with torch.no_grad():\n",
        "            for x, y in data_loader:\n",
        "                x = x.flatten(start_dim=1)\n",
        "                if cuda:\n",
        "                    x = x.cuda()\n",
        "                    y = y.cuda()\n",
        "                if enc_type == 'VAE':\n",
        "                    (_, _), _, p_z_given_x = encoder(x)\n",
        "                else: \n",
        "                    p_z_given_x = encoder(x)\n",
        "                reps.append(p_z_given_x.detach())\n",
        "                ys.append(y)\n",
        "            ys = torch.cat(ys, 0)\n",
        "\n",
        "        encoder.train()\n",
        "        return reps, ys\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        y = self.target[index]\n",
        "        # x = self.means[index][0]\n",
        "        x = self.means[index // self.BLOCK_SIZE][index % self.BLOCK_SIZE]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.target.size(0)\n",
        "\n",
        "def train_and_evaluate_linear_model(train_set, test_set, solver='saga', multi_class='multinomial', tol=.1, C=2):\n",
        "    model = LogisticRegression(solver=solver, multi_class=multi_class, tol=tol, C=C)\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    x_train, y_train = build_matrix(train_set)\n",
        "    x_test, y_test = build_matrix(test_set)\n",
        "    x_train = scaler.fit_transform(x_train)\n",
        "    x_test = scaler.transform(x_test)\n",
        "\n",
        "    model.fit(x_train, y_train)\n",
        "    test_accuracy = model.score(x_test, y_test)\n",
        "    train_accuracy = model.score(x_train, y_train)\n",
        "\n",
        "    return train_accuracy, test_accuracy\n",
        "\n",
        "\n",
        "def build_matrix(dataset):\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "    xs = []\n",
        "    ys = []\n",
        "\n",
        "    for x, y in data_loader:\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "\n",
        "    xs = torch.cat(xs, 0)\n",
        "    ys = torch.cat(ys, 0)\n",
        "\n",
        "    if xs.is_cuda:\n",
        "        xs = xs.cpu()\n",
        "    if ys.is_cuda:\n",
        "        ys = ys.cpu()\n",
        "\n",
        "    return xs.data.numpy(), ys.data.numpy()\n",
        "\n",
        "def evaluate(encoder, enc_type, train_on, test_on, cuda):\n",
        "    embedded_train = EmbeddedDataset(train_on, encoder, enc_type, cuda=cuda)\n",
        "    embedded_test = EmbeddedDataset(test_on, encoder, enc_type, cuda=cuda)\n",
        "    return train_and_evaluate_linear_model(embedded_train, embedded_test)\n",
        "\n",
        "def onehot_encoding(x, num_classes=10):\n",
        "    x_onehot = torch.FloatTensor(x.shape[0], num_classes)\n",
        "    x_onehot.zero_()\n",
        "    x_onehot.scatter_(1, x.view(x.shape[0], 1), 1)\n",
        "    return x_onehot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91duTE0CUrud",
        "colab_type": "code",
        "outputId": "191be6fc-3c2e-4ee8-ef25-dc1131ae9927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def train_MI(encoder, beta=None, num_epochs=2000, estimate_mi_on_train=True):\n",
        "    \n",
        "    if estimate_mi_on_train:\n",
        "        loader = train_loader\n",
        "    else:\n",
        "        loader = test_loader\n",
        "\n",
        "    if enc_type == 'VAE':\n",
        "       (_, _), _, z_test = encoder(X_test)\n",
        "    else:\n",
        "       z_test = encoder(X_test)\n",
        "    z_test = torch.tensor(z_test, requires_grad=False).to(device)\n",
        "\n",
        "    x_dim, y_dim, z_dim = X_test.shape[-1], dnn_output_units, z_test.shape[-1]\n",
        "    print(x_dim, y_dim, z_dim)\n",
        "    mi_estimator_X = MIEstimator(x_dim, z_dim).to(device)\n",
        "    mi_estimator_Y = MIEstimator(z_dim, y_dim).to(device)\n",
        "\n",
        "    optimizer = optim.Adam([\n",
        "    {'params': mi_estimator_X.parameters(), 'lr':1e-4},\n",
        "    {'params': mi_estimator_Y.parameters(), 'lr':1e-4},\n",
        "    ])\n",
        "    if beta is None:\n",
        "        use_scheduler = True\n",
        "        beta_scheduler = ExponentialScheduler(start_value=1e-9, end_value=1e-1, n_iterations=500, start_iteration=1)\n",
        "    else:\n",
        "        use_scheduler = False\n",
        "\n",
        "    start_time = time.time()\n",
        "    max_MI_x, max_MI_y = 0, 0\n",
        "    mi_mean_est_all = {'X': [], 'Y': []}\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        if use_scheduler:\n",
        "            beta = beta_scheduler(epoch)\n",
        "        mi_over_epoch = {'X': [], 'Y': []}\n",
        "        for X, y in loader:\n",
        "            y = onehot_encoding(y)\n",
        "            X, y = X.flatten(start_dim=1).to(device), y.float().to(device)\n",
        "\n",
        "            if enc_type == 'VAE':\n",
        "                (_, _), _, z = encoder(X)\n",
        "            else:\n",
        "                z = encoder(X)\n",
        "            optimizer.zero_grad()\n",
        "            mi_gradient_X, mi_estimation_X = mi_estimator_X(X, z)\n",
        "            mi_gradient_X = mi_gradient_X.mean()\n",
        "            mi_estimation_X = mi_estimation_X.mean()\n",
        "\n",
        "            mi_gradient_Y, mi_estimation_Y = mi_estimator_Y(z, y)\n",
        "            mi_gradient_Y = mi_gradient_Y.mean()\n",
        "            mi_estimation_Y = mi_estimation_Y.mean()\n",
        "                    \n",
        "            loss_mi = - mi_gradient_Y - beta * mi_gradient_X\n",
        "            loss_mi.backward()\n",
        "            optimizer.step()\n",
        "            mi_over_epoch['X'].append(mi_estimation_X.item())\n",
        "            mi_over_epoch['Y'].append(mi_estimation_Y.item())\n",
        "            if mi_estimation_X.item() > max_MI_x and epoch > 5:#10:\n",
        "                max_MI_x = mi_estimation_X.item()\n",
        "                max_MI_y = mi_estimation_Y.item()\n",
        "        mi_mean_est_all['X'].append(np.mean(mi_over_epoch['X']))\n",
        "        mi_mean_est_all['Y'].append(np.mean(mi_over_epoch['Y']))\n",
        "        eval_freq = 1\n",
        "            \n",
        "        # if epoch >= 50 and np.mean(mi_est_all['X'][-50]) > max_MI_x - 1e-1:\n",
        "        #     break\n",
        "        if epoch % eval_freq == 0 or epoch == num_epochs - 1:\n",
        "            #if mi_estimation_X.item() > max_MI_x and epoch > 5:\n",
        "            #    max_MI_x = mi_estimation_X.item()\n",
        "            #    max_MI_y = mi_estimation_Y.item()\n",
        "            \n",
        "            # if epoch >= 15 and np.mean(mi_est_all['X'][-10]) > max_MI_x - 1e-1:\n",
        "            #     break\n",
        "\n",
        "            print('#'*30)\n",
        "            print('Step - ', epoch)\n",
        "            print('Beta - ', beta)\n",
        "                \n",
        "            # print('Mean MI X', np.mean(mi_mean_est_all['X']))\n",
        "            # print('Mean MI Y', np.mean(mi_mean_est_all['Y']))\n",
        "            if epoch >= 1:\n",
        "\n",
        "              delta_x = np.abs(mi_mean_est_all['X'][-2] - mi_mean_est_all['X'][-1])\n",
        "              print('Delta X: ', delta_x)\n",
        "              \n",
        "              delta_y = np.abs(mi_mean_est_all['Y'][-2] - mi_mean_est_all['Y'][-1])\n",
        "              print('Delta Y: ', delta_y)\n",
        "              print('\\nMean MI X for last 10', mi_mean_est_all['X'][-10:])\n",
        "              print('Mean MI Y for last 10', mi_mean_est_all['Y'][-10:])\n",
        "              mi_df = pd.DataFrame.from_dict(mi_mean_est_all)\n",
        "              mi_df.to_csv('mi_mlp.csv', sep=' ')\n",
        "            # print('I_est(X, %s) - %s' % (layer, mi_estimation_X.item()))\n",
        "            #print('Grad I_est(X, T)', mi_gradient_X)\n",
        "            # print('I_est(%s, Y) - %s' % (layer, mi_estimation_Y.item()))\n",
        "            # print('Max I_est(X, %s) - %s' % (layer, max_MI_x))\n",
        "            #print('Grad I_est(X, T)', mi_gradient_X)\n",
        "            # print('Max I_est(%s, Y) - %s' % (layer, max_MI_y))\n",
        "            #print('Grad I_est(T, Y)', mi_gradient_Y)\n",
        "            print('Elapsed time training MI for %s: %s' % (layer, time.time() - start_time))\n",
        "            print('#'*30,'\\n')\n",
        "\n",
        "            \n",
        "    return max_MI_x, max_MI_y\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Initialization of the data loader\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "\n",
        "num_classes = 10\n",
        "labels_per_class = [2**i for i in range(0, int(np.log2(n_train_samples/num_classes)))]\n",
        "num_labels_range = [] #num_classes * np.array(labels_per_class)\n",
        "# layers = ['Linear2', 'Linear3', 'Linear4']\n",
        "layers = ['Linear4']\n",
        "\n",
        "acc = {layer:{i:[] for i in num_labels_range} for layer in layers}\n",
        "# acc = {i:[] for i in num_labels_range}\n",
        "print(num_labels_range)\n",
        "seeds = [9]#, 42, 103, 48, 79]\n",
        "# enc_type = 'VAE'\n",
        "enc_type = 'MLP'\n",
        "mi_layers = {} #probably make for different seeds as well\n",
        "start_time = time.time()\n",
        "\n",
        "for i in range(len(seeds)):\n",
        "\n",
        "    \n",
        "    print('\\nRunning with seed %d out of %d' % (i+1, len(seeds)))\n",
        "    torch.manual_seed(seeds[i])\n",
        "    np.random.seed(seeds[i])\n",
        "    seed(seeds[i])\n",
        "    \n",
        "    \n",
        "    for layer in layers:\n",
        "        #'''\n",
        "        if seeds[i] == 9:\n",
        "            if enc_type == 'MLP':\n",
        "                MI_X, MI_Y = train_MI(Encoder.models[layer], beta=1)\n",
        "            else:\n",
        "                MI_X, MI_Y = train_MI(Encoder, num_epochs=2000)\n",
        "            mi_layers[layer] = (MI_X, MI_Y)\n",
        "            print('MI values for %s - %s, %s' % (layer, MI_X, MI_Y))\n",
        "        #'''\n",
        "        # train_set = torch.utils.data.TensorDataset(torch.Tensor(x_train).to(device), torch.Tensor(y_train).to(device)) \n",
        "        # test_set = torch.utils.data.TensorDataset(torch.Tensor(x_test).to(device), torch.Tensor(y_test).to(device))\n",
        "    \n",
        "        for num_labels in num_labels_range:\n",
        "            print('\\n\\nEvaluating for %s (labels per class - %s)' % (layer, num_labels))\n",
        "            #acc[layer].append(train_MI(num_labels, Encoder, num_epochs=2000))\n",
        "            print('Num labels:', num_labels)\n",
        "            train_subset = split(train_set, num_labels, 'Balanced') \n",
        "            print(len(train_subset))\n",
        "            # test_subset = split(train_set, n_test_samples, 'Random') \n",
        "            if enc_type == 'MLP':\n",
        "                train_accuracy, test_accuracy = evaluate(encoder=Encoder.models[layer], enc_type=enc_type, train_on=train_subset, test_on=test_set, cuda=torch.cuda.is_available())\n",
        "            else:\n",
        "                train_accuracy, test_accuracy = evaluate(encoder=Encoder, enc_type=enc_type, train_on=train_subset, test_on=test_set, cuda=torch.cuda.is_available())\n",
        "            #train_accuracy, test_accuracy = train_and_evaluate_linear_model(train_subset, test_set, C=2)\n",
        "            print('Train Accuracy: %f'% train_accuracy)\n",
        "            print('Test Accuracy: %f'% test_accuracy)\n",
        "            if enc_type == 'MLP':\n",
        "                acc[layer][num_labels].append(test_accuracy)\n",
        "            else:\n",
        "                acc[num_labels].append(test_accuracy)\n",
        "\n",
        "    print('Elapsed time - ', time.time() - start_time)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "\n",
            "Running with seed 1 out of 1\n",
            "784 10 64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "##############################\n",
            "Step -  0\n",
            "Beta -  1\n",
            "Elapsed time training MI for Linear4: 16.093988180160522\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  1\n",
            "Beta -  1\n",
            "Delta X:  0.5369921798136696\n",
            "Delta Y:  0.011261859428145504\n",
            "\n",
            "Mean MI X for last 10 [1.2368499202006407, 1.7738421000143103]\n",
            "Mean MI Y for last 10 [1.0105211316649594, 0.9992592722368139]\n",
            "Elapsed time training MI for Linear4: 32.37566423416138\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  2\n",
            "Beta -  1\n",
            "Delta X:  0.08346374012005597\n",
            "Delta Y:  21.11820037075197\n",
            "\n",
            "Mean MI X for last 10 [1.2368499202006407, 1.7738421000143103, 1.6903783598942543]\n",
            "Mean MI Y for last 10 [1.0105211316649594, 0.9992592722368139, -20.118941098515158]\n",
            "Elapsed time training MI for Linear4: 48.39339470863342\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  3\n",
            "Beta -  1\n",
            "Delta X:  0.6740705266690203\n",
            "Delta Y:  20.351069534765376\n",
            "\n",
            "Mean MI X for last 10 [1.2368499202006407, 1.7738421000143103, 1.6903783598942543, 2.3644488865632747]\n",
            "Mean MI Y for last 10 [1.0105211316649594, 0.9992592722368139, -20.118941098515158, 0.23212843625021895]\n",
            "Elapsed time training MI for Linear4: 64.58113741874695\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  4\n",
            "Beta -  1\n",
            "Delta X:  0.41649461631327545\n",
            "Delta Y:  0.5914376310702326\n",
            "\n",
            "Mean MI X for last 10 [1.2368499202006407, 1.7738421000143103, 1.6903783598942543, 2.3644488865632747, 1.9479542702499992]\n",
            "Mean MI Y for last 10 [1.0105211316649594, 0.9992592722368139, -20.118941098515158, 0.23212843625021895, 0.8235660673204516]\n",
            "Elapsed time training MI for Linear4: 80.86340546607971\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  5\n",
            "Beta -  1\n",
            "Delta X:  1.9802619344644201\n",
            "Delta Y:  0.13022065213494216\n",
            "\n",
            "Mean MI X for last 10 [1.2368499202006407, 1.7738421000143103, 1.6903783598942543, 2.3644488865632747, 1.9479542702499992, -0.032307664214420925]\n",
            "Mean MI Y for last 10 [1.0105211316649594, 0.9992592722368139, -20.118941098515158, 0.23212843625021895, 0.8235660673204516, 0.6933454151855094]\n",
            "Elapsed time training MI for Linear4: 96.81885099411011\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  6\n",
            "Beta -  1\n",
            "Delta X:  2.890819708294452\n",
            "Delta Y:  0.6170930618416273\n",
            "\n",
            "Mean MI X for last 10 [1.2368499202006407, 1.7738421000143103, 1.6903783598942543, 2.3644488865632747, 1.9479542702499992, -0.032307664214420925, 2.858512044080031]\n",
            "Mean MI Y for last 10 [1.0105211316649594, 0.9992592722368139, -20.118941098515158, 0.23212843625021895, 0.8235660673204516, 0.6933454151855094, 1.3104384770271367]\n",
            "Elapsed time training MI for Linear4: 113.08876729011536\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  7\n",
            "Beta -  1\n",
            "Delta X:  0.02213876117775415\n",
            "Delta Y:  0.3339849885847015\n",
            "\n",
            "Mean MI X for last 10 [1.2368499202006407, 1.7738421000143103, 1.6903783598942543, 2.3644488865632747, 1.9479542702499992, -0.032307664214420925, 2.858512044080031, 2.880650805257785]\n",
            "Mean MI Y for last 10 [1.0105211316649594, 0.9992592722368139, -20.118941098515158, 0.23212843625021895, 0.8235660673204516, 0.6933454151855094, 1.3104384770271367, 0.9764534884424352]\n",
            "Elapsed time training MI for Linear4: 128.9434883594513\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  8\n",
            "Beta -  1\n",
            "Delta X:  0.03726899827212904\n",
            "Delta Y:  0.30292176679253324\n",
            "\n",
            "Mean MI X for last 10 [1.2368499202006407, 1.7738421000143103, 1.6903783598942543, 2.3644488865632747, 1.9479542702499992, -0.032307664214420925, 2.858512044080031, 2.880650805257785, 2.917919803529914]\n",
            "Mean MI Y for last 10 [1.0105211316649594, 0.9992592722368139, -20.118941098515158, 0.23212843625021895, 0.8235660673204516, 0.6933454151855094, 1.3104384770271367, 0.9764534884424352, 0.6735317216499019]\n",
            "Elapsed time training MI for Linear4: 145.1232898235321\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  9\n",
            "Beta -  1\n",
            "Delta X:  4.010029557417196\n",
            "Delta Y:  0.510161185823778\n",
            "\n",
            "Mean MI X for last 10 [1.2368499202006407, 1.7738421000143103, 1.6903783598942543, 2.3644488865632747, 1.9479542702499992, -0.032307664214420925, 2.858512044080031, 2.880650805257785, 2.917919803529914, -1.0921097538872822]\n",
            "Mean MI Y for last 10 [1.0105211316649594, 0.9992592722368139, -20.118941098515158, 0.23212843625021895, 0.8235660673204516, 0.6933454151855094, 1.3104384770271367, 0.9764534884424352, 0.6735317216499019, 1.18369290747368]\n",
            "Elapsed time training MI for Linear4: 161.13323283195496\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  10\n",
            "Beta -  1\n",
            "Delta X:  4.27695529801505\n",
            "Delta Y:  0.25706920669531264\n",
            "\n",
            "Mean MI X for last 10 [1.7738421000143103, 1.6903783598942543, 2.3644488865632747, 1.9479542702499992, -0.032307664214420925, 2.858512044080031, 2.880650805257785, 2.917919803529914, -1.0921097538872822, 3.1848455441277674]\n",
            "Mean MI Y for last 10 [0.9992592722368139, -20.118941098515158, 0.23212843625021895, 0.8235660673204516, 0.6933454151855094, 1.3104384770271367, 0.9764534884424352, 0.6735317216499019, 1.18369290747368, 1.4407621141689926]\n",
            "Elapsed time training MI for Linear4: 177.14090704917908\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  11\n",
            "Beta -  1\n",
            "Delta X:  0.220855334420194\n",
            "Delta Y:  0.24609275883448922\n",
            "\n",
            "Mean MI X for last 10 [1.6903783598942543, 2.3644488865632747, 1.9479542702499992, -0.032307664214420925, 2.858512044080031, 2.880650805257785, 2.917919803529914, -1.0921097538872822, 3.1848455441277674, 2.9639902097075734]\n",
            "Mean MI Y for last 10 [-20.118941098515158, 0.23212843625021895, 0.8235660673204516, 0.6933454151855094, 1.3104384770271367, 0.9764534884424352, 0.6735317216499019, 1.18369290747368, 1.4407621141689926, 1.6868548730034818]\n",
            "Elapsed time training MI for Linear4: 193.1677553653717\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  12\n",
            "Beta -  1\n",
            "Delta X:  0.44397555714222925\n",
            "Delta Y:  0.031915993705741386\n",
            "\n",
            "Mean MI X for last 10 [2.3644488865632747, 1.9479542702499992, -0.032307664214420925, 2.858512044080031, 2.880650805257785, 2.917919803529914, -1.0921097538872822, 3.1848455441277674, 2.9639902097075734, 3.4079657668498027]\n",
            "Mean MI Y for last 10 [0.23212843625021895, 0.8235660673204516, 0.6933454151855094, 1.3104384770271367, 0.9764534884424352, 0.6735317216499019, 1.18369290747368, 1.4407621141689926, 1.6868548730034818, 1.7187708667092232]\n",
            "Elapsed time training MI for Linear4: 209.2482635974884\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  13\n",
            "Beta -  1\n",
            "Delta X:  0.06951294118153228\n",
            "Delta Y:  0.01580506766528722\n",
            "\n",
            "Mean MI X for last 10 [1.9479542702499992, -0.032307664214420925, 2.858512044080031, 2.880650805257785, 2.917919803529914, -1.0921097538872822, 3.1848455441277674, 2.9639902097075734, 3.4079657668498027, 3.477478708031335]\n",
            "Mean MI Y for last 10 [0.8235660673204516, 0.6933454151855094, 1.3104384770271367, 0.9764534884424352, 0.6735317216499019, 1.18369290747368, 1.4407621141689926, 1.6868548730034818, 1.7187708667092232, 1.7345759343745104]\n",
            "Elapsed time training MI for Linear4: 225.2241246700287\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  14\n",
            "Beta -  1\n",
            "Delta X:  0.031011690463084385\n",
            "Delta Y:  0.17785353841049578\n",
            "\n",
            "Mean MI X for last 10 [-0.032307664214420925, 2.858512044080031, 2.880650805257785, 2.917919803529914, -1.0921097538872822, 3.1848455441277674, 2.9639902097075734, 3.4079657668498027, 3.477478708031335, 3.5084903984944193]\n",
            "Mean MI Y for last 10 [0.6933454151855094, 1.3104384770271367, 0.9764534884424352, 0.6735317216499019, 1.18369290747368, 1.4407621141689926, 1.6868548730034818, 1.7187708667092232, 1.7345759343745104, 1.9124294727850062]\n",
            "Elapsed time training MI for Linear4: 241.10722088813782\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  15\n",
            "Beta -  1\n",
            "Delta X:  0.10246270729788876\n",
            "Delta Y:  0.10811084585149144\n",
            "\n",
            "Mean MI X for last 10 [2.858512044080031, 2.880650805257785, 2.917919803529914, -1.0921097538872822, 3.1848455441277674, 2.9639902097075734, 3.4079657668498027, 3.477478708031335, 3.5084903984944193, 3.610953105792308]\n",
            "Mean MI Y for last 10 [1.3104384770271367, 0.9764534884424352, 0.6735317216499019, 1.18369290747368, 1.4407621141689926, 1.6868548730034818, 1.7187708667092232, 1.7345759343745104, 1.9124294727850062, 2.0205403186364976]\n",
            "Elapsed time training MI for Linear4: 256.9360771179199\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  16\n",
            "Beta -  1\n",
            "Delta X:  11.9477144395873\n",
            "Delta Y:  0.1948773212778543\n",
            "\n",
            "Mean MI X for last 10 [2.880650805257785, 2.917919803529914, -1.0921097538872822, 3.1848455441277674, 2.9639902097075734, 3.4079657668498027, 3.477478708031335, 3.5084903984944193, 3.610953105792308, -8.33676133379499]\n",
            "Mean MI Y for last 10 [0.9764534884424352, 0.6735317216499019, 1.18369290747368, 1.4407621141689926, 1.6868548730034818, 1.7187708667092232, 1.7345759343745104, 1.9124294727850062, 2.0205403186364976, 1.8256629973586433]\n",
            "Elapsed time training MI for Linear4: 272.8285131454468\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  17\n",
            "Beta -  1\n",
            "Delta X:  11.682813402432114\n",
            "Delta Y:  0.24894903806735225\n",
            "\n",
            "Mean MI X for last 10 [2.917919803529914, -1.0921097538872822, 3.1848455441277674, 2.9639902097075734, 3.4079657668498027, 3.477478708031335, 3.5084903984944193, 3.610953105792308, -8.33676133379499, 3.346052068637124]\n",
            "Mean MI Y for last 10 [0.6735317216499019, 1.18369290747368, 1.4407621141689926, 1.6868548730034818, 1.7187708667092232, 1.7345759343745104, 1.9124294727850062, 2.0205403186364976, 1.8256629973586433, 2.0746120354259956]\n",
            "Elapsed time training MI for Linear4: 288.74772572517395\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  18\n",
            "Beta -  1\n",
            "Delta X:  0.4601481949596775\n",
            "Delta Y:  0.056301143759094785\n",
            "\n",
            "Mean MI X for last 10 [-1.0921097538872822, 3.1848455441277674, 2.9639902097075734, 3.4079657668498027, 3.477478708031335, 3.5084903984944193, 3.610953105792308, -8.33676133379499, 3.346052068637124, 3.8062002635968013]\n",
            "Mean MI Y for last 10 [1.18369290747368, 1.4407621141689926, 1.6868548730034818, 1.7187708667092232, 1.7345759343745104, 1.9124294727850062, 2.0205403186364976, 1.8256629973586433, 2.0746120354259956, 2.1309131791850904]\n",
            "Elapsed time training MI for Linear4: 304.4880220890045\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  19\n",
            "Beta -  1\n",
            "Delta X:  0.09239833898889982\n",
            "Delta Y:  0.01595201815115077\n",
            "\n",
            "Mean MI X for last 10 [3.1848455441277674, 2.9639902097075734, 3.4079657668498027, 3.477478708031335, 3.5084903984944193, 3.610953105792308, -8.33676133379499, 3.346052068637124, 3.8062002635968013, 3.898598602585701]\n",
            "Mean MI Y for last 10 [1.4407621141689926, 1.6868548730034818, 1.7187708667092232, 1.7345759343745104, 1.9124294727850062, 2.0205403186364976, 1.8256629973586433, 2.0746120354259956, 2.1309131791850904, 2.1149611610339396]\n",
            "Elapsed time training MI for Linear4: 320.3744249343872\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  20\n",
            "Beta -  1\n",
            "Delta X:  0.2716262800607092\n",
            "Delta Y:  0.022362753399399526\n",
            "\n",
            "Mean MI X for last 10 [2.9639902097075734, 3.4079657668498027, 3.477478708031335, 3.5084903984944193, 3.610953105792308, -8.33676133379499, 3.346052068637124, 3.8062002635968013, 3.898598602585701, 3.626972322524992]\n",
            "Mean MI Y for last 10 [1.6868548730034818, 1.7187708667092232, 1.7345759343745104, 1.9124294727850062, 2.0205403186364976, 1.8256629973586433, 2.0746120354259956, 2.1309131791850904, 2.1149611610339396, 2.137323914433339]\n",
            "Elapsed time training MI for Linear4: 336.2834131717682\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  21\n",
            "Beta -  1\n",
            "Delta X:  0.13086168140744858\n",
            "Delta Y:  0.017082167459703257\n",
            "\n",
            "Mean MI X for last 10 [3.4079657668498027, 3.477478708031335, 3.5084903984944193, 3.610953105792308, -8.33676133379499, 3.346052068637124, 3.8062002635968013, 3.898598602585701, 3.626972322524992, 3.4961106411175433]\n",
            "Mean MI Y for last 10 [1.7187708667092232, 1.7345759343745104, 1.9124294727850062, 2.0205403186364976, 1.8256629973586433, 2.0746120354259956, 2.1309131791850904, 2.1149611610339396, 2.137323914433339, 2.1544060818930424]\n",
            "Elapsed time training MI for Linear4: 352.25248980522156\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  22\n",
            "Beta -  1\n",
            "Delta X:  0.4639912060837248\n",
            "Delta Y:  0.022296048176568384\n",
            "\n",
            "Mean MI X for last 10 [3.477478708031335, 3.5084903984944193, 3.610953105792308, -8.33676133379499, 3.346052068637124, 3.8062002635968013, 3.898598602585701, 3.626972322524992, 3.4961106411175433, 3.960101847201268]\n",
            "Mean MI Y for last 10 [1.7345759343745104, 1.9124294727850062, 2.0205403186364976, 1.8256629973586433, 2.0746120354259956, 2.1309131791850904, 2.1149611610339396, 2.137323914433339, 2.1544060818930424, 2.1767021300696108]\n",
            "Elapsed time training MI for Linear4: 368.1427230834961\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  23\n",
            "Beta -  1\n",
            "Delta X:  0.783497954482463\n",
            "Delta Y:  0.0019692852298840435\n",
            "\n",
            "Mean MI X for last 10 [3.5084903984944193, 3.610953105792308, -8.33676133379499, 3.346052068637124, 3.8062002635968013, 3.898598602585701, 3.626972322524992, 3.4961106411175433, 3.960101847201268, 3.176603892718805]\n",
            "Mean MI Y for last 10 [1.9124294727850062, 2.0205403186364976, 1.8256629973586433, 2.0746120354259956, 2.1309131791850904, 2.1149611610339396, 2.137323914433339, 2.1544060818930424, 2.1767021300696108, 2.178671415299495]\n",
            "Elapsed time training MI for Linear4: 383.99300146102905\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  24\n",
            "Beta -  1\n",
            "Delta X:  0.589924765548218\n",
            "Delta Y:  0.0013910567582544608\n",
            "\n",
            "Mean MI X for last 10 [3.610953105792308, -8.33676133379499, 3.346052068637124, 3.8062002635968013, 3.898598602585701, 3.626972322524992, 3.4961106411175433, 3.960101847201268, 3.176603892718805, 3.766528658267023]\n",
            "Mean MI Y for last 10 [2.0205403186364976, 1.8256629973586433, 2.0746120354259956, 2.1309131791850904, 2.1149611610339396, 2.137323914433339, 2.1544060818930424, 2.1767021300696108, 2.178671415299495, 2.1800624720577493]\n",
            "Elapsed time training MI for Linear4: 399.73383045196533\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  25\n",
            "Beta -  1\n",
            "Delta X:  34.42625198943782\n",
            "Delta Y:  0.056332542443834566\n",
            "\n",
            "Mean MI X for last 10 [-8.33676133379499, 3.346052068637124, 3.8062002635968013, 3.898598602585701, 3.626972322524992, 3.4961106411175433, 3.960101847201268, 3.176603892718805, 3.766528658267023, -30.659723331170802]\n",
            "Mean MI Y for last 10 [1.8256629973586433, 2.0746120354259956, 2.1309131791850904, 2.1149611610339396, 2.137323914433339, 2.1544060818930424, 2.1767021300696108, 2.178671415299495, 2.1800624720577493, 2.1237299296139147]\n",
            "Elapsed time training MI for Linear4: 415.6258690357208\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  26\n",
            "Beta -  1\n",
            "Delta X:  34.382944066387246\n",
            "Delta Y:  0.05438862985639403\n",
            "\n",
            "Mean MI X for last 10 [3.346052068637124, 3.8062002635968013, 3.898598602585701, 3.626972322524992, 3.4961106411175433, 3.960101847201268, 3.176603892718805, 3.766528658267023, -30.659723331170802, 3.723220735216446]\n",
            "Mean MI Y for last 10 [2.0746120354259956, 2.1309131791850904, 2.1149611610339396, 2.137323914433339, 2.1544060818930424, 2.1767021300696108, 2.178671415299495, 2.1800624720577493, 2.1237299296139147, 2.1781185594703087]\n",
            "Elapsed time training MI for Linear4: 431.4742205142975\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  27\n",
            "Beta -  1\n",
            "Delta X:  0.44059756874783984\n",
            "Delta Y:  0.013023607131006365\n",
            "\n",
            "Mean MI X for last 10 [3.8062002635968013, 3.898598602585701, 3.626972322524992, 3.4961106411175433, 3.960101847201268, 3.176603892718805, 3.766528658267023, -30.659723331170802, 3.723220735216446, 4.163818303964286]\n",
            "Mean MI Y for last 10 [2.1309131791850904, 2.1149611610339396, 2.137323914433339, 2.1544060818930424, 2.1767021300696108, 2.178671415299495, 2.1800624720577493, 2.1237299296139147, 2.1781185594703087, 2.191142166601315]\n",
            "Elapsed time training MI for Linear4: 447.5213871002197\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  28\n",
            "Beta -  1\n",
            "Delta X:  0.879929037744811\n",
            "Delta Y:  0.003235904519745869\n",
            "\n",
            "Mean MI X for last 10 [3.898598602585701, 3.626972322524992, 3.4961106411175433, 3.960101847201268, 3.176603892718805, 3.766528658267023, -30.659723331170802, 3.723220735216446, 4.163818303964286, 3.2838892662194747]\n",
            "Mean MI Y for last 10 [2.1149611610339396, 2.137323914433339, 2.1544060818930424, 2.1767021300696108, 2.178671415299495, 2.1800624720577493, 2.1237299296139147, 2.1781185594703087, 2.191142166601315, 2.1879062620815692]\n",
            "Elapsed time training MI for Linear4: 463.3233542442322\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  29\n",
            "Beta -  1\n",
            "Delta X:  0.7796468195884723\n",
            "Delta Y:  0.002327227516214947\n",
            "\n",
            "Mean MI X for last 10 [3.626972322524992, 3.4961106411175433, 3.960101847201268, 3.176603892718805, 3.766528658267023, -30.659723331170802, 3.723220735216446, 4.163818303964286, 3.2838892662194747, 2.5042424466310025]\n",
            "Mean MI Y for last 10 [2.137323914433339, 2.1544060818930424, 2.1767021300696108, 2.178671415299495, 2.1800624720577493, 2.1237299296139147, 2.1781185594703087, 2.191142166601315, 2.1879062620815692, 2.190233489597784]\n",
            "Elapsed time training MI for Linear4: 479.2708945274353\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  30\n",
            "Beta -  1\n",
            "Delta X:  0.6279086774346161\n",
            "Delta Y:  0.023812675272732342\n",
            "\n",
            "Mean MI X for last 10 [3.4961106411175433, 3.960101847201268, 3.176603892718805, 3.766528658267023, -30.659723331170802, 3.723220735216446, 4.163818303964286, 3.2838892662194747, 2.5042424466310025, 3.1321511240656186]\n",
            "Mean MI Y for last 10 [2.1544060818930424, 2.1767021300696108, 2.178671415299495, 2.1800624720577493, 2.1237299296139147, 2.1781185594703087, 2.191142166601315, 2.1879062620815692, 2.190233489597784, 2.2140461648705165]\n",
            "Elapsed time training MI for Linear4: 495.1764106750488\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  31\n",
            "Beta -  1\n",
            "Delta X:  0.5289190649223738\n",
            "Delta Y:  0.0011047712012901556\n",
            "\n",
            "Mean MI X for last 10 [3.960101847201268, 3.176603892718805, 3.766528658267023, -30.659723331170802, 3.723220735216446, 4.163818303964286, 3.2838892662194747, 2.5042424466310025, 3.1321511240656186, 3.6610701889879924]\n",
            "Mean MI Y for last 10 [2.1767021300696108, 2.178671415299495, 2.1800624720577493, 2.1237299296139147, 2.1781185594703087, 2.191142166601315, 2.1879062620815692, 2.190233489597784, 2.2140461648705165, 2.2151509360718067]\n",
            "Elapsed time training MI for Linear4: 511.26214361190796\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  32\n",
            "Beta -  1\n",
            "Delta X:  0.7284440699416685\n",
            "Delta Y:  0.022344896025749073\n",
            "\n",
            "Mean MI X for last 10 [3.176603892718805, 3.766528658267023, -30.659723331170802, 3.723220735216446, 4.163818303964286, 3.2838892662194747, 2.5042424466310025, 3.1321511240656186, 3.6610701889879924, 4.389514258929661]\n",
            "Mean MI Y for last 10 [2.178671415299495, 2.1800624720577493, 2.1237299296139147, 2.1781185594703087, 2.191142166601315, 2.1879062620815692, 2.190233489597784, 2.2140461648705165, 2.2151509360718067, 2.2374958320975558]\n",
            "Elapsed time training MI for Linear4: 527.2861678600311\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  33\n",
            "Beta -  1\n",
            "Delta X:  0.77697252261359\n",
            "Delta Y:  0.026901100998494076\n",
            "\n",
            "Mean MI X for last 10 [3.766528658267023, -30.659723331170802, 3.723220735216446, 4.163818303964286, 3.2838892662194747, 2.5042424466310025, 3.1321511240656186, 3.6610701889879924, 4.389514258929661, 3.612541736316071]\n",
            "Mean MI Y for last 10 [2.1800624720577493, 2.1237299296139147, 2.1781185594703087, 2.191142166601315, 2.1879062620815692, 2.190233489597784, 2.2140461648705165, 2.2151509360718067, 2.2374958320975558, 2.2105947310990617]\n",
            "Elapsed time training MI for Linear4: 543.2393131256104\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  34\n",
            "Beta -  1\n",
            "Delta X:  0.2041805156512555\n",
            "Delta Y:  0.027670663175806354\n",
            "\n",
            "Mean MI X for last 10 [-30.659723331170802, 3.723220735216446, 4.163818303964286, 3.2838892662194747, 2.5042424466310025, 3.1321511240656186, 3.6610701889879924, 4.389514258929661, 3.612541736316071, 3.8167222519673265]\n",
            "Mean MI Y for last 10 [2.1237299296139147, 2.1781185594703087, 2.191142166601315, 2.1879062620815692, 2.190233489597784, 2.2140461648705165, 2.2151509360718067, 2.2374958320975558, 2.2105947310990617, 2.238265394274868]\n",
            "Elapsed time training MI for Linear4: 559.2273108959198\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  35\n",
            "Beta -  1\n",
            "Delta X:  0.2403345779061059\n",
            "Delta Y:  0.013595339713066146\n",
            "\n",
            "Mean MI X for last 10 [3.723220735216446, 4.163818303964286, 3.2838892662194747, 2.5042424466310025, 3.1321511240656186, 3.6610701889879924, 4.389514258929661, 3.612541736316071, 3.8167222519673265, 4.057056829873432]\n",
            "Mean MI Y for last 10 [2.1781185594703087, 2.191142166601315, 2.1879062620815692, 2.190233489597784, 2.2140461648705165, 2.2151509360718067, 2.2374958320975558, 2.2105947310990617, 2.238265394274868, 2.224670054561802]\n",
            "Elapsed time training MI for Linear4: 575.2921741008759\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  36\n",
            "Beta -  1\n",
            "Delta X:  0.3361775333693293\n",
            "Delta Y:  0.00810478313136942\n",
            "\n",
            "Mean MI X for last 10 [4.163818303964286, 3.2838892662194747, 2.5042424466310025, 3.1321511240656186, 3.6610701889879924, 4.389514258929661, 3.612541736316071, 3.8167222519673265, 4.057056829873432, 4.393234363242762]\n",
            "Mean MI Y for last 10 [2.191142166601315, 2.1879062620815692, 2.190233489597784, 2.2140461648705165, 2.2151509360718067, 2.2374958320975558, 2.2105947310990617, 2.238265394274868, 2.224670054561802, 2.2165652714304325]\n",
            "Elapsed time training MI for Linear4: 591.3765161037445\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  37\n",
            "Beta -  1\n",
            "Delta X:  0.13786370464479436\n",
            "Delta Y:  0.0280073599012165\n",
            "\n",
            "Mean MI X for last 10 [3.2838892662194747, 2.5042424466310025, 3.1321511240656186, 3.6610701889879924, 4.389514258929661, 3.612541736316071, 3.8167222519673265, 4.057056829873432, 4.393234363242762, 4.531098067887556]\n",
            "Mean MI Y for last 10 [2.1879062620815692, 2.190233489597784, 2.2140461648705165, 2.2151509360718067, 2.2374958320975558, 2.2105947310990617, 2.238265394274868, 2.224670054561802, 2.2165652714304325, 2.244572631331649]\n",
            "Elapsed time training MI for Linear4: 607.2546484470367\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  38\n",
            "Beta -  1\n",
            "Delta X:  0.1979681563529887\n",
            "Delta Y:  0.00972843818318836\n",
            "\n",
            "Mean MI X for last 10 [2.5042424466310025, 3.1321511240656186, 3.6610701889879924, 4.389514258929661, 3.612541736316071, 3.8167222519673265, 4.057056829873432, 4.393234363242762, 4.531098067887556, 4.333129911534567]\n",
            "Mean MI Y for last 10 [2.190233489597784, 2.2140461648705165, 2.2151509360718067, 2.2374958320975558, 2.2105947310990617, 2.238265394274868, 2.224670054561802, 2.2165652714304325, 2.244572631331649, 2.2348441931484606]\n",
            "Elapsed time training MI for Linear4: 623.2781941890717\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  39\n",
            "Beta -  1\n",
            "Delta X:  0.17694606277734248\n",
            "Delta Y:  0.00814459763610298\n",
            "\n",
            "Mean MI X for last 10 [3.1321511240656186, 3.6610701889879924, 4.389514258929661, 3.612541736316071, 3.8167222519673265, 4.057056829873432, 4.393234363242762, 4.531098067887556, 4.333129911534567, 4.156183848757225]\n",
            "Mean MI Y for last 10 [2.2140461648705165, 2.2151509360718067, 2.2374958320975558, 2.2105947310990617, 2.238265394274868, 2.224670054561802, 2.2165652714304325, 2.244572631331649, 2.2348441931484606, 2.2266995955123576]\n",
            "Elapsed time training MI for Linear4: 639.3038446903229\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  40\n",
            "Beta -  1\n",
            "Delta X:  2.8866476250101503\n",
            "Delta Y:  0.025021369904597357\n",
            "\n",
            "Mean MI X for last 10 [3.6610701889879924, 4.389514258929661, 3.612541736316071, 3.8167222519673265, 4.057056829873432, 4.393234363242762, 4.531098067887556, 4.333129911534567, 4.156183848757225, 1.2695362237470744]\n",
            "Mean MI Y for last 10 [2.2151509360718067, 2.2374958320975558, 2.2105947310990617, 2.238265394274868, 2.224670054561802, 2.2165652714304325, 2.244572631331649, 2.2348441931484606, 2.2266995955123576, 2.251720965416955]\n",
            "Elapsed time training MI for Linear4: 655.3462600708008\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  41\n",
            "Beta -  1\n",
            "Delta X:  0.2699143515466881\n",
            "Delta Y:  0.027816997026838042\n",
            "\n",
            "Mean MI X for last 10 [4.389514258929661, 3.612541736316071, 3.8167222519673265, 4.057056829873432, 4.393234363242762, 4.531098067887556, 4.333129911534567, 4.156183848757225, 1.2695362237470744, 0.9996218722003863]\n",
            "Mean MI Y for last 10 [2.2374958320975558, 2.2105947310990617, 2.238265394274868, 2.224670054561802, 2.2165652714304325, 2.244572631331649, 2.2348441931484606, 2.2266995955123576, 2.251720965416955, 2.223903968390117]\n",
            "Elapsed time training MI for Linear4: 671.1029562950134\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  42\n",
            "Beta -  1\n",
            "Delta X:  2.3248384174253385\n",
            "Delta Y:  0.029556122670041596\n",
            "\n",
            "Mean MI X for last 10 [3.612541736316071, 3.8167222519673265, 4.057056829873432, 4.393234363242762, 4.531098067887556, 4.333129911534567, 4.156183848757225, 1.2695362237470744, 0.9996218722003863, 3.324460289625725]\n",
            "Mean MI Y for last 10 [2.2105947310990617, 2.238265394274868, 2.224670054561802, 2.2165652714304325, 2.244572631331649, 2.2348441931484606, 2.2266995955123576, 2.251720965416955, 2.223903968390117, 2.2534600910601585]\n",
            "Elapsed time training MI for Linear4: 687.1138579845428\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  43\n",
            "Beta -  1\n",
            "Delta X:  1.192894164178926\n",
            "Delta Y:  0.017497118602175288\n",
            "\n",
            "Mean MI X for last 10 [3.8167222519673265, 4.057056829873432, 4.393234363242762, 4.531098067887556, 4.333129911534567, 4.156183848757225, 1.2695362237470744, 0.9996218722003863, 3.324460289625725, 4.517354453804651]\n",
            "Mean MI Y for last 10 [2.238265394274868, 2.224670054561802, 2.2165652714304325, 2.244572631331649, 2.2348441931484606, 2.2266995955123576, 2.251720965416955, 2.223903968390117, 2.2534600910601585, 2.2359629724579833]\n",
            "Elapsed time training MI for Linear4: 703.0230224132538\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  44\n",
            "Beta -  1\n",
            "Delta X:  0.002044607835537171\n",
            "Delta Y:  0.007492285420391376\n",
            "\n",
            "Mean MI X for last 10 [4.057056829873432, 4.393234363242762, 4.531098067887556, 4.333129911534567, 4.156183848757225, 1.2695362237470744, 0.9996218722003863, 3.324460289625725, 4.517354453804651, 4.519399061640188]\n",
            "Mean MI Y for last 10 [2.224670054561802, 2.2165652714304325, 2.244572631331649, 2.2348441931484606, 2.2266995955123576, 2.251720965416955, 2.223903968390117, 2.2534600910601585, 2.2359629724579833, 2.228470687037592]\n",
            "Elapsed time training MI for Linear4: 718.9974045753479\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  45\n",
            "Beta -  1\n",
            "Delta X:  0.042768808570243344\n",
            "Delta Y:  0.0029211501831185593\n",
            "\n",
            "Mean MI X for last 10 [4.393234363242762, 4.531098067887556, 4.333129911534567, 4.156183848757225, 1.2695362237470744, 0.9996218722003863, 3.324460289625725, 4.517354453804651, 4.519399061640188, 4.476630253069945]\n",
            "Mean MI Y for last 10 [2.2165652714304325, 2.244572631331649, 2.2348441931484606, 2.2266995955123576, 2.251720965416955, 2.223903968390117, 2.2534600910601585, 2.2359629724579833, 2.228470687037592, 2.2313918372207104]\n",
            "Elapsed time training MI for Linear4: 734.817752122879\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  46\n",
            "Beta -  1\n",
            "Delta X:  0.11218099858460917\n",
            "Delta Y:  0.008351390549877546\n",
            "\n",
            "Mean MI X for last 10 [4.531098067887556, 4.333129911534567, 4.156183848757225, 1.2695362237470744, 0.9996218722003863, 3.324460289625725, 4.517354453804651, 4.519399061640188, 4.476630253069945, 4.588811251654554]\n",
            "Mean MI Y for last 10 [2.244572631331649, 2.2348441931484606, 2.2266995955123576, 2.251720965416955, 2.223903968390117, 2.2534600910601585, 2.2359629724579833, 2.228470687037592, 2.2313918372207104, 2.239743227770588]\n",
            "Elapsed time training MI for Linear4: 750.8203561306\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  47\n",
            "Beta -  1\n",
            "Delta X:  0.31215752086151394\n",
            "Delta Y:  0.005692506141499631\n",
            "\n",
            "Mean MI X for last 10 [4.333129911534567, 4.156183848757225, 1.2695362237470744, 0.9996218722003863, 3.324460289625725, 4.517354453804651, 4.519399061640188, 4.476630253069945, 4.588811251654554, 4.27665373079304]\n",
            "Mean MI Y for last 10 [2.2348441931484606, 2.2266995955123576, 2.251720965416955, 2.223903968390117, 2.2534600910601585, 2.2359629724579833, 2.228470687037592, 2.2313918372207104, 2.239743227770588, 2.2454357339120876]\n",
            "Elapsed time training MI for Linear4: 766.8398156166077\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  48\n",
            "Beta -  1\n",
            "Delta X:  0.8158852693114453\n",
            "Delta Y:  0.012659030682496741\n",
            "\n",
            "Mean MI X for last 10 [4.156183848757225, 1.2695362237470744, 0.9996218722003863, 3.324460289625725, 4.517354453804651, 4.519399061640188, 4.476630253069945, 4.588811251654554, 4.27665373079304, 3.4607684614815946]\n",
            "Mean MI Y for last 10 [2.2266995955123576, 2.251720965416955, 2.223903968390117, 2.2534600910601585, 2.2359629724579833, 2.228470687037592, 2.2313918372207104, 2.239743227770588, 2.2454357339120876, 2.232776703229591]\n",
            "Elapsed time training MI for Linear4: 782.7522337436676\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  49\n",
            "Beta -  1\n",
            "Delta X:  1.1205385270149217\n",
            "Delta Y:  0.013683381873661471\n",
            "\n",
            "Mean MI X for last 10 [1.2695362237470744, 0.9996218722003863, 3.324460289625725, 4.517354453804651, 4.519399061640188, 4.476630253069945, 4.588811251654554, 4.27665373079304, 3.4607684614815946, 4.581306988496516]\n",
            "Mean MI Y for last 10 [2.251720965416955, 2.223903968390117, 2.2534600910601585, 2.2359629724579833, 2.228470687037592, 2.2313918372207104, 2.239743227770588, 2.2454357339120876, 2.232776703229591, 2.2464600851032523]\n",
            "Elapsed time training MI for Linear4: 798.8199923038483\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  50\n",
            "Beta -  1\n",
            "Delta X:  0.10632886662920438\n",
            "Delta Y:  0.00059144596046945\n",
            "\n",
            "Mean MI X for last 10 [0.9996218722003863, 3.324460289625725, 4.517354453804651, 4.519399061640188, 4.476630253069945, 4.588811251654554, 4.27665373079304, 3.4607684614815946, 4.581306988496516, 4.474978121867312]\n",
            "Mean MI Y for last 10 [2.223903968390117, 2.2534600910601585, 2.2359629724579833, 2.228470687037592, 2.2313918372207104, 2.239743227770588, 2.2454357339120876, 2.232776703229591, 2.2464600851032523, 2.245868639142783]\n",
            "Elapsed time training MI for Linear4: 814.6016421318054\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  51\n",
            "Beta -  1\n",
            "Delta X:  0.0198848331406678\n",
            "Delta Y:  0.006285101493030076\n",
            "\n",
            "Mean MI X for last 10 [3.324460289625725, 4.517354453804651, 4.519399061640188, 4.476630253069945, 4.588811251654554, 4.27665373079304, 3.4607684614815946, 4.581306988496516, 4.474978121867312, 4.455093288726644]\n",
            "Mean MI Y for last 10 [2.2534600910601585, 2.2359629724579833, 2.228470687037592, 2.2313918372207104, 2.239743227770588, 2.2454357339120876, 2.232776703229591, 2.2464600851032523, 2.245868639142783, 2.252153740635813]\n",
            "Elapsed time training MI for Linear4: 830.8323032855988\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  52\n",
            "Beta -  1\n",
            "Delta X:  1.0317391487581138\n",
            "Delta Y:  0.003998382894723207\n",
            "\n",
            "Mean MI X for last 10 [4.517354453804651, 4.519399061640188, 4.476630253069945, 4.588811251654554, 4.27665373079304, 3.4607684614815946, 4.581306988496516, 4.474978121867312, 4.455093288726644, 3.4233541399685303]\n",
            "Mean MI Y for last 10 [2.2359629724579833, 2.228470687037592, 2.2313918372207104, 2.239743227770588, 2.2454357339120876, 2.232776703229591, 2.2464600851032523, 2.245868639142783, 2.252153740635813, 2.256152123530536]\n",
            "Elapsed time training MI for Linear4: 846.6582231521606\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  53\n",
            "Beta -  1\n",
            "Delta X:  1.3521128023611202\n",
            "Delta Y:  0.010009454384541705\n",
            "\n",
            "Mean MI X for last 10 [4.519399061640188, 4.476630253069945, 4.588811251654554, 4.27665373079304, 3.4607684614815946, 4.581306988496516, 4.474978121867312, 4.455093288726644, 3.4233541399685303, 4.7754669423296505]\n",
            "Mean MI Y for last 10 [2.228470687037592, 2.2313918372207104, 2.239743227770588, 2.2454357339120876, 2.232776703229591, 2.2464600851032523, 2.245868639142783, 2.252153740635813, 2.256152123530536, 2.266161577915078]\n",
            "Elapsed time training MI for Linear4: 862.5638773441315\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  54\n",
            "Beta -  1\n",
            "Delta X:  2.0128673792902085\n",
            "Delta Y:  0.0093142048382302\n",
            "\n",
            "Mean MI X for last 10 [4.476630253069945, 4.588811251654554, 4.27665373079304, 3.4607684614815946, 4.581306988496516, 4.474978121867312, 4.455093288726644, 3.4233541399685303, 4.7754669423296505, 2.762599563039442]\n",
            "Mean MI Y for last 10 [2.2313918372207104, 2.239743227770588, 2.2454357339120876, 2.232776703229591, 2.2464600851032523, 2.245868639142783, 2.252153740635813, 2.256152123530536, 2.266161577915078, 2.275475782753308]\n",
            "Elapsed time training MI for Linear4: 878.5982866287231\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  55\n",
            "Beta -  1\n",
            "Delta X:  3.2322577616807493\n",
            "Delta Y:  0.03443717016085923\n",
            "\n",
            "Mean MI X for last 10 [4.588811251654554, 4.27665373079304, 3.4607684614815946, 4.581306988496516, 4.474978121867312, 4.455093288726644, 3.4233541399685303, 4.7754669423296505, 2.762599563039442, -0.4696581986413073]\n",
            "Mean MI Y for last 10 [2.239743227770588, 2.2454357339120876, 2.232776703229591, 2.2464600851032523, 2.245868639142783, 2.252153740635813, 2.256152123530536, 2.266161577915078, 2.275475782753308, 2.241038612592449]\n",
            "Elapsed time training MI for Linear4: 894.4979758262634\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  56\n",
            "Beta -  1\n",
            "Delta X:  4.425999969307547\n",
            "Delta Y:  0.015825516760730185\n",
            "\n",
            "Mean MI X for last 10 [4.27665373079304, 3.4607684614815946, 4.581306988496516, 4.474978121867312, 4.455093288726644, 3.4233541399685303, 4.7754669423296505, 2.762599563039442, -0.4696581986413073, 3.9563417706662403]\n",
            "Mean MI Y for last 10 [2.2454357339120876, 2.232776703229591, 2.2464600851032523, 2.245868639142783, 2.252153740635813, 2.256152123530536, 2.266161577915078, 2.275475782753308, 2.241038612592449, 2.2252130958317187]\n",
            "Elapsed time training MI for Linear4: 910.3323769569397\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  57\n",
            "Beta -  1\n",
            "Delta X:  0.698937099625561\n",
            "Delta Y:  0.020909710352354782\n",
            "\n",
            "Mean MI X for last 10 [3.4607684614815946, 4.581306988496516, 4.474978121867312, 4.455093288726644, 3.4233541399685303, 4.7754669423296505, 2.762599563039442, -0.4696581986413073, 3.9563417706662403, 4.655278870291801]\n",
            "Mean MI Y for last 10 [2.232776703229591, 2.2464600851032523, 2.245868639142783, 2.252153740635813, 2.256152123530536, 2.266161577915078, 2.275475782753308, 2.241038612592449, 2.2252130958317187, 2.2461228061840735]\n",
            "Elapsed time training MI for Linear4: 926.0795707702637\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  58\n",
            "Beta -  1\n",
            "Delta X:  0.29849367355232825\n",
            "Delta Y:  0.03055406099697633\n",
            "\n",
            "Mean MI X for last 10 [4.581306988496516, 4.474978121867312, 4.455093288726644, 3.4233541399685303, 4.7754669423296505, 2.762599563039442, -0.4696581986413073, 3.9563417706662403, 4.655278870291801, 4.356785196739473]\n",
            "Mean MI Y for last 10 [2.2464600851032523, 2.245868639142783, 2.252153740635813, 2.256152123530536, 2.266161577915078, 2.275475782753308, 2.241038612592449, 2.2252130958317187, 2.2461228061840735, 2.27667686718105]\n",
            "Elapsed time training MI for Linear4: 941.7810888290405\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  59\n",
            "Beta -  1\n",
            "Delta X:  0.3489921230242965\n",
            "Delta Y:  0.01788349459166172\n",
            "\n",
            "Mean MI X for last 10 [4.474978121867312, 4.455093288726644, 3.4233541399685303, 4.7754669423296505, 2.762599563039442, -0.4696581986413073, 3.9563417706662403, 4.655278870291801, 4.356785196739473, 4.70577731976377]\n",
            "Mean MI Y for last 10 [2.245868639142783, 2.252153740635813, 2.256152123530536, 2.266161577915078, 2.275475782753308, 2.241038612592449, 2.2252130958317187, 2.2461228061840735, 2.27667686718105, 2.258793372589388]\n",
            "Elapsed time training MI for Linear4: 957.7367882728577\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  60\n",
            "Beta -  1\n",
            "Delta X:  0.1238459104668097\n",
            "Delta Y:  0.014682673187906836\n",
            "\n",
            "Mean MI X for last 10 [4.455093288726644, 3.4233541399685303, 4.7754669423296505, 2.762599563039442, -0.4696581986413073, 3.9563417706662403, 4.655278870291801, 4.356785196739473, 4.70577731976377, 4.829623230230579]\n",
            "Mean MI Y for last 10 [2.252153740635813, 2.256152123530536, 2.266161577915078, 2.275475782753308, 2.241038612592449, 2.2252130958317187, 2.2461228061840735, 2.27667686718105, 2.258793372589388, 2.2441106994014812]\n",
            "Elapsed time training MI for Linear4: 973.3201818466187\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  61\n",
            "Beta -  1\n",
            "Delta X:  0.06905588488588954\n",
            "Delta Y:  0.01663894503355534\n",
            "\n",
            "Mean MI X for last 10 [3.4233541399685303, 4.7754669423296505, 2.762599563039442, -0.4696581986413073, 3.9563417706662403, 4.655278870291801, 4.356785196739473, 4.70577731976377, 4.829623230230579, 4.76056734534469]\n",
            "Mean MI Y for last 10 [2.256152123530536, 2.266161577915078, 2.275475782753308, 2.241038612592449, 2.2252130958317187, 2.2461228061840735, 2.27667686718105, 2.258793372589388, 2.2441106994014812, 2.2607496444350366]\n",
            "Elapsed time training MI for Linear4: 988.9436342716217\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  62\n",
            "Beta -  1\n",
            "Delta X:  0.004026085074777086\n",
            "Delta Y:  0.007474196236779473\n",
            "\n",
            "Mean MI X for last 10 [4.7754669423296505, 2.762599563039442, -0.4696581986413073, 3.9563417706662403, 4.655278870291801, 4.356785196739473, 4.70577731976377, 4.829623230230579, 4.76056734534469, 4.764593430419467]\n",
            "Mean MI Y for last 10 [2.266161577915078, 2.275475782753308, 2.241038612592449, 2.2252130958317187, 2.2461228061840735, 2.27667686718105, 2.258793372589388, 2.2441106994014812, 2.2607496444350366, 2.268223840671816]\n",
            "Elapsed time training MI for Linear4: 1004.6229772567749\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  63\n",
            "Beta -  1\n",
            "Delta X:  0.26702828092107467\n",
            "Delta Y:  0.03710255096716164\n",
            "\n",
            "Mean MI X for last 10 [2.762599563039442, -0.4696581986413073, 3.9563417706662403, 4.655278870291801, 4.356785196739473, 4.70577731976377, 4.829623230230579, 4.76056734534469, 4.764593430419467, 4.497565149498392]\n",
            "Mean MI Y for last 10 [2.275475782753308, 2.241038612592449, 2.2252130958317187, 2.2461228061840735, 2.27667686718105, 2.258793372589388, 2.2441106994014812, 2.2607496444350366, 2.268223840671816, 2.2311212897046544]\n",
            "Elapsed time training MI for Linear4: 1020.2785232067108\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  64\n",
            "Beta -  1\n",
            "Delta X:  0.45264046278589554\n",
            "Delta Y:  0.002142007671185109\n",
            "\n",
            "Mean MI X for last 10 [-0.4696581986413073, 3.9563417706662403, 4.655278870291801, 4.356785196739473, 4.70577731976377, 4.829623230230579, 4.76056734534469, 4.764593430419467, 4.497565149498392, 4.044924686712497]\n",
            "Mean MI Y for last 10 [2.241038612592449, 2.2252130958317187, 2.2461228061840735, 2.27667686718105, 2.258793372589388, 2.2441106994014812, 2.2607496444350366, 2.268223840671816, 2.2311212897046544, 2.2332632973758395]\n",
            "Elapsed time training MI for Linear4: 1036.0640769004822\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  65\n",
            "Beta -  1\n",
            "Delta X:  0.8266240475274351\n",
            "Delta Y:  0.01878528134909274\n",
            "\n",
            "Mean MI X for last 10 [3.9563417706662403, 4.655278870291801, 4.356785196739473, 4.70577731976377, 4.829623230230579, 4.76056734534469, 4.764593430419467, 4.497565149498392, 4.044924686712497, 4.871548734239932]\n",
            "Mean MI Y for last 10 [2.2252130958317187, 2.2461228061840735, 2.27667686718105, 2.258793372589388, 2.2441106994014812, 2.2607496444350366, 2.268223840671816, 2.2311212897046544, 2.2332632973758395, 2.2520485787249322]\n",
            "Elapsed time training MI for Linear4: 1051.7393624782562\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  66\n",
            "Beta -  1\n",
            "Delta X:  0.6578909870403908\n",
            "Delta Y:  0.012530164169604507\n",
            "\n",
            "Mean MI X for last 10 [4.655278870291801, 4.356785196739473, 4.70577731976377, 4.829623230230579, 4.76056734534469, 4.764593430419467, 4.497565149498392, 4.044924686712497, 4.871548734239932, 4.213657747199541]\n",
            "Mean MI Y for last 10 [2.2461228061840735, 2.27667686718105, 2.258793372589388, 2.2441106994014812, 2.2607496444350366, 2.268223840671816, 2.2311212897046544, 2.2332632973758395, 2.2520485787249322, 2.2645787428945368]\n",
            "Elapsed time training MI for Linear4: 1067.4023923873901\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  67\n",
            "Beta -  1\n",
            "Delta X:  0.24709991376791463\n",
            "Delta Y:  0.025704205417429904\n",
            "\n",
            "Mean MI X for last 10 [4.356785196739473, 4.70577731976377, 4.829623230230579, 4.76056734534469, 4.764593430419467, 4.497565149498392, 4.044924686712497, 4.871548734239932, 4.213657747199541, 3.9665578334316263]\n",
            "Mean MI Y for last 10 [2.27667686718105, 2.258793372589388, 2.2441106994014812, 2.2607496444350366, 2.268223840671816, 2.2311212897046544, 2.2332632973758395, 2.2520485787249322, 2.2645787428945368, 2.238874537477107]\n",
            "Elapsed time training MI for Linear4: 1083.0507357120514\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  68\n",
            "Beta -  1\n",
            "Delta X:  0.645674105900437\n",
            "Delta Y:  0.026929029777868596\n",
            "\n",
            "Mean MI X for last 10 [4.70577731976377, 4.829623230230579, 4.76056734534469, 4.764593430419467, 4.497565149498392, 4.044924686712497, 4.871548734239932, 4.213657747199541, 3.9665578334316263, 4.612231939332063]\n",
            "Mean MI Y for last 10 [2.258793372589388, 2.2441106994014812, 2.2607496444350366, 2.268223840671816, 2.2311212897046544, 2.2332632973758395, 2.2520485787249322, 2.2645787428945368, 2.238874537477107, 2.2658035672549754]\n",
            "Elapsed time training MI for Linear4: 1098.6782038211823\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  69\n",
            "Beta -  1\n",
            "Delta X:  0.5359847286362633\n",
            "Delta Y:  0.026813842848674163\n",
            "\n",
            "Mean MI X for last 10 [4.829623230230579, 4.76056734534469, 4.764593430419467, 4.497565149498392, 4.044924686712497, 4.871548734239932, 4.213657747199541, 3.9665578334316263, 4.612231939332063, 4.0762472106958]\n",
            "Mean MI Y for last 10 [2.2441106994014812, 2.2607496444350366, 2.268223840671816, 2.2311212897046544, 2.2332632973758395, 2.2520485787249322, 2.2645787428945368, 2.238874537477107, 2.2658035672549754, 2.2389897244063013]\n",
            "Elapsed time training MI for Linear4: 1114.4607548713684\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  70\n",
            "Beta -  1\n",
            "Delta X:  0.8253195588268447\n",
            "Delta Y:  0.05661875530600824\n",
            "\n",
            "Mean MI X for last 10 [4.76056734534469, 4.764593430419467, 4.497565149498392, 4.044924686712497, 4.871548734239932, 4.213657747199541, 3.9665578334316263, 4.612231939332063, 4.0762472106958, 4.901566769522645]\n",
            "Mean MI Y for last 10 [2.2607496444350366, 2.268223840671816, 2.2311212897046544, 2.2332632973758395, 2.2520485787249322, 2.2645787428945368, 2.238874537477107, 2.2658035672549754, 2.2389897244063013, 2.2956084797123095]\n",
            "Elapsed time training MI for Linear4: 1130.400634765625\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  71\n",
            "Beta -  1\n",
            "Delta X:  0.16740428689700426\n",
            "Delta Y:  0.04281414724362209\n",
            "\n",
            "Mean MI X for last 10 [4.764593430419467, 4.497565149498392, 4.044924686712497, 4.871548734239932, 4.213657747199541, 3.9665578334316263, 4.612231939332063, 4.0762472106958, 4.901566769522645, 4.73416248262564]\n",
            "Mean MI Y for last 10 [2.268223840671816, 2.2311212897046544, 2.2332632973758395, 2.2520485787249322, 2.2645787428945368, 2.238874537477107, 2.2658035672549754, 2.2389897244063013, 2.2956084797123095, 2.2527943324686874]\n",
            "Elapsed time training MI for Linear4: 1146.1006436347961\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  72\n",
            "Beta -  1\n",
            "Delta X:  0.17206040653846877\n",
            "Delta Y:  0.004204945904868307\n",
            "\n",
            "Mean MI X for last 10 [4.497565149498392, 4.044924686712497, 4.871548734239932, 4.213657747199541, 3.9665578334316263, 4.612231939332063, 4.0762472106958, 4.901566769522645, 4.73416248262564, 4.906222889164109]\n",
            "Mean MI Y for last 10 [2.2311212897046544, 2.2332632973758395, 2.2520485787249322, 2.2645787428945368, 2.238874537477107, 2.2658035672549754, 2.2389897244063013, 2.2956084797123095, 2.2527943324686874, 2.2569992783735557]\n",
            "Elapsed time training MI for Linear4: 1161.8026340007782\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  73\n",
            "Beta -  1\n",
            "Delta X:  0.08226527156097774\n",
            "Delta Y:  0.0016968018973049226\n",
            "\n",
            "Mean MI X for last 10 [4.044924686712497, 4.871548734239932, 4.213657747199541, 3.9665578334316263, 4.612231939332063, 4.0762472106958, 4.901566769522645, 4.73416248262564, 4.906222889164109, 4.988488160725087]\n",
            "Mean MI Y for last 10 [2.2332632973758395, 2.2520485787249322, 2.2645787428945368, 2.238874537477107, 2.2658035672549754, 2.2389897244063013, 2.2956084797123095, 2.2527943324686874, 2.2569992783735557, 2.2586960802708607]\n",
            "Elapsed time training MI for Linear4: 1177.3354032039642\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  74\n",
            "Beta -  1\n",
            "Delta X:  0.764027745484797\n",
            "Delta Y:  0.0026964137294909207\n",
            "\n",
            "Mean MI X for last 10 [4.871548734239932, 4.213657747199541, 3.9665578334316263, 4.612231939332063, 4.0762472106958, 4.901566769522645, 4.73416248262564, 4.906222889164109, 4.988488160725087, 4.22446041524029]\n",
            "Mean MI Y for last 10 [2.2520485787249322, 2.2645787428945368, 2.238874537477107, 2.2658035672549754, 2.2389897244063013, 2.2956084797123095, 2.2527943324686874, 2.2569992783735557, 2.2586960802708607, 2.2613924940003516]\n",
            "Elapsed time training MI for Linear4: 1193.0648608207703\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  75\n",
            "Beta -  1\n",
            "Delta X:  35.94136783614088\n",
            "Delta Y:  0.00882692110818084\n",
            "\n",
            "Mean MI X for last 10 [4.213657747199541, 3.9665578334316263, 4.612231939332063, 4.0762472106958, 4.901566769522645, 4.73416248262564, 4.906222889164109, 4.988488160725087, 4.22446041524029, -31.716907420900586]\n",
            "Mean MI Y for last 10 [2.2645787428945368, 2.238874537477107, 2.2658035672549754, 2.2389897244063013, 2.2956084797123095, 2.2527943324686874, 2.2569992783735557, 2.2586960802708607, 2.2613924940003516, 2.2525655728921707]\n",
            "Elapsed time training MI for Linear4: 1208.6314251422882\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  76\n",
            "Beta -  1\n",
            "Delta X:  36.56469230331592\n",
            "Delta Y:  0.006374951491732173\n",
            "\n",
            "Mean MI X for last 10 [3.9665578334316263, 4.612231939332063, 4.0762472106958, 4.901566769522645, 4.73416248262564, 4.906222889164109, 4.988488160725087, 4.22446041524029, -31.716907420900586, 4.847784882415333]\n",
            "Mean MI Y for last 10 [2.238874537477107, 2.2658035672549754, 2.2389897244063013, 2.2956084797123095, 2.2527943324686874, 2.2569992783735557, 2.2586960802708607, 2.2613924940003516, 2.2525655728921707, 2.258940524383903]\n",
            "Elapsed time training MI for Linear4: 1224.2032778263092\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  77\n",
            "Beta -  1\n",
            "Delta X:  0.2631292439727124\n",
            "Delta Y:  0.021708220688264834\n",
            "\n",
            "Mean MI X for last 10 [4.612231939332063, 4.0762472106958, 4.901566769522645, 4.73416248262564, 4.906222889164109, 4.988488160725087, 4.22446041524029, -31.716907420900586, 4.847784882415333, 5.110914126388045]\n",
            "Mean MI Y for last 10 [2.2658035672549754, 2.2389897244063013, 2.2956084797123095, 2.2527943324686874, 2.2569992783735557, 2.2586960802708607, 2.2613924940003516, 2.2525655728921707, 2.258940524383903, 2.2806487450721677]\n",
            "Elapsed time training MI for Linear4: 1239.805728673935\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  78\n",
            "Beta -  1\n",
            "Delta X:  0.10778376186834393\n",
            "Delta Y:  0.03597323764870186\n",
            "\n",
            "Mean MI X for last 10 [4.0762472106958, 4.901566769522645, 4.73416248262564, 4.906222889164109, 4.988488160725087, 4.22446041524029, -31.716907420900586, 4.847784882415333, 5.110914126388045, 5.003130364519701]\n",
            "Mean MI Y for last 10 [2.2389897244063013, 2.2956084797123095, 2.2527943324686874, 2.2569992783735557, 2.2586960802708607, 2.2613924940003516, 2.2525655728921707, 2.258940524383903, 2.2806487450721677, 2.244675507423466]\n",
            "Elapsed time training MI for Linear4: 1255.3067314624786\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  79\n",
            "Beta -  1\n",
            "Delta X:  2.2247991910112948\n",
            "Delta Y:  0.017227656678604486\n",
            "\n",
            "Mean MI X for last 10 [4.901566769522645, 4.73416248262564, 4.906222889164109, 4.988488160725087, 4.22446041524029, -31.716907420900586, 4.847784882415333, 5.110914126388045, 5.003130364519701, 2.7783311735084064]\n",
            "Mean MI Y for last 10 [2.2956084797123095, 2.2527943324686874, 2.2569992783735557, 2.2586960802708607, 2.2613924940003516, 2.2525655728921707, 2.258940524383903, 2.2806487450721677, 2.244675507423466, 2.2619031641020704]\n",
            "Elapsed time training MI for Linear4: 1271.0210444927216\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  80\n",
            "Beta -  1\n",
            "Delta X:  2.5442464249983017\n",
            "Delta Y:  0.00030856396852030343\n",
            "\n",
            "Mean MI X for last 10 [4.73416248262564, 4.906222889164109, 4.988488160725087, 4.22446041524029, -31.716907420900586, 4.847784882415333, 5.110914126388045, 5.003130364519701, 2.7783311735084064, 5.322577598506708]\n",
            "Mean MI Y for last 10 [2.2527943324686874, 2.2569992783735557, 2.2586960802708607, 2.2613924940003516, 2.2525655728921707, 2.258940524383903, 2.2806487450721677, 2.244675507423466, 2.2619031641020704, 2.26159460013355]\n",
            "Elapsed time training MI for Linear4: 1286.568717956543\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  81\n",
            "Beta -  1\n",
            "Delta X:  0.3001971699789898\n",
            "Delta Y:  0.005716609929415917\n",
            "\n",
            "Mean MI X for last 10 [4.906222889164109, 4.988488160725087, 4.22446041524029, -31.716907420900586, 4.847784882415333, 5.110914126388045, 5.003130364519701, 2.7783311735084064, 5.322577598506708, 5.022380428527718]\n",
            "Mean MI Y for last 10 [2.2569992783735557, 2.2586960802708607, 2.2613924940003516, 2.2525655728921707, 2.258940524383903, 2.2806487450721677, 2.244675507423466, 2.2619031641020704, 2.26159460013355, 2.255877990204134]\n",
            "Elapsed time training MI for Linear4: 1302.1085050106049\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  82\n",
            "Beta -  1\n",
            "Delta X:  2.741039401686776\n",
            "Delta Y:  0.022808447321340353\n",
            "\n",
            "Mean MI X for last 10 [4.988488160725087, 4.22446041524029, -31.716907420900586, 4.847784882415333, 5.110914126388045, 5.003130364519701, 2.7783311735084064, 5.322577598506708, 5.022380428527718, 2.281341026840942]\n",
            "Mean MI Y for last 10 [2.2586960802708607, 2.2613924940003516, 2.2525655728921707, 2.258940524383903, 2.2806487450721677, 2.244675507423466, 2.2619031641020704, 2.26159460013355, 2.255877990204134, 2.2786864375254745]\n",
            "Elapsed time training MI for Linear4: 1317.8595101833344\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  83\n",
            "Beta -  1\n",
            "Delta X:  111.67831054171012\n",
            "Delta Y:  0.01624783829076959\n",
            "\n",
            "Mean MI X for last 10 [4.22446041524029, -31.716907420900586, 4.847784882415333, 5.110914126388045, 5.003130364519701, 2.7783311735084064, 5.322577598506708, 5.022380428527718, 2.281341026840942, -109.39696951486917]\n",
            "Mean MI Y for last 10 [2.2613924940003516, 2.2525655728921707, 2.258940524383903, 2.2806487450721677, 2.244675507423466, 2.2619031641020704, 2.26159460013355, 2.255877990204134, 2.2786864375254745, 2.262438599234705]\n",
            "Elapsed time training MI for Linear4: 1333.566727399826\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  84\n",
            "Beta -  1\n",
            "Delta X:  112.79447138716164\n",
            "Delta Y:  0.009193804091228053\n",
            "\n",
            "Mean MI X for last 10 [-31.716907420900586, 4.847784882415333, 5.110914126388045, 5.003130364519701, 2.7783311735084064, 5.322577598506708, 5.022380428527718, 2.281341026840942, -109.39696951486917, 3.3975018722924597]\n",
            "Mean MI Y for last 10 [2.2525655728921707, 2.258940524383903, 2.2806487450721677, 2.244675507423466, 2.2619031641020704, 2.26159460013355, 2.255877990204134, 2.2786864375254745, 2.262438599234705, 2.271632403325933]\n",
            "Elapsed time training MI for Linear4: 1349.1628742218018\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  85\n",
            "Beta -  1\n",
            "Delta X:  1.6636508098289147\n",
            "Delta Y:  0.029670766167549267\n",
            "\n",
            "Mean MI X for last 10 [4.847784882415333, 5.110914126388045, 5.003130364519701, 2.7783311735084064, 5.322577598506708, 5.022380428527718, 2.281341026840942, -109.39696951486917, 3.3975018722924597, 5.061152682121374]\n",
            "Mean MI Y for last 10 [2.258940524383903, 2.2806487450721677, 2.244675507423466, 2.2619031641020704, 2.26159460013355, 2.255877990204134, 2.2786864375254745, 2.262438599234705, 2.271632403325933, 2.2419616371583837]\n",
            "Elapsed time training MI for Linear4: 1364.9642944335938\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  86\n",
            "Beta -  1\n",
            "Delta X:  0.06667490274921395\n",
            "Delta Y:  0.03004035220217327\n",
            "\n",
            "Mean MI X for last 10 [5.110914126388045, 5.003130364519701, 2.7783311735084064, 5.322577598506708, 5.022380428527718, 2.281341026840942, -109.39696951486917, 3.3975018722924597, 5.061152682121374, 4.99447777937216]\n",
            "Mean MI Y for last 10 [2.2806487450721677, 2.244675507423466, 2.2619031641020704, 2.26159460013355, 2.255877990204134, 2.2786864375254745, 2.262438599234705, 2.271632403325933, 2.2419616371583837, 2.272001989360557]\n",
            "Elapsed time training MI for Linear4: 1380.505492925644\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  87\n",
            "Beta -  1\n",
            "Delta X:  13.022342408898034\n",
            "Delta Y:  0.004061663328712051\n",
            "\n",
            "Mean MI X for last 10 [5.003130364519701, 2.7783311735084064, 5.322577598506708, 5.022380428527718, 2.281341026840942, -109.39696951486917, 3.3975018722924597, 5.061152682121374, 4.99447777937216, -8.027864629525874]\n",
            "Mean MI Y for last 10 [2.244675507423466, 2.2619031641020704, 2.26159460013355, 2.255877990204134, 2.2786864375254745, 2.262438599234705, 2.271632403325933, 2.2419616371583837, 2.272001989360557, 2.276063652689269]\n",
            "Elapsed time training MI for Linear4: 1395.945232629776\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  88\n",
            "Beta -  1\n",
            "Delta X:  13.323846641379888\n",
            "Delta Y:  0.0053677369536617725\n",
            "\n",
            "Mean MI X for last 10 [2.7783311735084064, 5.322577598506708, 5.022380428527718, 2.281341026840942, -109.39696951486917, 3.3975018722924597, 5.061152682121374, 4.99447777937216, -8.027864629525874, 5.295982011854013]\n",
            "Mean MI Y for last 10 [2.2619031641020704, 2.26159460013355, 2.255877990204134, 2.2786864375254745, 2.262438599234705, 2.271632403325933, 2.2419616371583837, 2.272001989360557, 2.276063652689269, 2.281431389642931]\n",
            "Elapsed time training MI for Linear4: 1411.52423787117\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  89\n",
            "Beta -  1\n",
            "Delta X:  0.014743401043451065\n",
            "Delta Y:  0.017167736853617832\n",
            "\n",
            "Mean MI X for last 10 [5.322577598506708, 5.022380428527718, 2.281341026840942, -109.39696951486917, 3.3975018722924597, 5.061152682121374, 4.99447777937216, -8.027864629525874, 5.295982011854013, 5.281238610810562]\n",
            "Mean MI Y for last 10 [2.26159460013355, 2.255877990204134, 2.2786864375254745, 2.262438599234705, 2.271632403325933, 2.2419616371583837, 2.272001989360557, 2.276063652689269, 2.281431389642931, 2.264263652789313]\n",
            "Elapsed time training MI for Linear4: 1427.1417508125305\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  90\n",
            "Beta -  1\n",
            "Delta X:  0.07713532956170077\n",
            "Delta Y:  0.0007865113744349728\n",
            "\n",
            "Mean MI X for last 10 [5.022380428527718, 2.281341026840942, -109.39696951486917, 3.3975018722924597, 5.061152682121374, 4.99447777937216, -8.027864629525874, 5.295982011854013, 5.281238610810562, 5.2041032812488615]\n",
            "Mean MI Y for last 10 [2.255877990204134, 2.2786864375254745, 2.262438599234705, 2.271632403325933, 2.2419616371583837, 2.272001989360557, 2.276063652689269, 2.281431389642931, 2.264263652789313, 2.263477141414878]\n",
            "Elapsed time training MI for Linear4: 1442.7353682518005\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  91\n",
            "Beta -  1\n",
            "Delta X:  0.06194525232701409\n",
            "Delta Y:  0.011006755869526152\n",
            "\n",
            "Mean MI X for last 10 [2.281341026840942, -109.39696951486917, 3.3975018722924597, 5.061152682121374, 4.99447777937216, -8.027864629525874, 5.295982011854013, 5.281238610810562, 5.2041032812488615, 5.2660485335758755]\n",
            "Mean MI Y for last 10 [2.2786864375254745, 2.262438599234705, 2.271632403325933, 2.2419616371583837, 2.272001989360557, 2.276063652689269, 2.281431389642931, 2.264263652789313, 2.263477141414878, 2.274483897284404]\n",
            "Elapsed time training MI for Linear4: 1458.3702192306519\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  92\n",
            "Beta -  1\n",
            "Delta X:  0.2082778009524482\n",
            "Delta Y:  0.036564252142713194\n",
            "\n",
            "Mean MI X for last 10 [-109.39696951486917, 3.3975018722924597, 5.061152682121374, 4.99447777937216, -8.027864629525874, 5.295982011854013, 5.281238610810562, 5.2041032812488615, 5.2660485335758755, 5.057770732623427]\n",
            "Mean MI Y for last 10 [2.262438599234705, 2.271632403325933, 2.2419616371583837, 2.272001989360557, 2.276063652689269, 2.281431389642931, 2.264263652789313, 2.263477141414878, 2.274483897284404, 2.237919645141691]\n",
            "Elapsed time training MI for Linear4: 1473.926512479782\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  93\n",
            "Beta -  1\n",
            "Delta X:  0.14502607276444746\n",
            "Delta Y:  0.01422356212062903\n",
            "\n",
            "Mean MI X for last 10 [3.3975018722924597, 5.061152682121374, 4.99447777937216, -8.027864629525874, 5.295982011854013, 5.281238610810562, 5.2041032812488615, 5.2660485335758755, 5.057770732623427, 4.91274465985898]\n",
            "Mean MI Y for last 10 [2.271632403325933, 2.2419616371583837, 2.272001989360557, 2.276063652689269, 2.281431389642931, 2.264263652789313, 2.263477141414878, 2.274483897284404, 2.237919645141691, 2.25214320726232]\n",
            "Elapsed time training MI for Linear4: 1489.475430727005\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  94\n",
            "Beta -  1\n",
            "Delta X:  0.004681069967843676\n",
            "Delta Y:  0.018380335907437928\n",
            "\n",
            "Mean MI X for last 10 [5.061152682121374, 4.99447777937216, -8.027864629525874, 5.295982011854013, 5.281238610810562, 5.2041032812488615, 5.2660485335758755, 5.057770732623427, 4.91274465985898, 4.917425729826824]\n",
            "Mean MI Y for last 10 [2.2419616371583837, 2.272001989360557, 2.276063652689269, 2.281431389642931, 2.264263652789313, 2.263477141414878, 2.274483897284404, 2.237919645141691, 2.25214320726232, 2.270523543169758]\n",
            "Elapsed time training MI for Linear4: 1504.7612376213074\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  95\n",
            "Beta -  1\n",
            "Delta X:  0.5168879858212181\n",
            "Delta Y:  0.007482656029495605\n",
            "\n",
            "Mean MI X for last 10 [4.99447777937216, -8.027864629525874, 5.295982011854013, 5.281238610810562, 5.2041032812488615, 5.2660485335758755, 5.057770732623427, 4.91274465985898, 4.917425729826824, 4.4005377440056055]\n",
            "Mean MI Y for last 10 [2.272001989360557, 2.276063652689269, 2.281431389642931, 2.264263652789313, 2.263477141414878, 2.274483897284404, 2.237919645141691, 2.25214320726232, 2.270523543169758, 2.2780061991992535]\n",
            "Elapsed time training MI for Linear4: 1520.1588416099548\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  96\n",
            "Beta -  1\n",
            "Delta X:  0.8891937704737005\n",
            "Delta Y:  0.0015922886476333886\n",
            "\n",
            "Mean MI X for last 10 [-8.027864629525874, 5.295982011854013, 5.281238610810562, 5.2041032812488615, 5.2660485335758755, 5.057770732623427, 4.91274465985898, 4.917425729826824, 4.4005377440056055, 5.289731514479306]\n",
            "Mean MI Y for last 10 [2.276063652689269, 2.281431389642931, 2.264263652789313, 2.263477141414878, 2.274483897284404, 2.237919645141691, 2.25214320726232, 2.270523543169758, 2.2780061991992535, 2.279598487846887]\n",
            "Elapsed time training MI for Linear4: 1535.459656238556\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  97\n",
            "Beta -  1\n",
            "Delta X:  0.8638872363165753\n",
            "Delta Y:  0.020532009189825118\n",
            "\n",
            "Mean MI X for last 10 [5.295982011854013, 5.281238610810562, 5.2041032812488615, 5.2660485335758755, 5.057770732623427, 4.91274465985898, 4.917425729826824, 4.4005377440056055, 5.289731514479306, 4.425844278162731]\n",
            "Mean MI Y for last 10 [2.281431389642931, 2.264263652789313, 2.263477141414878, 2.274483897284404, 2.237919645141691, 2.25214320726232, 2.270523543169758, 2.2780061991992535, 2.279598487846887, 2.259066478657062]\n",
            "Elapsed time training MI for Linear4: 1551.2787880897522\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  98\n",
            "Beta -  1\n",
            "Delta X:  0.6669613565209067\n",
            "Delta Y:  0.021863508071980675\n",
            "\n",
            "Mean MI X for last 10 [5.281238610810562, 5.2041032812488615, 5.2660485335758755, 5.057770732623427, 4.91274465985898, 4.917425729826824, 4.4005377440056055, 5.289731514479306, 4.425844278162731, 5.0928056346836375]\n",
            "Mean MI Y for last 10 [2.264263652789313, 2.263477141414878, 2.274483897284404, 2.237919645141691, 2.25214320726232, 2.270523543169758, 2.2780061991992535, 2.279598487846887, 2.259066478657062, 2.2809299867290425]\n",
            "Elapsed time training MI for Linear4: 1566.891838312149\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  99\n",
            "Beta -  1\n",
            "Delta X:  0.9186185039182719\n",
            "Delta Y:  0.004910261646262626\n",
            "\n",
            "Mean MI X for last 10 [5.2041032812488615, 5.2660485335758755, 5.057770732623427, 4.91274465985898, 4.917425729826824, 4.4005377440056055, 5.289731514479306, 4.425844278162731, 5.0928056346836375, 4.1741871307653655]\n",
            "Mean MI Y for last 10 [2.263477141414878, 2.274483897284404, 2.237919645141691, 2.25214320726232, 2.270523543169758, 2.2780061991992535, 2.279598487846887, 2.259066478657062, 2.2809299867290425, 2.285840248375305]\n",
            "Elapsed time training MI for Linear4: 1582.4853525161743\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  100\n",
            "Beta -  1\n",
            "Delta X:  1.2039423232902093\n",
            "Delta Y:  0.019459462114997272\n",
            "\n",
            "Mean MI X for last 10 [5.2660485335758755, 5.057770732623427, 4.91274465985898, 4.917425729826824, 4.4005377440056055, 5.289731514479306, 4.425844278162731, 5.0928056346836375, 4.1741871307653655, 5.378129454055575]\n",
            "Mean MI Y for last 10 [2.274483897284404, 2.237919645141691, 2.25214320726232, 2.270523543169758, 2.2780061991992535, 2.279598487846887, 2.259066478657062, 2.2809299867290425, 2.285840248375305, 2.266380786260308]\n",
            "Elapsed time training MI for Linear4: 1598.0267701148987\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  101\n",
            "Beta -  1\n",
            "Delta X:  0.5215149098622014\n",
            "Delta Y:  0.030247614709045134\n",
            "\n",
            "Mean MI X for last 10 [5.057770732623427, 4.91274465985898, 4.917425729826824, 4.4005377440056055, 5.289731514479306, 4.425844278162731, 5.0928056346836375, 4.1741871307653655, 5.378129454055575, 4.8566145441933735]\n",
            "Mean MI Y for last 10 [2.237919645141691, 2.25214320726232, 2.270523543169758, 2.2780061991992535, 2.279598487846887, 2.259066478657062, 2.2809299867290425, 2.285840248375305, 2.266380786260308, 2.296628400969353]\n",
            "Elapsed time training MI for Linear4: 1613.6183547973633\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  102\n",
            "Beta -  1\n",
            "Delta X:  0.9786956330606422\n",
            "Delta Y:  0.03697068986099694\n",
            "\n",
            "Mean MI X for last 10 [4.91274465985898, 4.917425729826824, 4.4005377440056055, 5.289731514479306, 4.425844278162731, 5.0928056346836375, 4.1741871307653655, 5.378129454055575, 4.8566145441933735, 3.8779189111327312]\n",
            "Mean MI Y for last 10 [2.25214320726232, 2.270523543169758, 2.2780061991992535, 2.279598487846887, 2.259066478657062, 2.2809299867290425, 2.285840248375305, 2.266380786260308, 2.296628400969353, 2.259657711108356]\n",
            "Elapsed time training MI for Linear4: 1629.2983734607697\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  103\n",
            "Beta -  1\n",
            "Delta X:  1.4800175118293843\n",
            "Delta Y:  0.015728953677708102\n",
            "\n",
            "Mean MI X for last 10 [4.917425729826824, 4.4005377440056055, 5.289731514479306, 4.425844278162731, 5.0928056346836375, 4.1741871307653655, 5.378129454055575, 4.8566145441933735, 3.8779189111327312, 5.357936422962116]\n",
            "Mean MI Y for last 10 [2.270523543169758, 2.2780061991992535, 2.279598487846887, 2.259066478657062, 2.2809299867290425, 2.285840248375305, 2.266380786260308, 2.296628400969353, 2.259657711108356, 2.275386664786064]\n",
            "Elapsed time training MI for Linear4: 1645.3539006710052\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  104\n",
            "Beta -  1\n",
            "Delta X:  0.11243809769148516\n",
            "Delta Y:  0.004962940714252184\n",
            "\n",
            "Mean MI X for last 10 [4.4005377440056055, 5.289731514479306, 4.425844278162731, 5.0928056346836375, 4.1741871307653655, 5.378129454055575, 4.8566145441933735, 3.8779189111327312, 5.357936422962116, 5.24549832527063]\n",
            "Mean MI Y for last 10 [2.2780061991992535, 2.279598487846887, 2.259066478657062, 2.2809299867290425, 2.285840248375305, 2.266380786260308, 2.296628400969353, 2.259657711108356, 2.275386664786064, 2.270423724071812]\n",
            "Elapsed time training MI for Linear4: 1661.024565935135\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  105\n",
            "Beta -  1\n",
            "Delta X:  0.4133972310816558\n",
            "Delta Y:  0.02252515254498544\n",
            "\n",
            "Mean MI X for last 10 [5.289731514479306, 4.425844278162731, 5.0928056346836375, 4.1741871307653655, 5.378129454055575, 4.8566145441933735, 3.8779189111327312, 5.357936422962116, 5.24549832527063, 5.658895556352286]\n",
            "Mean MI Y for last 10 [2.279598487846887, 2.259066478657062, 2.2809299867290425, 2.285840248375305, 2.266380786260308, 2.296628400969353, 2.259657711108356, 2.275386664786064, 2.270423724071812, 2.2478985715268265]\n",
            "Elapsed time training MI for Linear4: 1676.6793851852417\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  106\n",
            "Beta -  1\n",
            "Delta X:  1.5929098721506252\n",
            "Delta Y:  0.03034990060049836\n",
            "\n",
            "Mean MI X for last 10 [4.425844278162731, 5.0928056346836375, 4.1741871307653655, 5.378129454055575, 4.8566145441933735, 3.8779189111327312, 5.357936422962116, 5.24549832527063, 5.658895556352286, 4.065985684201661]\n",
            "Mean MI Y for last 10 [2.259066478657062, 2.2809299867290425, 2.285840248375305, 2.266380786260308, 2.296628400969353, 2.259657711108356, 2.275386664786064, 2.270423724071812, 2.2478985715268265, 2.278248472127325]\n",
            "Elapsed time training MI for Linear4: 1692.1823589801788\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  107\n",
            "Beta -  1\n",
            "Delta X:  1.389553295269704\n",
            "Delta Y:  0.01752485636709089\n",
            "\n",
            "Mean MI X for last 10 [5.0928056346836375, 4.1741871307653655, 5.378129454055575, 4.8566145441933735, 3.8779189111327312, 5.357936422962116, 5.24549832527063, 5.658895556352286, 4.065985684201661, 5.455538979471365]\n",
            "Mean MI Y for last 10 [2.2809299867290425, 2.285840248375305, 2.266380786260308, 2.296628400969353, 2.259657711108356, 2.275386664786064, 2.270423724071812, 2.2478985715268265, 2.278248472127325, 2.2957733284944157]\n",
            "Elapsed time training MI for Linear4: 1707.8223297595978\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  108\n",
            "Beta -  1\n",
            "Delta X:  0.23657412849255444\n",
            "Delta Y:  0.02139344525489717\n",
            "\n",
            "Mean MI X for last 10 [4.1741871307653655, 5.378129454055575, 4.8566145441933735, 3.8779189111327312, 5.357936422962116, 5.24549832527063, 5.658895556352286, 4.065985684201661, 5.455538979471365, 5.218964850978811]\n",
            "Mean MI Y for last 10 [2.285840248375305, 2.266380786260308, 2.296628400969353, 2.259657711108356, 2.275386664786064, 2.270423724071812, 2.2478985715268265, 2.278248472127325, 2.2957733284944157, 2.2743798832395186]\n",
            "Elapsed time training MI for Linear4: 1723.399772644043\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  109\n",
            "Beta -  1\n",
            "Delta X:  0.07255613676774697\n",
            "Delta Y:  0.0038728548773820926\n",
            "\n",
            "Mean MI X for last 10 [5.378129454055575, 4.8566145441933735, 3.8779189111327312, 5.357936422962116, 5.24549832527063, 5.658895556352286, 4.065985684201661, 5.455538979471365, 5.218964850978811, 5.291520987746558]\n",
            "Mean MI Y for last 10 [2.266380786260308, 2.296628400969353, 2.259657711108356, 2.275386664786064, 2.270423724071812, 2.2478985715268265, 2.278248472127325, 2.2957733284944157, 2.2743798832395186, 2.2782527381169007]\n",
            "Elapsed time training MI for Linear4: 1738.8692729473114\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  110\n",
            "Beta -  1\n",
            "Delta X:  50.45741981356891\n",
            "Delta Y:  0.00971870521492546\n",
            "\n",
            "Mean MI X for last 10 [4.8566145441933735, 3.8779189111327312, 5.357936422962116, 5.24549832527063, 5.658895556352286, 4.065985684201661, 5.455538979471365, 5.218964850978811, 5.291520987746558, -45.16589882582235]\n",
            "Mean MI Y for last 10 [2.296628400969353, 2.259657711108356, 2.275386664786064, 2.270423724071812, 2.2478985715268265, 2.278248472127325, 2.2957733284944157, 2.2743798832395186, 2.2782527381169007, 2.287971443331826]\n",
            "Elapsed time training MI for Linear4: 1754.7539076805115\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  111\n",
            "Beta -  1\n",
            "Delta X:  50.42494302365317\n",
            "Delta Y:  0.003125139899345264\n",
            "\n",
            "Mean MI X for last 10 [3.8779189111327312, 5.357936422962116, 5.24549832527063, 5.658895556352286, 4.065985684201661, 5.455538979471365, 5.218964850978811, 5.291520987746558, -45.16589882582235, 5.259044197830819]\n",
            "Mean MI Y for last 10 [2.259657711108356, 2.275386664786064, 2.270423724071812, 2.2478985715268265, 2.278248472127325, 2.2957733284944157, 2.2743798832395186, 2.2782527381169007, 2.287971443331826, 2.284846303432481]\n",
            "Elapsed time training MI for Linear4: 1770.5743253231049\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  112\n",
            "Beta -  1\n",
            "Delta X:  14.453595970485257\n",
            "Delta Y:  0.02443534186653995\n",
            "\n",
            "Mean MI X for last 10 [5.357936422962116, 5.24549832527063, 5.658895556352286, 4.065985684201661, 5.455538979471365, 5.218964850978811, 5.291520987746558, -45.16589882582235, 5.259044197830819, -9.194551772654437]\n",
            "Mean MI Y for last 10 [2.275386664786064, 2.270423724071812, 2.2478985715268265, 2.278248472127325, 2.2957733284944157, 2.2743798832395186, 2.2782527381169007, 2.287971443331826, 2.284846303432481, 2.260410961565941]\n",
            "Elapsed time training MI for Linear4: 1786.2859930992126\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  113\n",
            "Beta -  1\n",
            "Delta X:  14.561498095485955\n",
            "Delta Y:  0.021365420523483003\n",
            "\n",
            "Mean MI X for last 10 [5.24549832527063, 5.658895556352286, 4.065985684201661, 5.455538979471365, 5.218964850978811, 5.291520987746558, -45.16589882582235, 5.259044197830819, -9.194551772654437, 5.3669463228315175]\n",
            "Mean MI Y for last 10 [2.270423724071812, 2.2478985715268265, 2.278248472127325, 2.2957733284944157, 2.2743798832395186, 2.2782527381169007, 2.287971443331826, 2.284846303432481, 2.260410961565941, 2.281776382089424]\n",
            "Elapsed time training MI for Linear4: 1801.8925514221191\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  114\n",
            "Beta -  1\n",
            "Delta X:  0.112753769227945\n",
            "Delta Y:  0.018624457850385134\n",
            "\n",
            "Mean MI X for last 10 [5.658895556352286, 4.065985684201661, 5.455538979471365, 5.218964850978811, 5.291520987746558, -45.16589882582235, 5.259044197830819, -9.194551772654437, 5.3669463228315175, 5.4797000920594625]\n",
            "Mean MI Y for last 10 [2.2478985715268265, 2.278248472127325, 2.2957733284944157, 2.2743798832395186, 2.2782527381169007, 2.287971443331826, 2.284846303432481, 2.260410961565941, 2.281776382089424, 2.2631519242390388]\n",
            "Elapsed time training MI for Linear4: 1817.6008319854736\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  115\n",
            "Beta -  1\n",
            "Delta X:  1.2445128505418035\n",
            "Delta Y:  0.03221400854175771\n",
            "\n",
            "Mean MI X for last 10 [4.065985684201661, 5.455538979471365, 5.218964850978811, 5.291520987746558, -45.16589882582235, 5.259044197830819, -9.194551772654437, 5.3669463228315175, 5.4797000920594625, 4.235187241517659]\n",
            "Mean MI Y for last 10 [2.278248472127325, 2.2957733284944157, 2.2743798832395186, 2.2782527381169007, 2.287971443331826, 2.284846303432481, 2.260410961565941, 2.281776382089424, 2.2631519242390388, 2.2953659327807965]\n",
            "Elapsed time training MI for Linear4: 1833.1818499565125\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  116\n",
            "Beta -  1\n",
            "Delta X:  1.3912347557702294\n",
            "Delta Y:  0.03156153911720727\n",
            "\n",
            "Mean MI X for last 10 [5.455538979471365, 5.218964850978811, 5.291520987746558, -45.16589882582235, 5.259044197830819, -9.194551772654437, 5.3669463228315175, 5.4797000920594625, 4.235187241517659, 5.626421997287888]\n",
            "Mean MI Y for last 10 [2.2957733284944157, 2.2743798832395186, 2.2782527381169007, 2.287971443331826, 2.284846303432481, 2.260410961565941, 2.281776382089424, 2.2631519242390388, 2.2953659327807965, 2.263804393663589]\n",
            "Elapsed time training MI for Linear4: 1848.9140026569366\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  117\n",
            "Beta -  1\n",
            "Delta X:  0.7285251289542547\n",
            "Delta Y:  0.010714934451748093\n",
            "\n",
            "Mean MI X for last 10 [5.218964850978811, 5.291520987746558, -45.16589882582235, 5.259044197830819, -9.194551772654437, 5.3669463228315175, 5.4797000920594625, 4.235187241517659, 5.626421997287888, 4.897896868333634]\n",
            "Mean MI Y for last 10 [2.2743798832395186, 2.2782527381169007, 2.287971443331826, 2.284846303432481, 2.260410961565941, 2.281776382089424, 2.2631519242390388, 2.2953659327807965, 2.263804393663589, 2.2745193281153373]\n",
            "Elapsed time training MI for Linear4: 1864.622481584549\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  118\n",
            "Beta -  1\n",
            "Delta X:  0.22551109033352734\n",
            "Delta Y:  0.2343017777908587\n",
            "\n",
            "Mean MI X for last 10 [5.291520987746558, -45.16589882582235, 5.259044197830819, -9.194551772654437, 5.3669463228315175, 5.4797000920594625, 4.235187241517659, 5.626421997287888, 4.897896868333634, 5.123407958667161]\n",
            "Mean MI Y for last 10 [2.2782527381169007, 2.287971443331826, 2.284846303432481, 2.260410961565941, 2.281776382089424, 2.2631519242390388, 2.2953659327807965, 2.263804393663589, 2.2745193281153373, 2.0402175503244786]\n",
            "Elapsed time training MI for Linear4: 1880.2903237342834\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  119\n",
            "Beta -  1\n",
            "Delta X:  0.6907984503805\n",
            "Delta Y:  0.23667963455989183\n",
            "\n",
            "Mean MI X for last 10 [-45.16589882582235, 5.259044197830819, -9.194551772654437, 5.3669463228315175, 5.4797000920594625, 4.235187241517659, 5.626421997287888, 4.897896868333634, 5.123407958667161, 4.432609508286661]\n",
            "Mean MI Y for last 10 [2.287971443331826, 2.284846303432481, 2.260410961565941, 2.281776382089424, 2.2631519242390388, 2.2953659327807965, 2.263804393663589, 2.2745193281153373, 2.0402175503244786, 2.2768971848843704]\n",
            "Elapsed time training MI for Linear4: 1895.8722367286682\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  120\n",
            "Beta -  1\n",
            "Delta X:  1.3647834972532067\n",
            "Delta Y:  0.009783163380775672\n",
            "\n",
            "Mean MI X for last 10 [5.259044197830819, -9.194551772654437, 5.3669463228315175, 5.4797000920594625, 4.235187241517659, 5.626421997287888, 4.897896868333634, 5.123407958667161, 4.432609508286661, 5.797393005539868]\n",
            "Mean MI Y for last 10 [2.284846303432481, 2.260410961565941, 2.281776382089424, 2.2631519242390388, 2.2953659327807965, 2.263804393663589, 2.2745193281153373, 2.0402175503244786, 2.2768971848843704, 2.2671140215035948]\n",
            "Elapsed time training MI for Linear4: 1911.775969028473\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  121\n",
            "Beta -  1\n",
            "Delta X:  1.2063318407103454\n",
            "Delta Y:  0.002486344466585688\n",
            "\n",
            "Mean MI X for last 10 [-9.194551772654437, 5.3669463228315175, 5.4797000920594625, 4.235187241517659, 5.626421997287888, 4.897896868333634, 5.123407958667161, 4.432609508286661, 5.797393005539868, 4.591061164829522]\n",
            "Mean MI Y for last 10 [2.260410961565941, 2.281776382089424, 2.2631519242390388, 2.2953659327807965, 2.263804393663589, 2.2745193281153373, 2.0402175503244786, 2.2768971848843704, 2.2671140215035948, 2.2696003659701804]\n",
            "Elapsed time training MI for Linear4: 1927.4660902023315\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  122\n",
            "Beta -  1\n",
            "Delta X:  1.0262827194575816\n",
            "Delta Y:  0.004067595833654458\n",
            "\n",
            "Mean MI X for last 10 [5.3669463228315175, 5.4797000920594625, 4.235187241517659, 5.626421997287888, 4.897896868333634, 5.123407958667161, 4.432609508286661, 5.797393005539868, 4.591061164829522, 5.617343884287104]\n",
            "Mean MI Y for last 10 [2.281776382089424, 2.2631519242390388, 2.2953659327807965, 2.263804393663589, 2.2745193281153373, 2.0402175503244786, 2.2768971848843704, 2.2671140215035948, 2.2696003659701804, 2.273667961803835]\n",
            "Elapsed time training MI for Linear4: 1943.0202124118805\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  123\n",
            "Beta -  1\n",
            "Delta X:  1.1521044822135709\n",
            "Delta Y:  0.005049372659817308\n",
            "\n",
            "Mean MI X for last 10 [5.4797000920594625, 4.235187241517659, 5.626421997287888, 4.897896868333634, 5.123407958667161, 4.432609508286661, 5.797393005539868, 4.591061164829522, 5.617343884287104, 4.465239402073533]\n",
            "Mean MI Y for last 10 [2.2631519242390388, 2.2953659327807965, 2.263804393663589, 2.2745193281153373, 2.0402175503244786, 2.2768971848843704, 2.2671140215035948, 2.2696003659701804, 2.273667961803835, 2.2686185891440176]\n",
            "Elapsed time training MI for Linear4: 1958.688172340393\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  124\n",
            "Beta -  1\n",
            "Delta X:  0.19634726510119016\n",
            "Delta Y:  0.008588451693561261\n",
            "\n",
            "Mean MI X for last 10 [4.235187241517659, 5.626421997287888, 4.897896868333634, 5.123407958667161, 4.432609508286661, 5.797393005539868, 4.591061164829522, 5.617343884287104, 4.465239402073533, 4.661586667174723]\n",
            "Mean MI Y for last 10 [2.2953659327807965, 2.263804393663589, 2.2745193281153373, 2.0402175503244786, 2.2768971848843704, 2.2671140215035948, 2.2696003659701804, 2.273667961803835, 2.2686185891440176, 2.277207040837579]\n",
            "Elapsed time training MI for Linear4: 1974.3485314846039\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  125\n",
            "Beta -  1\n",
            "Delta X:  0.5655205570050139\n",
            "Delta Y:  0.0023190507502444113\n",
            "\n",
            "Mean MI X for last 10 [5.626421997287888, 4.897896868333634, 5.123407958667161, 4.432609508286661, 5.797393005539868, 4.591061164829522, 5.617343884287104, 4.465239402073533, 4.661586667174723, 5.227107224179737]\n",
            "Mean MI Y for last 10 [2.263804393663589, 2.2745193281153373, 2.0402175503244786, 2.2768971848843704, 2.2671140215035948, 2.2696003659701804, 2.273667961803835, 2.2686185891440176, 2.277207040837579, 2.2748879900873344]\n",
            "Elapsed time training MI for Linear4: 1989.9621176719666\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  126\n",
            "Beta -  1\n",
            "Delta X:  0.012930617657805676\n",
            "Delta Y:  0.005587571338295572\n",
            "\n",
            "Mean MI X for last 10 [4.897896868333634, 5.123407958667161, 4.432609508286661, 5.797393005539868, 4.591061164829522, 5.617343884287104, 4.465239402073533, 4.661586667174723, 5.227107224179737, 5.2141766065219315]\n",
            "Mean MI Y for last 10 [2.2745193281153373, 2.0402175503244786, 2.2768971848843704, 2.2671140215035948, 2.2696003659701804, 2.273667961803835, 2.2686185891440176, 2.277207040837579, 2.2748879900873344, 2.28047556142563]\n",
            "Elapsed time training MI for Linear4: 2005.6396124362946\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  127\n",
            "Beta -  1\n",
            "Delta X:  0.5763384739218997\n",
            "Delta Y:  0.0020387448481660186\n",
            "\n",
            "Mean MI X for last 10 [5.123407958667161, 4.432609508286661, 5.797393005539868, 4.591061164829522, 5.617343884287104, 4.465239402073533, 4.661586667174723, 5.227107224179737, 5.2141766065219315, 5.790515080443831]\n",
            "Mean MI Y for last 10 [2.0402175503244786, 2.2768971848843704, 2.2671140215035948, 2.2696003659701804, 2.273667961803835, 2.2686185891440176, 2.277207040837579, 2.2748879900873344, 2.28047556142563, 2.282514306273796]\n",
            "Elapsed time training MI for Linear4: 2021.2230772972107\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  128\n",
            "Beta -  1\n",
            "Delta X:  0.8396164875294856\n",
            "Delta Y:  0.003815302462466086\n",
            "\n",
            "Mean MI X for last 10 [4.432609508286661, 5.797393005539868, 4.591061164829522, 5.617343884287104, 4.465239402073533, 4.661586667174723, 5.227107224179737, 5.2141766065219315, 5.790515080443831, 4.950898592914346]\n",
            "Mean MI Y for last 10 [2.2768971848843704, 2.2671140215035948, 2.2696003659701804, 2.273667961803835, 2.2686185891440176, 2.277207040837579, 2.2748879900873344, 2.28047556142563, 2.282514306273796, 2.27869900381133]\n",
            "Elapsed time training MI for Linear4: 2037.0921716690063\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  129\n",
            "Beta -  1\n",
            "Delta X:  0.3708670322320611\n",
            "Delta Y:  0.004420707347804864\n",
            "\n",
            "Mean MI X for last 10 [5.797393005539868, 4.591061164829522, 5.617343884287104, 4.465239402073533, 4.661586667174723, 5.227107224179737, 5.2141766065219315, 5.790515080443831, 4.950898592914346, 5.321765625146407]\n",
            "Mean MI Y for last 10 [2.2671140215035948, 2.2696003659701804, 2.273667961803835, 2.2686185891440176, 2.277207040837579, 2.2748879900873344, 2.28047556142563, 2.282514306273796, 2.27869900381133, 2.283119711159135]\n",
            "Elapsed time training MI for Linear4: 2052.754005908966\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  130\n",
            "Beta -  1\n",
            "Delta X:  567.7223671506971\n",
            "Delta Y:  0.01021668410250376\n",
            "\n",
            "Mean MI X for last 10 [4.591061164829522, 5.617343884287104, 4.465239402073533, 4.661586667174723, 5.227107224179737, 5.2141766065219315, 5.790515080443831, 4.950898592914346, 5.321765625146407, -562.4006015255507]\n",
            "Mean MI Y for last 10 [2.2696003659701804, 2.273667961803835, 2.2686185891440176, 2.277207040837579, 2.2748879900873344, 2.28047556142563, 2.282514306273796, 2.27869900381133, 2.283119711159135, 2.272903027056631]\n",
            "Elapsed time training MI for Linear4: 2068.647184610367\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  131\n",
            "Beta -  1\n",
            "Delta X:  567.9196805763346\n",
            "Delta Y:  0.014211546256343688\n",
            "\n",
            "Mean MI X for last 10 [5.617343884287104, 4.465239402073533, 4.661586667174723, 5.227107224179737, 5.2141766065219315, 5.790515080443831, 4.950898592914346, 5.321765625146407, -562.4006015255507, 5.519079050783918]\n",
            "Mean MI Y for last 10 [2.273667961803835, 2.2686185891440176, 2.277207040837579, 2.2748879900873344, 2.28047556142563, 2.282514306273796, 2.27869900381133, 2.283119711159135, 2.272903027056631, 2.2871145733129747]\n",
            "Elapsed time training MI for Linear4: 2084.5050599575043\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  132\n",
            "Beta -  1\n",
            "Delta X:  0.015495468050177763\n",
            "Delta Y:  0.015721472595800368\n",
            "\n",
            "Mean MI X for last 10 [4.465239402073533, 4.661586667174723, 5.227107224179737, 5.2141766065219315, 5.790515080443831, 4.950898592914346, 5.321765625146407, -562.4006015255507, 5.519079050783918, 5.534574518834096]\n",
            "Mean MI Y for last 10 [2.2686185891440176, 2.277207040837579, 2.2748879900873344, 2.28047556142563, 2.282514306273796, 2.27869900381133, 2.283119711159135, 2.272903027056631, 2.2871145733129747, 2.2713931007171744]\n",
            "Elapsed time training MI for Linear4: 2100.498525619507\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  133\n",
            "Beta -  1\n",
            "Delta X:  0.1791502133107139\n",
            "Delta Y:  0.009295550363658478\n",
            "\n",
            "Mean MI X for last 10 [4.661586667174723, 5.227107224179737, 5.2141766065219315, 5.790515080443831, 4.950898592914346, 5.321765625146407, -562.4006015255507, 5.519079050783918, 5.534574518834096, 5.355424305523382]\n",
            "Mean MI Y for last 10 [2.277207040837579, 2.2748879900873344, 2.28047556142563, 2.282514306273796, 2.27869900381133, 2.283119711159135, 2.272903027056631, 2.2871145733129747, 2.2713931007171744, 2.262097550353516]\n",
            "Elapsed time training MI for Linear4: 2116.2428278923035\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  134\n",
            "Beta -  1\n",
            "Delta X:  0.34121343703158047\n",
            "Delta Y:  0.013826999074614488\n",
            "\n",
            "Mean MI X for last 10 [5.227107224179737, 5.2141766065219315, 5.790515080443831, 4.950898592914346, 5.321765625146407, -562.4006015255507, 5.519079050783918, 5.534574518834096, 5.355424305523382, 5.014210868491801]\n",
            "Mean MI Y for last 10 [2.2748879900873344, 2.28047556142563, 2.282514306273796, 2.27869900381133, 2.283119711159135, 2.272903027056631, 2.2871145733129747, 2.2713931007171744, 2.262097550353516, 2.2759245494281304]\n",
            "Elapsed time training MI for Linear4: 2132.0245974063873\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  135\n",
            "Beta -  1\n",
            "Delta X:  1.6993233290816678\n",
            "Delta Y:  0.014356837216725093\n",
            "\n",
            "Mean MI X for last 10 [5.2141766065219315, 5.790515080443831, 4.950898592914346, 5.321765625146407, -562.4006015255507, 5.519079050783918, 5.534574518834096, 5.355424305523382, 5.014210868491801, 3.3148875394101336]\n",
            "Mean MI Y for last 10 [2.28047556142563, 2.282514306273796, 2.27869900381133, 2.283119711159135, 2.272903027056631, 2.2871145733129747, 2.2713931007171744, 2.262097550353516, 2.2759245494281304, 2.2902813866448555]\n",
            "Elapsed time training MI for Linear4: 2147.8499088287354\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  136\n",
            "Beta -  1\n",
            "Delta X:  1.6893699504673356\n",
            "Delta Y:  0.02329794252350892\n",
            "\n",
            "Mean MI X for last 10 [5.790515080443831, 4.950898592914346, 5.321765625146407, -562.4006015255507, 5.519079050783918, 5.534574518834096, 5.355424305523382, 5.014210868491801, 3.3148875394101336, 5.004257489877469]\n",
            "Mean MI Y for last 10 [2.282514306273796, 2.27869900381133, 2.283119711159135, 2.272903027056631, 2.2871145733129747, 2.2713931007171744, 2.262097550353516, 2.2759245494281304, 2.2902813866448555, 2.2669834441213466]\n",
            "Elapsed time training MI for Linear4: 2163.9740805625916\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  137\n",
            "Beta -  1\n",
            "Delta X:  3.5453894903410728\n",
            "Delta Y:  0.007172417157748523\n",
            "\n",
            "Mean MI X for last 10 [4.950898592914346, 5.321765625146407, -562.4006015255507, 5.519079050783918, 5.534574518834096, 5.355424305523382, 5.014210868491801, 3.3148875394101336, 5.004257489877469, 1.4588679995363965]\n",
            "Mean MI Y for last 10 [2.27869900381133, 2.283119711159135, 2.272903027056631, 2.2871145733129747, 2.2713931007171744, 2.262097550353516, 2.2759245494281304, 2.2902813866448555, 2.2669834441213466, 2.259811026963598]\n",
            "Elapsed time training MI for Linear4: 2179.7989134788513\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  138\n",
            "Beta -  1\n",
            "Delta X:  4.136422692585602\n",
            "Delta Y:  0.045072978493501115\n",
            "\n",
            "Mean MI X for last 10 [5.321765625146407, -562.4006015255507, 5.519079050783918, 5.534574518834096, 5.355424305523382, 5.014210868491801, 3.3148875394101336, 5.004257489877469, 1.4588679995363965, 5.595290692121998]\n",
            "Mean MI Y for last 10 [2.283119711159135, 2.272903027056631, 2.2871145733129747, 2.2713931007171744, 2.262097550353516, 2.2759245494281304, 2.2902813866448555, 2.2669834441213466, 2.259811026963598, 2.304884005457099]\n",
            "Elapsed time training MI for Linear4: 2195.468187570572\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  139\n",
            "Beta -  1\n",
            "Delta X:  0.05277702167852638\n",
            "Delta Y:  0.04552916969571763\n",
            "\n",
            "Mean MI X for last 10 [-562.4006015255507, 5.519079050783918, 5.534574518834096, 5.355424305523382, 5.014210868491801, 3.3148875394101336, 5.004257489877469, 1.4588679995363965, 5.595290692121998, 5.542513670443472]\n",
            "Mean MI Y for last 10 [2.272903027056631, 2.2871145733129747, 2.2713931007171744, 2.262097550353516, 2.2759245494281304, 2.2902813866448555, 2.2669834441213466, 2.259811026963598, 2.304884005457099, 2.2593548357613815]\n",
            "Elapsed time training MI for Linear4: 2211.3778190612793\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  140\n",
            "Beta -  1\n",
            "Delta X:  0.3241022642233222\n",
            "Delta Y:  0.023523994981606844\n",
            "\n",
            "Mean MI X for last 10 [5.519079050783918, 5.534574518834096, 5.355424305523382, 5.014210868491801, 3.3148875394101336, 5.004257489877469, 1.4588679995363965, 5.595290692121998, 5.542513670443472, 5.866615934666794]\n",
            "Mean MI Y for last 10 [2.2871145733129747, 2.2713931007171744, 2.262097550353516, 2.2759245494281304, 2.2902813866448555, 2.2669834441213466, 2.259811026963598, 2.304884005457099, 2.2593548357613815, 2.2828788307429884]\n",
            "Elapsed time training MI for Linear4: 2227.3465535640717\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  141\n",
            "Beta -  1\n",
            "Delta X:  0.3106097913245911\n",
            "Delta Y:  0.17171321482038193\n",
            "\n",
            "Mean MI X for last 10 [5.534574518834096, 5.355424305523382, 5.014210868491801, 3.3148875394101336, 5.004257489877469, 1.4588679995363965, 5.595290692121998, 5.542513670443472, 5.866615934666794, 5.556006143342203]\n",
            "Mean MI Y for last 10 [2.2713931007171744, 2.262097550353516, 2.2759245494281304, 2.2902813866448555, 2.2669834441213466, 2.259811026963598, 2.304884005457099, 2.2593548357613815, 2.2828788307429884, 2.1111656159226064]\n",
            "Elapsed time training MI for Linear4: 2243.0435123443604\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  142\n",
            "Beta -  1\n",
            "Delta X:  0.9715566045439825\n",
            "Delta Y:  0.166367301046213\n",
            "\n",
            "Mean MI X for last 10 [5.355424305523382, 5.014210868491801, 3.3148875394101336, 5.004257489877469, 1.4588679995363965, 5.595290692121998, 5.542513670443472, 5.866615934666794, 5.556006143342203, 4.5844495387982205]\n",
            "Mean MI Y for last 10 [2.262097550353516, 2.2759245494281304, 2.2902813866448555, 2.2669834441213466, 2.259811026963598, 2.304884005457099, 2.2593548357613815, 2.2828788307429884, 2.1111656159226064, 2.2775329169688194]\n",
            "Elapsed time training MI for Linear4: 2258.774426460266\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  143\n",
            "Beta -  1\n",
            "Delta X:  0.6985934319526654\n",
            "Delta Y:  0.00031040891655464975\n",
            "\n",
            "Mean MI X for last 10 [5.014210868491801, 3.3148875394101336, 5.004257489877469, 1.4588679995363965, 5.595290692121998, 5.542513670443472, 5.866615934666794, 5.556006143342203, 4.5844495387982205, 5.283042970750886]\n",
            "Mean MI Y for last 10 [2.2759245494281304, 2.2902813866448555, 2.2669834441213466, 2.259811026963598, 2.304884005457099, 2.2593548357613815, 2.2828788307429884, 2.1111656159226064, 2.2775329169688194, 2.277843325885374]\n",
            "Elapsed time training MI for Linear4: 2274.6696445941925\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  144\n",
            "Beta -  1\n",
            "Delta X:  0.3490118683019938\n",
            "Delta Y:  0.017169699485876322\n",
            "\n",
            "Mean MI X for last 10 [3.3148875394101336, 5.004257489877469, 1.4588679995363965, 5.595290692121998, 5.542513670443472, 5.866615934666794, 5.556006143342203, 4.5844495387982205, 5.283042970750886, 5.63205483905288]\n",
            "Mean MI Y for last 10 [2.2902813866448555, 2.2669834441213466, 2.259811026963598, 2.304884005457099, 2.2593548357613815, 2.2828788307429884, 2.1111656159226064, 2.2775329169688194, 2.277843325885374, 2.2950130253712504]\n",
            "Elapsed time training MI for Linear4: 2290.4535570144653\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  145\n",
            "Beta -  1\n",
            "Delta X:  0.2506929854594313\n",
            "Delta Y:  0.0222979280740212\n",
            "\n",
            "Mean MI X for last 10 [5.004257489877469, 1.4588679995363965, 5.595290692121998, 5.542513670443472, 5.866615934666794, 5.556006143342203, 4.5844495387982205, 5.283042970750886, 5.63205483905288, 5.381361853593448]\n",
            "Mean MI Y for last 10 [2.2669834441213466, 2.259811026963598, 2.304884005457099, 2.2593548357613815, 2.2828788307429884, 2.1111656159226064, 2.2775329169688194, 2.277843325885374, 2.2950130253712504, 2.272715097297229]\n",
            "Elapsed time training MI for Linear4: 2306.445677757263\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  146\n",
            "Beta -  1\n",
            "Delta X:  0.07030734705772534\n",
            "Delta Y:  0.00810646515156943\n",
            "\n",
            "Mean MI X for last 10 [1.4588679995363965, 5.595290692121998, 5.542513670443472, 5.866615934666794, 5.556006143342203, 4.5844495387982205, 5.283042970750886, 5.63205483905288, 5.381361853593448, 5.311054506535723]\n",
            "Mean MI Y for last 10 [2.259811026963598, 2.304884005457099, 2.2593548357613815, 2.2828788307429884, 2.1111656159226064, 2.2775329169688194, 2.277843325885374, 2.2950130253712504, 2.272715097297229, 2.2808215624487986]\n",
            "Elapsed time training MI for Linear4: 2322.1403379440308\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  147\n",
            "Beta -  1\n",
            "Delta X:  0.18022690576785116\n",
            "Delta Y:  0.018314157848927426\n",
            "\n",
            "Mean MI X for last 10 [5.595290692121998, 5.542513670443472, 5.866615934666794, 5.556006143342203, 4.5844495387982205, 5.283042970750886, 5.63205483905288, 5.381361853593448, 5.311054506535723, 5.130827600767872]\n",
            "Mean MI Y for last 10 [2.304884005457099, 2.2593548357613815, 2.2828788307429884, 2.1111656159226064, 2.2775329169688194, 2.277843325885374, 2.2950130253712504, 2.272715097297229, 2.2808215624487986, 2.299135720297726]\n",
            "Elapsed time training MI for Linear4: 2337.8374292850494\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  148\n",
            "Beta -  1\n",
            "Delta X:  0.009240549764653494\n",
            "Delta Y:  0.008671536247359057\n",
            "\n",
            "Mean MI X for last 10 [5.542513670443472, 5.866615934666794, 5.556006143342203, 4.5844495387982205, 5.283042970750886, 5.63205483905288, 5.381361853593448, 5.311054506535723, 5.130827600767872, 5.121587051003218]\n",
            "Mean MI Y for last 10 [2.2593548357613815, 2.2828788307429884, 2.1111656159226064, 2.2775329169688194, 2.277843325885374, 2.2950130253712504, 2.272715097297229, 2.2808215624487986, 2.299135720297726, 2.290464184050367]\n",
            "Elapsed time training MI for Linear4: 2353.419508457184\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  149\n",
            "Beta -  1\n",
            "Delta X:  0.13034197999470276\n",
            "Delta Y:  0.012316502996091216\n",
            "\n",
            "Mean MI X for last 10 [5.866615934666794, 5.556006143342203, 4.5844495387982205, 5.283042970750886, 5.63205483905288, 5.381361853593448, 5.311054506535723, 5.130827600767872, 5.121587051003218, 5.251929030997921]\n",
            "Mean MI Y for last 10 [2.2828788307429884, 2.1111656159226064, 2.2775329169688194, 2.277843325885374, 2.2950130253712504, 2.272715097297229, 2.2808215624487986, 2.299135720297726, 2.290464184050367, 2.278147681054276]\n",
            "Elapsed time training MI for Linear4: 2369.168478012085\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  150\n",
            "Beta -  1\n",
            "Delta X:  0.22552168852230636\n",
            "Delta Y:  0.01247443763940348\n",
            "\n",
            "Mean MI X for last 10 [5.556006143342203, 4.5844495387982205, 5.283042970750886, 5.63205483905288, 5.381361853593448, 5.311054506535723, 5.130827600767872, 5.121587051003218, 5.251929030997921, 5.4774507195202276]\n",
            "Mean MI Y for last 10 [2.1111656159226064, 2.2775329169688194, 2.277843325885374, 2.2950130253712504, 2.272715097297229, 2.2808215624487986, 2.299135720297726, 2.290464184050367, 2.278147681054276, 2.2906221186936793]\n",
            "Elapsed time training MI for Linear4: 2385.1693642139435\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  151\n",
            "Beta -  1\n",
            "Delta X:  1.6865921470402148\n",
            "Delta Y:  0.026778188087284605\n",
            "\n",
            "Mean MI X for last 10 [4.5844495387982205, 5.283042970750886, 5.63205483905288, 5.381361853593448, 5.311054506535723, 5.130827600767872, 5.121587051003218, 5.251929030997921, 5.4774507195202276, 3.790858572480013]\n",
            "Mean MI Y for last 10 [2.2775329169688194, 2.277843325885374, 2.2950130253712504, 2.272715097297229, 2.2808215624487986, 2.299135720297726, 2.290464184050367, 2.278147681054276, 2.2906221186936793, 2.2638439306063947]\n",
            "Elapsed time training MI for Linear4: 2400.9328730106354\n",
            "############################## \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-8d0a45dfe49b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0menc_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MLP'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0mMI_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMI_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_MI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mMI_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMI_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_MI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-8d0a45dfe49b>\u001b[0m in \u001b[0;36mtrain_MI\u001b[0;34m(encoder, beta, num_epochs, estimate_mi_on_train)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mmi_gradient_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmi_estimation_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmi_estimator_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mmi_gradient_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmi_gradient_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mmi_estimation_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmi_estimation_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-93422241d79d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# breakpoint()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Positive Samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mneg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Predictions for shuffled (negative) samples from p(z1)p(z2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#breakpoint()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFOs0siAkTKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b4b3680d-4741-4855-cd36-4f5ba55134d5"
      },
      "source": [
        "mi_df_plot = pd.read_csv('mi_mlp.csv', sep=' ', index_col=0)\n",
        "mi_df_plot[mi_df_plot < 0] = np.nan\n",
        "plt.plot(np.arange(len(mi_df_plot)), mi_df_plot['X'], label='I(X,Z)')\n",
        "plt.plot(np.arange(len(mi_df_plot)), mi_df_plot['Y'], label='I(Z,Y)')\n",
        "plt.legend()\n",
        "plt.savefig('mi.png')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHJDUb6tisON",
        "colab_type": "code",
        "outputId": "90b35165-070c-440e-cc00-8fd6f9189f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6W9FsK7fP4n",
        "colab_type": "code",
        "outputId": "c0f5bd25-899a-4dbf-ef76-90bb8b6db84b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "Encoder.models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Linear0': Sequential(\n",
              "   (0): Linear(in_features=784, out_features=1024, bias=True)\n",
              "   (1): LeakyReLU(negative_slope=0.02)\n",
              " ), 'Linear1': Sequential(\n",
              "   (0): Linear(in_features=784, out_features=1024, bias=True)\n",
              "   (1): LeakyReLU(negative_slope=0.02)\n",
              "   (2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "   (3): LeakyReLU(negative_slope=0.02)\n",
              " ), 'Linear2': Sequential(\n",
              "   (0): Linear(in_features=784, out_features=1024, bias=True)\n",
              "   (1): LeakyReLU(negative_slope=0.02)\n",
              "   (2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "   (3): LeakyReLU(negative_slope=0.02)\n",
              "   (4): Linear(in_features=512, out_features=256, bias=True)\n",
              "   (5): LeakyReLU(negative_slope=0.02)\n",
              " ), 'Linear3': Sequential(\n",
              "   (0): Linear(in_features=784, out_features=1024, bias=True)\n",
              "   (1): LeakyReLU(negative_slope=0.02)\n",
              "   (2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "   (3): LeakyReLU(negative_slope=0.02)\n",
              "   (4): Linear(in_features=512, out_features=256, bias=True)\n",
              "   (5): LeakyReLU(negative_slope=0.02)\n",
              "   (6): Linear(in_features=256, out_features=128, bias=True)\n",
              "   (7): LeakyReLU(negative_slope=0.02)\n",
              " ), 'Linear4': Sequential(\n",
              "   (0): Linear(in_features=784, out_features=1024, bias=True)\n",
              "   (1): LeakyReLU(negative_slope=0.02)\n",
              "   (2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "   (3): LeakyReLU(negative_slope=0.02)\n",
              "   (4): Linear(in_features=512, out_features=256, bias=True)\n",
              "   (5): LeakyReLU(negative_slope=0.02)\n",
              "   (6): Linear(in_features=256, out_features=128, bias=True)\n",
              "   (7): LeakyReLU(negative_slope=0.02)\n",
              "   (8): Linear(in_features=128, out_features=64, bias=True)\n",
              "   (9): LeakyReLU(negative_slope=0.02)\n",
              " ), 'Output': Sequential(\n",
              "   (0): Linear(in_features=784, out_features=1024, bias=True)\n",
              "   (1): LeakyReLU(negative_slope=0.02)\n",
              "   (2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "   (3): LeakyReLU(negative_slope=0.02)\n",
              "   (4): Linear(in_features=512, out_features=256, bias=True)\n",
              "   (5): LeakyReLU(negative_slope=0.02)\n",
              "   (6): Linear(in_features=256, out_features=128, bias=True)\n",
              "   (7): LeakyReLU(negative_slope=0.02)\n",
              "   (8): Linear(in_features=128, out_features=64, bias=True)\n",
              "   (9): LeakyReLU(negative_slope=0.02)\n",
              "   (10): Linear(in_features=64, out_features=10, bias=True)\n",
              " )}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDXAwdvsKrz0",
        "colab_type": "code",
        "outputId": "61b9e8bc-ef53-47dd-8d4f-550d716cda6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "acc_df = pd.DataFrame.from_dict(acc)\n",
        "plot_data = pd.DataFrame()\n",
        "# acc_df.to_csv('acc_mlp_l2.csv', sep=' ')\n",
        "acc_df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Linear2</th>\n",
              "      <th>Linear3</th>\n",
              "      <th>Linear4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[0.9022]</td>\n",
              "      <td>[0.8543]</td>\n",
              "      <td>[0.9158]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[0.8938]</td>\n",
              "      <td>[0.9367]</td>\n",
              "      <td>[0.8855]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[0.966]</td>\n",
              "      <td>[0.9311]</td>\n",
              "      <td>[0.9456]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>[0.9638]</td>\n",
              "      <td>[0.9473]</td>\n",
              "      <td>[0.9493]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>[0.9676]</td>\n",
              "      <td>[0.9522]</td>\n",
              "      <td>[0.9457]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>[0.9769]</td>\n",
              "      <td>[0.9711]</td>\n",
              "      <td>[0.9516]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>640</th>\n",
              "      <td>[0.9727]</td>\n",
              "      <td>[0.9666]</td>\n",
              "      <td>[0.9669]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1280</th>\n",
              "      <td>[0.976]</td>\n",
              "      <td>[0.9726]</td>\n",
              "      <td>[0.9732]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2560</th>\n",
              "      <td>[0.9792]</td>\n",
              "      <td>[0.9788]</td>\n",
              "      <td>[0.9657]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5120</th>\n",
              "      <td>[0.9794]</td>\n",
              "      <td>[0.9683]</td>\n",
              "      <td>[0.9742]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10240</th>\n",
              "      <td>[0.9803]</td>\n",
              "      <td>[0.9799]</td>\n",
              "      <td>[0.9739]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20480</th>\n",
              "      <td>[0.9794]</td>\n",
              "      <td>[0.9798]</td>\n",
              "      <td>[0.977]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Linear2   Linear3   Linear4\n",
              "10     [0.9022]  [0.8543]  [0.9158]\n",
              "20     [0.8938]  [0.9367]  [0.8855]\n",
              "40      [0.966]  [0.9311]  [0.9456]\n",
              "80     [0.9638]  [0.9473]  [0.9493]\n",
              "160    [0.9676]  [0.9522]  [0.9457]\n",
              "320    [0.9769]  [0.9711]  [0.9516]\n",
              "640    [0.9727]  [0.9666]  [0.9669]\n",
              "1280    [0.976]  [0.9726]  [0.9732]\n",
              "2560   [0.9792]  [0.9788]  [0.9657]\n",
              "5120   [0.9794]  [0.9683]  [0.9742]\n",
              "10240  [0.9803]  [0.9799]  [0.9739]\n",
              "20480  [0.9794]  [0.9798]   [0.977]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L2TlkyAgJis",
        "colab_type": "code",
        "outputId": "13353970-6326-45bf-fffe-c0e9a2d0b4c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "mean = lambda x: np.mean(x)\n",
        "std = lambda x: np.std(x)\n",
        "acc_df['Linear4'].apply(mean)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10       0.9158\n",
              "20       0.8855\n",
              "40       0.9456\n",
              "80       0.9493\n",
              "160      0.9457\n",
              "320      0.9516\n",
              "640      0.9669\n",
              "1280     0.9732\n",
              "2560     0.9657\n",
              "5120     0.9742\n",
              "10240    0.9739\n",
              "20480    0.9770\n",
              "Name: Linear4, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMtPl7e7e1v4",
        "colab_type": "code",
        "outputId": "816c1278-0556-4cbb-9ce9-dcabe99a919e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "pd.DataFrame.from_dict(mi_layers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Linear2</th>\n",
              "      <th>Linear3</th>\n",
              "      <th>Linear4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.838330</td>\n",
              "      <td>2.027251</td>\n",
              "      <td>1.946483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.697114</td>\n",
              "      <td>0.691475</td>\n",
              "      <td>0.689363</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Linear2   Linear3   Linear4\n",
              "0  2.838330  2.027251  1.946483\n",
              "1  0.697114  0.691475  0.689363"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUbkkzYOmqI1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ac3e1de2-8259-4568-e9c0-8718facaa53d"
      },
      "source": [
        "np.log10(nums)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 1.30103   , 1.60205999, 1.90308999, 2.20411998,\n",
              "       2.50514998, 2.80617997, 3.10720997, 3.40823997, 3.70926996,\n",
              "       4.01029996, 4.31132995])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqS3_Be1nDrG",
        "colab_type": "code",
        "outputId": "f7da2014-d4fb-424d-aea9-9f10399e7f9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        }
      },
      "source": [
        "fig1, ax1 = plt.subplots(3, 1, sharex=True)\n",
        "nums = np.array(num_labels_range)\n",
        "colors = ['black', 'blue', 'red']\n",
        "for i in range(len(layers)):\n",
        "    means = acc_df[layers[i]].apply(mean)\n",
        "    stds = acc_df[layers[i]].apply(std)\n",
        "    ax1[i].plot(np.log10(nums), means, color=colors[i], label=layers[i]+' + L2 (lambda = 0.01)')\n",
        "    ax1[i].fill_between(np.log10(nums), means - stds, means + stds, facecolor=colors[i], interpolate=True, alpha=0.25)\n",
        "    ax1[i].grid()\n",
        "ax1[-1].set_xlabel('# Labels')\n",
        "ax1[1].set_ylabel('Accuracy')\n",
        "\n",
        "fig1.legend()\n",
        "fig1.set_size_inches(10, 7, forward=True)\n",
        "fig1.savefig('acc_l2.png')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqoAAAHhCAYAAACm8pxYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiIpKTFFRFREREJCcpqIqIiIhITvp/33FchRu/E8QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x504 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-JjG7v4EVKT",
        "colab_type": "code",
        "outputId": "3c4a9290-134e-4169-9c3e-c66fb710134a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        }
      },
      "source": [
        "mi_df = pd.DataFrame.from_dict(mi_layers)\n",
        "fig2, ax2 = plt.subplots(1, 1, sharex=True)\n",
        "colors = ['black', 'blue', 'red']\n",
        "for i in range(len(layers)):\n",
        "    ax2.scatter(mi_df.loc[0, layers[i]], mi_df.loc[1, layers[i]], color=colors[i], label=layers[i])\n",
        "    \n",
        "    ax2.annotate(layers[i], (mi_df.loc[0, layers[i]], mi_df.loc[1, layers[i]]))\n",
        "    ax2.grid()\n",
        "ax2.set_xlabel('I(X, Z)')\n",
        "ax2.set_ylabel('I(Z, Y)')\n",
        "\n",
        "fig2.legend()\n",
        "fig2.set_size_inches(10, 7, forward=True)\n",
        "fig2.savefig('mi_l2.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArEAAAHhCAYAAAB5vOZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+X9bmSbhdqcoIQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoFtMDUkoLi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}