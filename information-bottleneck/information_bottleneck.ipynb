{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Bottleneck theory for Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a demonstration of the information bottleneck theory for deep learning, introduced by Naftali Tishby. Here I tried to reproduce the main results in their recent paper [Opening the black box of Deep Neural Networks via Information](https://arxiv.org/pdf/1703.00810.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will generate a very simple dataset for the demonstration. The inputs are vectors of 10 binaries, and the outputs are just single binaries. The inputs could be represented by integers from 0 to 1023 ($=2^{10}-1$). The 1024 possible inputs are divided into 16 groups (each group has 64 numbers), and each integer input $n\\in[0,1023]$ belongs to group $i$ if $x\\equiv i \\pmod{16}$, where $i \\in [0,15]$. Each group $i$ is then associated with a random binary number - we build kinda of a distribution over space of possible discrete states (output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "from random import randint, seed\n",
    "\n",
    "# Flag to enable execution on GPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "n_train_samples = 50000 # number of train samples\n",
    "n_test_samples = 10000 # number of test samples\n",
    "\n",
    "groups = np.append(np.zeros(8),np.ones(8)) # 16 groups\n",
    "print(groups)\n",
    "np.random.seed(1234)\n",
    "np.random.shuffle(groups)\n",
    "\n",
    "# generate samples\n",
    "seed(1234)\n",
    "def generate_samples(n_samples):\n",
    "    x_data = np.zeros((n_samples, 10)) # inputs\n",
    "    x_int = np.zeros(n_samples) # integers representing the inputs\n",
    "    y_data = np.zeros((n_samples, 2)) # outputs\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        random_int = randint(0, 1023)\n",
    "        x_data[i,:] = [int(b) for b in list(\"{0:b}\".format(random_int).zfill(10))]\n",
    "        x_int[i] = random_int\n",
    "        y_data[i,0] = groups[random_int % 16]\n",
    "        y_data[i,1] = 1 - y_data[i,0]\n",
    "        \n",
    "    return x_data, y_data, x_int\n",
    "\n",
    "x_train, y_train, x_train_int = generate_samples(n_train_samples) # training dataset\n",
    "x_test, y_test, _ = generate_samples(n_test_samples) # testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.0, 0.0': 24820, '0.0, 1.0': 25180}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d={}\n",
    "for i in y_train:\n",
    "    d[str(i[0])+', '+str(i[1])] = 0\n",
    "for i in y_train:\n",
    "    d[str(i[0])+', '+str(i[1])] += 1\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our dataset, the theoritical mutual information between $X$ and $Y$ would be\n",
    "\\begin{align}\n",
    "I(X;Y) & = \\sum_{x\\in X, y\\in Y}P(x,y)\\log\\Big(\\frac{P(x,y)}{P(x)P(y)}\\Big) \\\\\n",
    "& = \\sum_{x\\in X}\\Big[P(x,y=0)\\log\\Big(\\frac{P(x,y=0)}{P(x)P(y=0)}\\Big) + P(x,y=1)\\log\\Big(\\frac{P(x,y=1)}{P(x)P(y=1)}\\Big)\\Big] \\\\\n",
    "& = 1024 \\Big[ \\frac{1}{1024}\\log\\Big(\\frac{1/1024}{0.5/1024}\\Big) + 0\\Big] \\\\\n",
    "& = 0.693.\n",
    "\\end{align}\n",
    "Note that terms with $P(x,y)=0$ are set to $0$ for entropy calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we are going to build a fully-connected neural networks with 3 hidden layers, which have 8, 6 and 4 neurons respectively. First let's define a fully-connected layer and a output layer using Tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden, n_classes, neg_slope=0.02):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.layers = []\n",
    "        self.num_neurons = [n_inputs] + n_hidden + [n_classes]\n",
    "        self.models = {}\n",
    "        for i in range(len(self.num_neurons) - 2):\n",
    "            self.layers.append(nn.Linear(self.num_neurons[i], self.num_neurons[i+1]))\n",
    "            # self.layers.append(nn.LeakyReLU(neg_slope))\n",
    "            self.layers.append(nn.Tanh())\n",
    "            #self.layers['linear{}'.format(i+1)] = nn.Linear(self.num_neurons[i], self.num_neurons[i+1])\n",
    "            #self.layers['tanh{}'.format(i+1)] = nn.Tanh()\n",
    "            self.models['Linear{}'.format(i)] = nn.Sequential(*self.layers)\n",
    "            \n",
    "\n",
    "        self.layers.append(nn.Linear(self.num_neurons[i+1], self.num_neurons[i+2]))\n",
    "        #self.layers['linear{}'.format(i+1)] = nn.Linear(self.num_neurons[i], self.num_neurons[i+1])\n",
    "        self.models['Output'] = nn.Sequential(*self.layers)\n",
    "        self.full_model = self.models['Output']\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x, exitLayer=None): \n",
    "        if exitLayer is not None:\n",
    "            out = self.models[exitLayer](x)\n",
    "        else:\n",
    "            out = self.full_model(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_named_layers(net):\n",
    "    conv2d_idx = 0\n",
    "    convT2d_idx = 0\n",
    "    linear_idx = 0\n",
    "    batchnorm2d_idx = 0\n",
    "    named_layers = {}\n",
    "    for mod in net.modules():\n",
    "        if isinstance(mod, torch.nn.Conv2d):\n",
    "            layer_name = 'Conv2d{}_{}-{}'.format(\n",
    "                conv2d_idx, mod.in_channels, mod.out_channels\n",
    "            )\n",
    "            named_layers[layer_name] = mod\n",
    "            conv2d_idx += 1\n",
    "        elif isinstance(mod, torch.nn.ConvTranspose2d):\n",
    "            layer_name = 'ConvT2d{}_{}-{}'.format(\n",
    "                conv2d_idx, mod.in_channels, mod.out_channels\n",
    "            )\n",
    "            named_layers[layer_name] = mod\n",
    "            convT2d_idx += 1\n",
    "        elif isinstance(mod, torch.nn.BatchNorm2d):\n",
    "            layer_name = 'BatchNorm2D{}_{}'.format(\n",
    "                batchnorm2d_idx, mod.num_features)\n",
    "            named_layers[layer_name] = mod\n",
    "            batchnorm2d_idx += 1\n",
    "        elif isinstance(mod, torch.nn.Linear):\n",
    "            layer_name = 'Linear{}_{}-{}'.format(\n",
    "                linear_idx, mod.in_features, mod.out_features\n",
    "            )\n",
    "            named_layers[layer_name] = mod\n",
    "            linear_idx += 1\n",
    "    return named_layers\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    accuracy = (predictions.argmax(dim=1) == targets.argmax(dim=1)).type(torch.FloatTensor).mean().item()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear0_10-16': Linear(in_features=10, out_features=16, bias=True),\n",
       " 'Linear1_16-12': Linear(in_features=16, out_features=12, bias=True),\n",
       " 'Linear2_12-8': Linear(in_features=12, out_features=8, bias=True),\n",
       " 'Linear3_8-6': Linear(in_features=8, out_features=6, bias=True),\n",
       " 'Linear4_6-4': Linear(in_features=6, out_features=4, bias=True),\n",
       " 'Linear5_4-2': Linear(in_features=4, out_features=2, bias=True)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 2000\n",
    "dnn_hidden_units = [16, 12, 8, 6, 4]\n",
    "dnn_input_units = x_train.shape[1]\n",
    "dnn_output_units = y_train.shape[1]\n",
    "eval_freq = 100\n",
    "\n",
    "MLP_object = MLP(dnn_input_units, dnn_hidden_units, dnn_output_units).to(device)\n",
    "get_named_layers(MLP_object)\n",
    "#MLP_object.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.496, Loss - 0.705\n",
      "Test: Accuracy - 0.496, Loss - 0.703\n",
      "Time after last eval:  0.07526564598083496\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.567, Loss - 0.692\n",
      "Test: Accuracy - 0.569, Loss - 0.692\n",
      "Time after last eval:  3.6912927627563477\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.590, Loss - 0.691\n",
      "Test: Accuracy - 0.591, Loss - 0.691\n",
      "Time after last eval:  7.097638845443726\n",
      "############################## \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bca87d072410>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time after last eval: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-bca87d072410>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train():\n",
    "\n",
    "    MLP_object = MLP(dnn_input_units, dnn_hidden_units, dnn_output_units).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = optim.SGD(MLP_object.parameters(), lr=0.1)#, momentum=0.2)\n",
    "    \n",
    "    X_test, Y_test = torch.tensor(x_test, requires_grad=False).to(device), torch.tensor(y_test, requires_grad=False).to(device)\n",
    "    accuracy_evaluation = {'train': [], 'test': []}\n",
    "    loss_evaluation = {'train': [], 'test': []}\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        X_train, Y_train = torch.from_numpy(x_train).to(device), torch.from_numpy(y_train).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = MLP_object(X_train.float())\n",
    "        loss = criterion(out, Y_train.argmax(dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % eval_freq == 0 or epoch == num_epochs - 1:\n",
    "            #accuracy_evaluation['train'].append(accuracy(out, y_train))\n",
    "            #accuracy_evaluation['test'].append(accuracy(MLP_object(X_test), y_test))\n",
    "            #loss_evaluation['train'].append(loss)\n",
    "            #loss_evaluation['test'].append(criterion(MLP_object(X_test), Y_test.argmax(dim=1)))\n",
    "            print('#'*30)\n",
    "            print('Step - ', epoch)\n",
    "            print('Train: Accuracy - %0.3f, Loss - %0.3f' % (accuracy(out, Y_train), loss))\n",
    "            print('Test: Accuracy - %0.3f, Loss - %0.3f' % (accuracy(MLP_object(X_test.float()), Y_test), criterion(MLP_object(X_test.float()), Y_test.argmax(dim=1))))\n",
    "            print('Time after last eval: ', time.time() - start_time)\n",
    "            print('#'*30,'\\n')\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to explore the information bottleneck theory for our network. To estimate the mutual information between all the hidden layers and intput/output layers, we could binned the output activations as stated in the paper  (here we choose 30 bins, the same as in the paper), so that the hidden layer random variables $T_i$ (each $i$ corresponds to one hidden layer) would be discrete. Then, we will be able to estimate the joint distribution $P(X,T_i)$ and $P(T_i,Y)$, and use them to calculate the encoder mutual information (between input $X$ and hidden layer $T_i$)\n",
    "\\begin{equation}\n",
    "    I(X;T_i) = \\sum_{x\\in X, t\\in T_i}P(x,t)\\log\\Big(\\frac{P(x,t)}{P(x)P(t)}\\Big)\n",
    "\\end{equation}\n",
    "\n",
    "and decoder mutual information (between hidden layer $T_i$ and desired output $Y$, note that it is not the model output $\\widehat{Y}$)\n",
    "\\begin{equation}\n",
    "    I(T_i;Y) = \\sum_{t\\in T_i, y\\in Y}P(t,y)\\log\\Big(\\frac{P(t,y)}{P(t)P(y)}\\Big).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def calc_mutual_information(hidden):\n",
    "    n_neurons = hidden.shape[1]\n",
    "  \n",
    "    # discretization \n",
    "    n_bins = 30\n",
    "    bins = np.linspace(-1, 1, n_bins+1)\n",
    "    indices = np.digitize(hidden, bins)\n",
    "    \n",
    "    # initialize pdfs\n",
    "    pdf_x = Counter(); pdf_y = Counter(); pdf_t = Counter(); pdf_xt = Counter(); pdf_yt = Counter()\n",
    "\n",
    "    for i in range(n_train_samples):\n",
    "        pdf_x[x_train_int[i]] += 1/float(n_train_samples)\n",
    "        pdf_y[y_train[i,0]] += 1/float(n_train_samples)      \n",
    "        pdf_xt[(x_train_int[i],)+tuple(indices[i,:])] += 1/float(n_train_samples)\n",
    "        pdf_yt[(y_train[i,0],)+tuple(indices[i,:])] += 1/float(n_train_samples)\n",
    "        pdf_t[tuple(indices[i,:])] += 1/float(n_train_samples)\n",
    "    \n",
    "    # calcuate encoder mutual information I(X;T)\n",
    "    mi_xt = 0\n",
    "    for i in pdf_xt:\n",
    "        # P(x,t), P(x) and P(t)\n",
    "        p_xt = pdf_xt[i]; p_x = pdf_x[i[0]]; p_t = pdf_t[i[1:]]\n",
    "        # I(X;T)\n",
    "        mi_xt += p_xt * np.log(p_xt / p_x / p_t)\n",
    " \n",
    "    # calculate decoder mutual information I(T;Y)\n",
    "    mi_ty = 0\n",
    "    for i in pdf_yt:\n",
    "        # P(t,y), P(t) and P(y)\n",
    "        p_yt = pdf_yt[i]; p_t = pdf_t[i[1:]]; p_y = pdf_y[i[0]]\n",
    "        # I(X;T)\n",
    "        mi_ty += p_yt * np.log(p_yt / p_t / p_y)\n",
    "            \n",
    "    return mi_xt, mi_ty\n",
    "\n",
    "# get mutual information for all hidden layers\n",
    "def get_mutual_information(hiddens):\n",
    "    mi_xt_list = []; mi_ty_list = []\n",
    "    for hidden in hiddens:\n",
    "        mi_xt, mi_ty = calc_mutual_information(hidden.data.numpy())\n",
    "        mi_xt_list.append(mi_xt)\n",
    "        mi_ty_list.append(mi_ty)\n",
    "    return mi_xt_list, mi_ty_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Neural approximation of MI starts here\n",
    "# Auxiliary network for mutual information estimation\n",
    "class MIEstimator(nn.Module):\n",
    "    def __init__(self, size1, size2):\n",
    "        super(MIEstimator, self).__init__()\n",
    "        \n",
    "        # Vanilla MLP\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(size1 + size2, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 1),\n",
    "        )\n",
    "    \n",
    "    # Gradient for JSD mutual information estimation and EB-based estimation\n",
    "    def forward(self, x1, x2):\n",
    "        pos = self.net(torch.cat([x1, x2], 1)) #Positive Samples \n",
    "        neg = self.net(torch.cat([torch.roll(x1, 1, 0), x2], 1)) #Predictions for shuffled (negative) samples from p(z1)p(z2)\n",
    "        #breakpoint()\n",
    "        return -softplus(-pos).mean() - softplus(neg).mean(), pos.mean() - neg.exp().mean() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now able to estimate the mutual information while training the network. We'll save the mutual information for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Linear0_10-10': Linear(in_features=10, out_features=10, bias=True), 'Linear1_10-8': Linear(in_features=10, out_features=8, bias=True), 'Linear2_8-6': Linear(in_features=8, out_features=6, bias=True), 'Linear3_6-4': Linear(in_features=6, out_features=4, bias=True), 'Linear4_4-2': Linear(in_features=4, out_features=2, bias=True)}\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.504, Loss - 0.735\n",
      "Test: Accuracy - 0.496, Loss - 0.695\n",
      "I(X, T) -  [6.921128755327638, 6.919661253842164, 5.315285447927424, 2.4722751040235824]\n",
      "I(T, Y) -  [0.6931212603355567, 0.6931212603355567, 0.1619643964568741, 0.007668447308412315]\n",
      "I_est(X, T) tensor(-0.0004, grad_fn=<MeanBackward0>)\n",
      "Time running:  7.506587266921997\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  1\n",
      "Train: Accuracy - 0.496, Loss - 0.754\n",
      "Test: Accuracy - 0.504, Loss - 0.694\n",
      "I(X, T) -  [6.921128755327638, 6.912801971065306, 5.828123019829641, 2.3128775419052037]\n",
      "I(T, Y) -  [0.6931212603355567, 0.6918438174756583, 0.32492526956593853, 0.03519213603779305]\n",
      "I_est(X, T) tensor(-4.8722, grad_fn=<MeanBackward0>)\n",
      "Time running:  14.83127212524414\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  2\n",
      "Train: Accuracy - 0.504, Loss - 0.717\n",
      "Test: Accuracy - 0.582, Loss - 0.690\n",
      "I(X, T) -  [6.921128755327638, 6.886613248908959, 6.0929925683647905, 3.665337194997837]\n",
      "I(T, Y) -  [0.6931212603355567, 0.6822964668306374, 0.42339637785963957, 0.07787758067143158]\n",
      "I_est(X, T) tensor(-4.9761, grad_fn=<MeanBackward0>)\n",
      "Time running:  22.920225143432617\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  3\n",
      "Train: Accuracy - 0.577, Loss - 0.706\n",
      "Test: Accuracy - 0.587, Loss - 0.678\n",
      "I(X, T) -  [6.915486287075458, 6.6004982653484605, 5.617659725811366, 3.691181471773052]\n",
      "I(T, Y) -  [0.6888928123317187, 0.5888289836071794, 0.3115524688206964, 0.09502720407135495]\n",
      "I_est(X, T) tensor(-0.3223, grad_fn=<MeanBackward0>)\n",
      "Time running:  30.64628005027771\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  4\n",
      "Train: Accuracy - 0.588, Loss - 0.692\n",
      "Test: Accuracy - 0.534, Loss - 0.715\n",
      "I(X, T) -  [6.8741685298084345, 6.484308055540645, 5.321742254159677, 3.6770587075541474]\n",
      "I(T, Y) -  [0.67573796999949, 0.5416382305982959, 0.28266525616843946, 0.11337062523346282]\n",
      "I_est(X, T) tensor(-0.0274, grad_fn=<MeanBackward0>)\n",
      "Time running:  39.22342920303345\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  5\n",
      "Train: Accuracy - 0.534, Loss - 0.729\n",
      "Test: Accuracy - 0.532, Loss - 0.714\n",
      "I(X, T) -  [6.872383692378723, 6.646338767423102, 5.329800275284836, 3.599011077134597]\n",
      "I(T, Y) -  [0.6673841469487266, 0.6041914664819477, 0.304987614835848, 0.13351027695781484]\n",
      "I_est(X, T) tensor(4.1306e-05, grad_fn=<MeanBackward0>)\n",
      "Time running:  49.40193724632263\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  6\n",
      "Train: Accuracy - 0.531, Loss - 0.729\n",
      "Test: Accuracy - 0.566, Loss - 0.681\n",
      "I(X, T) -  [6.886260045614548, 6.607433663900277, 4.95850084512207, 3.304416195186407]\n",
      "I(T, Y) -  [0.6767672924701935, 0.5610745557640655, 0.26058743023475683, 0.12934190871914447]\n",
      "I_est(X, T) tensor(-0.0265, grad_fn=<MeanBackward0>)\n",
      "Time running:  57.55467128753662\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  7\n",
      "Train: Accuracy - 0.564, Loss - 0.696\n",
      "Test: Accuracy - 0.596, Loss - 0.661\n",
      "I(X, T) -  [6.907322429502317, 6.716182006339535, 5.112887552734528, 3.4929789721110622]\n",
      "I(T, Y) -  [0.6849268702768714, 0.6074314692349275, 0.285747346047109, 0.14522997145217648]\n",
      "I_est(X, T) tensor(-0.0117, grad_fn=<MeanBackward0>)\n",
      "Time running:  64.81065392494202\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  8\n",
      "Train: Accuracy - 0.590, Loss - 0.675\n",
      "Test: Accuracy - 0.598, Loss - 0.677\n",
      "I(X, T) -  [6.910997356475215, 6.843104156322151, 5.934678602588122, 4.427806648569143]\n",
      "I(T, Y) -  [0.6845670777005162, 0.667776799311774, 0.4119144113957682, 0.2179886713068233]\n",
      "I_est(X, T) tensor(0.0024, grad_fn=<MeanBackward0>)\n",
      "Time running:  72.15386509895325\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  9\n",
      "Train: Accuracy - 0.598, Loss - 0.691\n",
      "Test: Accuracy - 0.597, Loss - 0.680\n",
      "I(X, T) -  [6.918236440659239, 6.868266363838754, 6.177510034079583, 4.49031670712819]\n",
      "I(T, Y) -  [0.6916984176899446, 0.6743412267874634, 0.5049563986155977, 0.23021305470799308]\n",
      "I_est(X, T) tensor(0.0084, grad_fn=<MeanBackward0>)\n",
      "Time running:  79.72051405906677\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  10\n",
      "Train: Accuracy - 0.597, Loss - 0.694\n",
      "Test: Accuracy - 0.610, Loss - 0.669\n",
      "I(X, T) -  [6.921128755327638, 6.859714610010266, 6.186080654382375, 4.517729997077473]\n",
      "I(T, Y) -  [0.6931212603355567, 0.6749940017535877, 0.5285304990150742, 0.260122680648595]\n",
      "I_est(X, T) tensor(0.0127, grad_fn=<MeanBackward0>)\n",
      "Time running:  87.46244215965271\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  11\n",
      "Train: Accuracy - 0.614, Loss - 0.683\n",
      "Test: Accuracy - 0.612, Loss - 0.654\n",
      "I(X, T) -  [6.921128755327638, 6.862163476369707, 6.112183252108783, 4.689770014303137]\n",
      "I(T, Y) -  [0.6931212603355567, 0.6683169732454858, 0.5201578395608905, 0.2813492773437536]\n",
      "I_est(X, T) tensor(0.0246, grad_fn=<MeanBackward0>)\n",
      "Time running:  94.69220614433289\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  12\n",
      "Train: Accuracy - 0.604, Loss - 0.668\n",
      "Test: Accuracy - 0.630, Loss - 0.643\n",
      "I(X, T) -  [6.921128755327638, 6.8284186696803095, 5.995328475105635, 4.711784777750345]\n",
      "I(T, Y) -  [0.6931212603355567, 0.6758490593957722, 0.5276789392586174, 0.2997647649640346]\n",
      "I_est(X, T) tensor(0.0447, grad_fn=<MeanBackward0>)\n",
      "Time running:  102.09334301948547\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  13\n",
      "Train: Accuracy - 0.628, Loss - 0.658\n",
      "Test: Accuracy - 0.628, Loss - 0.644\n",
      "I(X, T) -  [6.921128755327638, 6.736886768374724, 5.670298892871585, 4.500024076223259]\n",
      "I(T, Y) -  [0.6931212603355567, 0.6387283458959464, 0.45811178907640526, 0.272439595442158]\n",
      "I_est(X, T) tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "Time running:  109.41099810600281\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  14\n",
      "Train: Accuracy - 0.626, Loss - 0.659\n",
      "Test: Accuracy - 0.630, Loss - 0.643\n",
      "I(X, T) -  [6.918204569462157, 6.5781548461878705, 5.323572603539099, 3.929424642437949]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6195934539578947, 0.3963759960076881, 0.23489216662344273]\n",
      "I_est(X, T) tensor(0.0899, grad_fn=<MeanBackward0>)\n",
      "Time running:  117.50255703926086\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  15\n",
      "Train: Accuracy - 0.628, Loss - 0.659\n",
      "Test: Accuracy - 0.644, Loss - 0.628\n",
      "I(X, T) -  [6.914321151264748, 6.575022560975749, 5.282273344698681, 3.722992159884387]\n",
      "I(T, Y) -  [0.6931212603355567, 0.6193377731239023, 0.41968771326687476, 0.25036835425589565]\n",
      "I_est(X, T) tensor(0.1269, grad_fn=<MeanBackward0>)\n",
      "Time running:  125.72345614433289\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  16\n",
      "Train: Accuracy - 0.643, Loss - 0.643\n",
      "Test: Accuracy - 0.638, Loss - 0.621\n",
      "I(X, T) -  [6.91267170729884, 6.6793070495381635, 5.481376163757218, 4.223687176274278]\n",
      "I(T, Y) -  [0.6918847294976813, 0.6373385746857431, 0.465410348550397, 0.311947603647289]\n",
      "I_est(X, T) tensor(0.1978, grad_fn=<MeanBackward0>)\n",
      "Time running:  135.35989713668823\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  17\n",
      "Train: Accuracy - 0.636, Loss - 0.635\n",
      "Test: Accuracy - 0.642, Loss - 0.615\n",
      "I(X, T) -  [6.909547307849435, 6.739917809345811, 5.805657154958113, 4.60674404182254]\n",
      "I(T, Y) -  [0.6931212603355567, 0.6634889915418937, 0.5422606382789477, 0.3423702807340513]\n",
      "I_est(X, T) tensor(0.2830, grad_fn=<MeanBackward0>)\n",
      "Time running:  144.76221919059753\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  18\n",
      "Train: Accuracy - 0.642, Loss - 0.628\n",
      "Test: Accuracy - 0.658, Loss - 0.592\n",
      "I(X, T) -  [6.894789189421049, 6.774498134750307, 5.795189345848723, 4.835868718299067]\n",
      "I(T, Y) -  [0.6856389186070303, 0.663981340956569, 0.5027601129154485, 0.3730155997766542]\n",
      "I_est(X, T) tensor(0.3553, grad_fn=<MeanBackward0>)\n",
      "Time running:  155.89034914970398\n",
      "############################## \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Step -  19\n",
      "Train: Accuracy - 0.654, Loss - 0.605\n",
      "Test: Accuracy - 0.672, Loss - 0.579\n",
      "I(X, T) -  [6.902879871165811, 6.6907646455114715, 5.612299841195258, 4.669988277241838]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6452374108345882, 0.4798124255202459, 0.3652238519021718]\n",
      "I_est(X, T) tensor(0.3539, grad_fn=<MeanBackward0>)\n",
      "Time running:  163.9734001159668\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  20\n",
      "Train: Accuracy - 0.671, Loss - 0.593\n",
      "Test: Accuracy - 0.686, Loss - 0.551\n",
      "I(X, T) -  [6.885993354778813, 6.651307728705847, 5.486958957186524, 4.492095801101302]\n",
      "I(T, Y) -  [0.6918598423592593, 0.6521123387702384, 0.46931139265270766, 0.3712505285744596]\n",
      "I_est(X, T) tensor(0.3013, grad_fn=<MeanBackward0>)\n",
      "Time running:  171.30100202560425\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  21\n",
      "Train: Accuracy - 0.685, Loss - 0.565\n",
      "Test: Accuracy - 0.664, Loss - 0.532\n",
      "I(X, T) -  [6.895359367401329, 6.6514193658232905, 5.449479565709928, 4.620845568630005]\n",
      "I(T, Y) -  [0.6905044098416381, 0.6445409028641882, 0.50030302399564, 0.4195704193199216]\n",
      "I_est(X, T) tensor(0.3833, grad_fn=<MeanBackward0>)\n",
      "Time running:  179.11517906188965\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  22\n",
      "Train: Accuracy - 0.662, Loss - 0.543\n",
      "Test: Accuracy - 0.694, Loss - 0.504\n",
      "I(X, T) -  [6.911149852799001, 6.6804575851136025, 5.481796094209261, 4.5666911851854755]\n",
      "I(T, Y) -  [0.6915933924083629, 0.6697732675360042, 0.5405370802020935, 0.4334196077323027]\n",
      "I_est(X, T) tensor(0.5270, grad_fn=<MeanBackward0>)\n",
      "Time running:  186.62543106079102\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  23\n",
      "Train: Accuracy - 0.692, Loss - 0.515\n",
      "Test: Accuracy - 0.688, Loss - 0.473\n",
      "I(X, T) -  [6.907685004928067, 6.601232547462028, 5.131623451060047, 4.20670123036999]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6719689065451447, 0.48879338826563606, 0.42151950780883257]\n",
      "I_est(X, T) tensor(0.4601, grad_fn=<MeanBackward0>)\n",
      "Time running:  194.7619330883026\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  24\n",
      "Train: Accuracy - 0.687, Loss - 0.483\n",
      "Test: Accuracy - 0.713, Loss - 0.452\n",
      "I(X, T) -  [6.903924184973321, 6.476046840387961, 4.664977089566499, 3.992768142642721]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6721993423396423, 0.4538288271827431, 0.41160705393198516]\n",
      "I_est(X, T) tensor(0.4247, grad_fn=<MeanBackward0>)\n",
      "Time running:  202.34907007217407\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  25\n",
      "Train: Accuracy - 0.713, Loss - 0.462\n",
      "Test: Accuracy - 0.706, Loss - 0.437\n",
      "I(X, T) -  [6.9038147629085636, 6.316579544507941, 4.332607917560798, 3.583388354210108]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6759150791176631, 0.46683751694403536, 0.40031429318945577]\n",
      "I_est(X, T) tensor(0.3767, grad_fn=<MeanBackward0>)\n",
      "Time running:  210.3119239807129\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  26\n",
      "Train: Accuracy - 0.712, Loss - 0.444\n",
      "Test: Accuracy - 0.727, Loss - 0.400\n",
      "I(X, T) -  [6.905023826246043, 6.229014794542676, 4.224469504987112, 3.8173146995673557]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6931212603355553, 0.5071702605200886, 0.5045088153342562]\n",
      "I_est(X, T) tensor(0.4701, grad_fn=<MeanBackward0>)\n",
      "Time running:  217.7706561088562\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  27\n",
      "Train: Accuracy - 0.726, Loss - 0.408\n",
      "Test: Accuracy - 0.756, Loss - 0.377\n",
      "I(X, T) -  [6.903200701505584, 6.161597544129159, 4.292264028238185, 3.367394523432848]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6931212603355544, 0.5792243580250312, 0.5102286555614071]\n",
      "I_est(X, T) tensor(0.5567, grad_fn=<MeanBackward0>)\n",
      "Time running:  225.25632524490356\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  28\n",
      "Train: Accuracy - 0.756, Loss - 0.384\n",
      "Test: Accuracy - 0.764, Loss - 0.355\n",
      "I(X, T) -  [6.905102904083503, 6.174142849642438, 4.256625341636996, 3.2984048128131724]\n",
      "I(T, Y) -  [0.6931212603355569, 0.6931212603355545, 0.5721861352586889, 0.5115440417150106]\n",
      "I_est(X, T) tensor(0.4709, grad_fn=<MeanBackward0>)\n",
      "Time running:  232.53356313705444\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  29\n",
      "Train: Accuracy - 0.769, Loss - 0.361\n",
      "Test: Accuracy - 0.783, Loss - 0.326\n",
      "I(X, T) -  [6.889791738872213, 5.996804793397927, 4.267055550224091, 2.8020827798267054]\n",
      "I(T, Y) -  [0.6931212603355567, 0.6855706337199606, 0.5922470489432957, 0.522567990673691]\n",
      "I_est(X, T) tensor(0.2956, grad_fn=<MeanBackward0>)\n",
      "Time running:  239.76842713356018\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  30\n",
      "Train: Accuracy - 0.791, Loss - 0.332\n",
      "Test: Accuracy - 0.868, Loss - 0.300\n",
      "I(X, T) -  [6.8248449208743365, 5.755934287650204, 4.232348274106868, 3.1061798345672145]\n",
      "I(T, Y) -  [0.6931212603355565, 0.6736992865542503, 0.6228170408918727, 0.5467769504560446]\n",
      "I_est(X, T) tensor(0.3324, grad_fn=<MeanBackward0>)\n",
      "Time running:  247.01105618476868\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  31\n",
      "Train: Accuracy - 0.873, Loss - 0.306\n",
      "Test: Accuracy - 0.870, Loss - 0.291\n",
      "I(X, T) -  [6.786548408464126, 5.664622968539673, 4.4004456084415375, 3.3916962776684]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6693973838162811, 0.5909986403157702, 0.5368543575476372]\n",
      "I_est(X, T) tensor(0.1744, grad_fn=<MeanBackward0>)\n",
      "Time running:  254.25288200378418\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  32\n",
      "Train: Accuracy - 0.876, Loss - 0.296\n",
      "Test: Accuracy - 0.815, Loss - 0.280\n",
      "I(X, T) -  [6.720810326485063, 5.728945638864788, 4.707364146670654, 3.37653914532934]\n",
      "I(T, Y) -  [0.6931212603355561, 0.6733771029837334, 0.6268997125988305, 0.5692621821730689]\n",
      "I_est(X, T) tensor(0.2829, grad_fn=<MeanBackward0>)\n",
      "Time running:  261.466835975647\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  33\n",
      "Train: Accuracy - 0.820, Loss - 0.285\n",
      "Test: Accuracy - 0.866, Loss - 0.272\n",
      "I(X, T) -  [6.667274590434284, 5.763241731046867, 4.830115851763032, 3.389563156687887]\n",
      "I(T, Y) -  [0.6931212603355561, 0.6799873780279025, 0.6046662288181085, 0.5571313113465388]\n",
      "I_est(X, T) tensor(0.1747, grad_fn=<MeanBackward0>)\n",
      "Time running:  268.6872730255127\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  34\n",
      "Train: Accuracy - 0.872, Loss - 0.276\n",
      "Test: Accuracy - 0.755, Loss - 0.318\n",
      "I(X, T) -  [6.5583929351242505, 5.643004875894906, 4.816447644568705, 3.4474354815781356]\n",
      "I(T, Y) -  [0.6931212603355554, 0.6824863519972698, 0.5511421451967479, 0.5490662970015678]\n",
      "I_est(X, T) tensor(0.3243, grad_fn=<MeanBackward0>)\n",
      "Time running:  275.8741991519928\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  35\n",
      "Train: Accuracy - 0.760, Loss - 0.321\n",
      "Test: Accuracy - 0.767, Loss - 0.414\n",
      "I(X, T) -  [6.563804899187461, 5.849378440900516, 5.126721105966956, 3.6404063826955415]\n",
      "I(T, Y) -  [0.6931212603355558, 0.6931212603355535, 0.6899947566401076, 0.6026287357638845]\n",
      "I_est(X, T) tensor(0.5227, grad_fn=<MeanBackward0>)\n",
      "Time running:  283.12661933898926\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  36\n",
      "Train: Accuracy - 0.770, Loss - 0.419\n",
      "Test: Accuracy - 0.811, Loss - 0.339\n",
      "I(X, T) -  [6.378939264493263, 5.212935076163004, 4.341263476165746, 3.02370016415258]\n",
      "I(T, Y) -  [0.6931212603355544, 0.6257057336302907, 0.6020902078725124, 0.49738490382014583]\n",
      "I_est(X, T) tensor(0.4622, grad_fn=<MeanBackward0>)\n",
      "Time running:  290.3788661956787\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  37\n",
      "Train: Accuracy - 0.816, Loss - 0.342\n",
      "Test: Accuracy - 0.868, Loss - 0.269\n",
      "I(X, T) -  [6.45206044477639, 5.207316541992088, 4.243551705247965, 3.071126976456354]\n",
      "I(T, Y) -  [0.6931212603355551, 0.6537116098596671, 0.5947282391431782, 0.4836779276002312]\n",
      "I_est(X, T) tensor(0.4015, grad_fn=<MeanBackward0>)\n",
      "Time running:  298.259574174881\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  38\n",
      "Train: Accuracy - 0.874, Loss - 0.275\n",
      "Test: Accuracy - 0.850, Loss - 0.259\n",
      "I(X, T) -  [6.5158570945056296, 5.402267638619364, 4.341286739433953, 3.244986662043301]\n",
      "I(T, Y) -  [0.6931212603355555, 0.6931212603355507, 0.5948963816216467, 0.4662771365068537]\n",
      "I_est(X, T) tensor(0.6225, grad_fn=<MeanBackward0>)\n",
      "Time running:  305.5190830230713\n",
      "############################## \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Step -  39\n",
      "Train: Accuracy - 0.854, Loss - 0.265\n",
      "Test: Accuracy - 0.751, Loss - 0.308\n",
      "I(X, T) -  [6.633415942148373, 5.449365457132816, 4.560652391271824, 3.0079078739472]\n",
      "I(T, Y) -  [0.6931212603355563, 0.6899129422766108, 0.6204386228072524, 0.4891786704185721]\n",
      "I_est(X, T) tensor(0.7278, grad_fn=<MeanBackward0>)\n",
      "Time running:  312.76637601852417\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  40\n",
      "Train: Accuracy - 0.750, Loss - 0.317\n",
      "Test: Accuracy - 0.811, Loss - 0.269\n",
      "I(X, T) -  [6.680478259614343, 5.533008031970744, 4.60444694260221, 3.2923502439535173]\n",
      "I(T, Y) -  [0.6931212603355564, 0.693121260335554, 0.6224039915711084, 0.5824880200908805]\n",
      "I_est(X, T) tensor(0.7600, grad_fn=<MeanBackward0>)\n",
      "Time running:  320.03656911849976\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  41\n",
      "Train: Accuracy - 0.813, Loss - 0.275\n",
      "Test: Accuracy - 0.926, Loss - 0.225\n",
      "I(X, T) -  [6.684327733613073, 5.508711229292059, 4.458371768456287, 3.266447067570131]\n",
      "I(T, Y) -  [0.6931212603355567, 0.693121260335552, 0.672201608519255, 0.5813002788431122]\n",
      "I_est(X, T) tensor(0.7404, grad_fn=<MeanBackward0>)\n",
      "Time running:  327.2554512023926\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  42\n",
      "Train: Accuracy - 0.930, Loss - 0.229\n",
      "Test: Accuracy - 0.927, Loss - 0.198\n",
      "I(X, T) -  [6.708780006596708, 5.478630115594475, 4.418022059310127, 3.282042877265726]\n",
      "I(T, Y) -  [0.6931212603355565, 0.6918008533357967, 0.6869200660187751, 0.5885569059835967]\n",
      "I_est(X, T) tensor(0.8093, grad_fn=<MeanBackward0>)\n",
      "Time running:  335.42477917671204\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  43\n",
      "Train: Accuracy - 0.932, Loss - 0.201\n",
      "Test: Accuracy - 0.931, Loss - 0.184\n",
      "I(X, T) -  [6.729070832835704, 5.42391451430545, 4.308703018452593, 3.1492882095010115]\n",
      "I(T, Y) -  [0.6931212603355563, 0.6912907120443005, 0.691379680894719, 0.5455611114457904]\n",
      "I_est(X, T) tensor(0.7979, grad_fn=<MeanBackward0>)\n",
      "Time running:  342.8206310272217\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  44\n",
      "Train: Accuracy - 0.935, Loss - 0.188\n",
      "Test: Accuracy - 0.930, Loss - 0.188\n",
      "I(X, T) -  [6.708079237409843, 5.484862077492274, 4.464845119715013, 3.2465695239392898]\n",
      "I(T, Y) -  [0.6931212603355563, 0.6919017758823607, 0.6911474725393373, 0.5533608301598417]\n",
      "I_est(X, T) tensor(0.7728, grad_fn=<MeanBackward0>)\n",
      "Time running:  351.71963119506836\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  45\n",
      "Train: Accuracy - 0.934, Loss - 0.190\n",
      "Test: Accuracy - 0.934, Loss - 0.194\n",
      "I(X, T) -  [6.706667781374115, 5.447853183632438, 4.459596697061959, 3.3628722081610136]\n",
      "I(T, Y) -  [0.6931212603355565, 0.6931212603355521, 0.6879832285237599, 0.5504949265239569]\n",
      "I_est(X, T) tensor(0.7555, grad_fn=<MeanBackward0>)\n",
      "Time running:  359.23743414878845\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  46\n",
      "Train: Accuracy - 0.938, Loss - 0.196\n",
      "Test: Accuracy - 0.933, Loss - 0.189\n",
      "I(X, T) -  [6.720622183992863, 5.4106124678217755, 4.45081419587154, 3.2427702384882524]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6931212603355523, 0.6931212603355573, 0.5403815333382845]\n",
      "I_est(X, T) tensor(0.6826, grad_fn=<MeanBackward0>)\n",
      "Time running:  367.4781630039215\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  47\n",
      "Train: Accuracy - 0.937, Loss - 0.189\n",
      "Test: Accuracy - 0.933, Loss - 0.192\n",
      "I(X, T) -  [6.702509478976593, 5.44298902005517, 4.422119195929169, 3.0149268742673923]\n",
      "I(T, Y) -  [0.6931212603355559, 0.6931212603355527, 0.6919458461335003, 0.5421491987374933]\n",
      "I_est(X, T) tensor(0.8183, grad_fn=<MeanBackward0>)\n",
      "Time running:  375.2906303405762\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  48\n",
      "Train: Accuracy - 0.937, Loss - 0.191\n",
      "Test: Accuracy - 0.934, Loss - 0.188\n",
      "I(X, T) -  [6.6721018242028665, 5.380111821817791, 4.306465637863508, 2.8776341327080504]\n",
      "I(T, Y) -  [0.6931212603355569, 0.6931212603355509, 0.6904381232724983, 0.5411572565277645]\n",
      "I_est(X, T) tensor(0.8078, grad_fn=<MeanBackward0>)\n",
      "Time running:  382.58240723609924\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  49\n",
      "Train: Accuracy - 0.938, Loss - 0.187\n",
      "Test: Accuracy - 0.934, Loss - 0.185\n",
      "I(X, T) -  [6.617686221035861, 5.294060945724475, 4.238242043084201, 2.7684214978831516]\n",
      "I(T, Y) -  [0.6931212603355567, 0.6931212603355509, 0.6931212603355482, 0.5389088189448374]\n",
      "I_est(X, T) tensor(0.8278, grad_fn=<MeanBackward0>)\n",
      "Time running:  389.81855511665344\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  50\n",
      "Train: Accuracy - 0.938, Loss - 0.184\n",
      "Test: Accuracy - 0.934, Loss - 0.181\n",
      "I(X, T) -  [6.609279084058796, 5.254073732179015, 4.157413356928619, 2.6783396057472055]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6931212603355513, 0.6522838600556228, 0.5375193754192593]\n",
      "I_est(X, T) tensor(0.9573, grad_fn=<MeanBackward0>)\n",
      "Time running:  397.21129512786865\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  51\n",
      "Train: Accuracy - 0.938, Loss - 0.181\n",
      "Test: Accuracy - 0.934, Loss - 0.173\n",
      "I(X, T) -  [6.613557248785047, 5.268355263919174, 4.149669424510195, 2.6988382024946644]\n",
      "I(T, Y) -  [0.6931212603355571, 0.6900299844729509, 0.6435198588019271, 0.5372789518896377]\n",
      "I_est(X, T) tensor(0.8351, grad_fn=<MeanBackward0>)\n",
      "Time running:  404.51803708076477\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  52\n",
      "Train: Accuracy - 0.938, Loss - 0.173\n",
      "Test: Accuracy - 0.961, Loss - 0.102\n",
      "I(X, T) -  [6.6151166089242945, 5.250783576976513, 4.321650631650954, 2.5616514065481195]\n",
      "I(T, Y) -  [0.6931212603355573, 0.6896687987916695, 0.6931212603355443, 0.5406628328959554]\n",
      "I_est(X, T) tensor(0.9641, grad_fn=<MeanBackward0>)\n",
      "Time running:  411.8301491737366\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  53\n",
      "Train: Accuracy - 0.965, Loss - 0.105\n",
      "Test: Accuracy - 0.933, Loss - 0.378\n",
      "I(X, T) -  [6.635138910390058, 5.293767740236898, 4.462909631730685, 2.7439739838163706]\n",
      "I(T, Y) -  [0.6931212603355573, 0.6931212603355512, 0.6931212603355447, 0.6668546254608299]\n",
      "I_est(X, T) tensor(0.9020, grad_fn=<MeanBackward0>)\n",
      "Time running:  419.3715510368347\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  54\n",
      "Train: Accuracy - 0.938, Loss - 0.363\n",
      "Test: Accuracy - 0.933, Loss - 0.335\n",
      "I(X, T) -  [6.6533077468805155, 5.244342865443003, 4.178019361419865, 2.8078541329852493]\n",
      "I(T, Y) -  [0.6931212603355564, 0.6931212603355498, 0.6487042688231813, 0.6322596502803318]\n",
      "I_est(X, T) tensor(0.4700, grad_fn=<MeanBackward0>)\n",
      "Time running:  426.7310862541199\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  55\n",
      "Train: Accuracy - 0.938, Loss - 0.322\n",
      "Test: Accuracy - 0.932, Loss - 0.214\n",
      "I(X, T) -  [6.656221698898357, 5.248586370534892, 4.306458407506369, 2.9593177644910442]\n",
      "I(T, Y) -  [0.6931212603355571, 0.680404416650081, 0.6300013313095922, 0.6269576059363784]\n",
      "I_est(X, T) tensor(0.6786, grad_fn=<MeanBackward0>)\n",
      "Time running:  433.9569962024689\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  56\n",
      "Train: Accuracy - 0.937, Loss - 0.211\n",
      "Test: Accuracy - 0.933, Loss - 0.145\n",
      "I(X, T) -  [6.61167718411628, 5.2936958300739265, 4.4929881128545865, 3.48593294164392]\n",
      "I(T, Y) -  [0.6931212603355574, 0.6561369410263539, 0.642603657670728, 0.6438630845176563]\n",
      "I_est(X, T) tensor(0.5530, grad_fn=<MeanBackward0>)\n",
      "Time running:  441.2645251750946\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  57\n",
      "Train: Accuracy - 0.938, Loss - 0.150\n",
      "Test: Accuracy - 0.934, Loss - 0.185\n",
      "I(X, T) -  [6.645625883762001, 5.258301589984619, 4.324984846530747, 3.303337613434833]\n",
      "I(T, Y) -  [0.6931212603355567, 0.6667117054688663, 0.6610778318682436, 0.6635318103758071]\n",
      "I_est(X, T) tensor(0.3948, grad_fn=<MeanBackward0>)\n",
      "Time running:  448.5569763183594\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  58\n",
      "Train: Accuracy - 0.938, Loss - 0.195\n",
      "Test: Accuracy - 0.911, Loss - 0.208\n",
      "I(X, T) -  [6.607016514635508, 5.21505517613777, 4.021138693924102, 3.114848752456894]\n",
      "I(T, Y) -  [0.6931212603355568, 0.678616505138093, 0.670423209170863, 0.6803421767415498]\n",
      "I_est(X, T) tensor(0.2014, grad_fn=<MeanBackward0>)\n",
      "Time running:  456.66258907318115\n",
      "############################## \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Step -  59\n",
      "Train: Accuracy - 0.912, Loss - 0.218\n",
      "Test: Accuracy - 0.934, Loss - 0.163\n",
      "I(X, T) -  [6.606232838197466, 5.195313692852722, 3.7819093003869595, 2.8674718785504734]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6855772211871671, 0.6819134640190609, 0.6835544902287627]\n",
      "I_est(X, T) tensor(0.0536, grad_fn=<MeanBackward0>)\n",
      "Time running:  466.7265841960907\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  60\n",
      "Train: Accuracy - 0.938, Loss - 0.171\n",
      "Test: Accuracy - 0.999, Loss - 0.116\n",
      "I(X, T) -  [6.612686741656293, 5.163633978265572, 3.7473708849556746, 2.99588991481546]\n",
      "I(T, Y) -  [0.6931212603355565, 0.688475571525498, 0.686710976240078, 0.6883330441861887]\n",
      "I_est(X, T) tensor(0.5540, grad_fn=<MeanBackward0>)\n",
      "Time running:  475.6713762283325\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  61\n",
      "Train: Accuracy - 0.999, Loss - 0.122\n",
      "Test: Accuracy - 0.999, Loss - 0.078\n",
      "I(X, T) -  [6.601395554002061, 5.12216775463635, 3.6423964766869634, 2.9285993764359435]\n",
      "I(T, Y) -  [0.6931212603355577, 0.6910990963289699, 0.6906563061540485, 0.6913564079434853]\n",
      "I_est(X, T) tensor(0.7506, grad_fn=<MeanBackward0>)\n",
      "Time running:  484.1118960380554\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  62\n",
      "Train: Accuracy - 0.999, Loss - 0.084\n",
      "Test: Accuracy - 0.999, Loss - 0.054\n",
      "I(X, T) -  [6.585817230540996, 5.094011790055494, 3.6076003191446158, 2.900879059559184]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6931212603355497, 0.6919031401062062, 0.6931212603355522]\n",
      "I_est(X, T) tensor(0.7050, grad_fn=<MeanBackward0>)\n",
      "Time running:  491.5447642803192\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  63\n",
      "Train: Accuracy - 0.999, Loss - 0.062\n",
      "Test: Accuracy - 0.997, Loss - 0.046\n",
      "I(X, T) -  [6.54844771174864, 5.070226258439006, 3.672813213360441, 2.9734744272054185]\n",
      "I(T, Y) -  [0.6931212603355564, 0.6931212603355498, 0.6931212603355573, 0.6931212603355581]\n",
      "I_est(X, T) tensor(0.4486, grad_fn=<MeanBackward0>)\n",
      "Time running:  498.75633001327515\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  64\n",
      "Train: Accuracy - 0.996, Loss - 0.055\n",
      "Test: Accuracy - 0.999, Loss - 0.035\n",
      "I(X, T) -  [6.545078455723977, 5.006859801869477, 3.7466927497085294, 2.9046794067096893]\n",
      "I(T, Y) -  [0.6931212603355569, 0.6931212603355538, 0.6931212603355538, 0.6931212603355377]\n",
      "I_est(X, T) tensor(-0.1381, grad_fn=<MeanBackward0>)\n",
      "Time running:  506.03222727775574\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  65\n",
      "Train: Accuracy - 0.999, Loss - 0.044\n",
      "Test: Accuracy - 1.000, Loss - 0.028\n",
      "I(X, T) -  [6.539864740538405, 4.935830485435777, 3.87014511472064, 2.9183006125781787]\n",
      "I(T, Y) -  [0.693121260335557, 0.6931212603355636, 0.6931212603355568, 0.69312126033555]\n",
      "I_est(X, T) tensor(0.2398, grad_fn=<MeanBackward0>)\n",
      "Time running:  513.5025491714478\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  66\n",
      "Train: Accuracy - 1.000, Loss - 0.038\n",
      "Test: Accuracy - 1.000, Loss - 0.021\n",
      "I(X, T) -  [6.516938864872959, 4.947943499764421, 3.9421712154961104, 3.0579607686053505]\n",
      "I(T, Y) -  [0.6931212603355564, 0.6931212603355624, 0.6931212603355478, 0.693121260335559]\n",
      "I_est(X, T) tensor(0.5877, grad_fn=<MeanBackward0>)\n",
      "Time running:  520.8260543346405\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  67\n",
      "Train: Accuracy - 1.000, Loss - 0.030\n",
      "Test: Accuracy - 1.000, Loss - 0.017\n",
      "I(X, T) -  [6.494839095790438, 4.833674711570324, 3.82379950573476, 2.886274768330114]\n",
      "I(T, Y) -  [0.693121260335557, 0.6931212603355622, 0.6931212603355582, 0.6931212603355741]\n",
      "I_est(X, T) tensor(0.6538, grad_fn=<MeanBackward0>)\n",
      "Time running:  528.0659792423248\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  68\n",
      "Train: Accuracy - 1.000, Loss - 0.026\n",
      "Test: Accuracy - 1.000, Loss - 0.015\n",
      "I(X, T) -  [6.500629334065163, 4.733561030366332, 3.789367102912499, 2.647705637088127]\n",
      "I(T, Y) -  [0.6931212603355567, 0.6931212603355615, 0.6931212603355541, 0.6931212603355932]\n",
      "I_est(X, T) tensor(0.7223, grad_fn=<MeanBackward0>)\n",
      "Time running:  535.7241590023041\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  69\n",
      "Train: Accuracy - 1.000, Loss - 0.024\n",
      "Test: Accuracy - 1.000, Loss - 0.013\n",
      "I(X, T) -  [6.525728090445797, 4.751887601599013, 3.705237277840223, 2.505290773012459]\n",
      "I(T, Y) -  [0.6931212603355569, 0.6931212603355623, 0.693121260335556, 0.6931212603355972]\n",
      "I_est(X, T) tensor(0.8673, grad_fn=<MeanBackward0>)\n",
      "Time running:  542.9980301856995\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  70\n",
      "Train: Accuracy - 1.000, Loss - 0.022\n",
      "Test: Accuracy - 1.000, Loss - 0.011\n",
      "I(X, T) -  [6.518527612139486, 4.744329581504178, 3.6510780871734494, 2.5443649436493736]\n",
      "I(T, Y) -  [0.6931212603355569, 0.6931212603355622, 0.6931212603355604, 0.6931212603356003]\n",
      "I_est(X, T) tensor(0.8617, grad_fn=<MeanBackward0>)\n",
      "Time running:  550.2613980770111\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  71\n",
      "Train: Accuracy - 1.000, Loss - 0.020\n",
      "Test: Accuracy - 1.000, Loss - 0.009\n",
      "I(X, T) -  [6.54092843314066, 4.802664615927618, 3.6207418076567186, 2.5171388679847295]\n",
      "I(T, Y) -  [0.693121260335557, 0.6931212603355525, 0.6931212603355595, 0.6931212603355842]\n",
      "I_est(X, T) tensor(0.8652, grad_fn=<MeanBackward0>)\n",
      "Time running:  557.4586141109467\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  72\n",
      "Train: Accuracy - 1.000, Loss - 0.018\n",
      "Test: Accuracy - 1.000, Loss - 0.007\n",
      "I(X, T) -  [6.558404487576249, 4.794477695447387, 3.660337270098128, 2.4103922685545847]\n",
      "I(T, Y) -  [0.6931212603355564, 0.6931212603355503, 0.6931212603355573, 0.6931212603355806]\n",
      "I_est(X, T) tensor(0.8694, grad_fn=<MeanBackward0>)\n",
      "Time running:  564.7344813346863\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  73\n",
      "Train: Accuracy - 1.000, Loss - 0.016\n",
      "Test: Accuracy - 1.000, Loss - 0.006\n",
      "I(X, T) -  [6.549413136180551, 4.7464741545140985, 3.629999577906836, 2.4205070072405763]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6931212603355607, 0.693121260335562, 0.6931212603355807]\n",
      "I_est(X, T) tensor(0.8353, grad_fn=<MeanBackward0>)\n",
      "Time running:  572.0309770107269\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  74\n",
      "Train: Accuracy - 1.000, Loss - 0.015\n",
      "Test: Accuracy - 1.000, Loss - 0.005\n",
      "I(X, T) -  [6.544811176110045, 4.711419979797324, 3.7090483963261796, 2.3961502090555524]\n",
      "I(T, Y) -  [0.6931212603355572, 0.6931212603355615, 0.6931212603355528, 0.6931212603355781]\n",
      "I_est(X, T) tensor(0.9252, grad_fn=<MeanBackward0>)\n",
      "Time running:  579.3116552829742\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  75\n",
      "Train: Accuracy - 1.000, Loss - 0.014\n",
      "Test: Accuracy - 1.000, Loss - 0.005\n",
      "I(X, T) -  [6.534116576991055, 4.730417645911987, 3.749430816415649, 2.444266711165819]\n",
      "I(T, Y) -  [0.693121260335557, 0.6931212603355608, 0.6931212603355486, 0.6931212603355753]\n",
      "I_est(X, T) tensor(0.9670, grad_fn=<MeanBackward0>)\n",
      "Time running:  588.4924762248993\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  76\n",
      "Train: Accuracy - 1.000, Loss - 0.013\n",
      "Test: Accuracy - 1.000, Loss - 0.004\n",
      "I(X, T) -  [6.524356194470952, 4.773095032413493, 3.804751394214877, 2.409928998395446]\n",
      "I(T, Y) -  [0.6931212603355569, 0.6931212603355553, 0.693121260335546, 0.693121260335566]\n",
      "I_est(X, T) tensor(1.0158, grad_fn=<MeanBackward0>)\n",
      "Time running:  596.2371351718903\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  77\n",
      "Train: Accuracy - 1.000, Loss - 0.012\n",
      "Test: Accuracy - 1.000, Loss - 0.004\n",
      "I(X, T) -  [6.544593341641747, 4.8097239260804345, 3.7569522768693777, 2.365701579870206]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6931212603355483, 0.6931212603355597, 0.6931212603355579]\n",
      "I_est(X, T) tensor(1.0246, grad_fn=<MeanBackward0>)\n",
      "Time running:  603.5709750652313\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  78\n",
      "Train: Accuracy - 1.000, Loss - 0.012\n",
      "Test: Accuracy - 1.000, Loss - 0.003\n",
      "I(X, T) -  [6.510859310783533, 4.781151085775669, 3.8327427625771375, 2.456771387481725]\n",
      "I(T, Y) -  [0.6931212603355564, 0.6931212603355564, 0.6931212603355531, 0.6931212603355622]\n",
      "I_est(X, T) tensor(1.0655, grad_fn=<MeanBackward0>)\n",
      "Time running:  610.8759212493896\n",
      "############################## \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Step -  79\n",
      "Train: Accuracy - 1.000, Loss - 0.011\n",
      "Test: Accuracy - 1.000, Loss - 0.003\n",
      "I(X, T) -  [6.520194073205991, 4.7385180371013975, 3.866445704962018, 2.6636626383713113]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6931212603355587, 0.6931212603355537, 0.6931212603355703]\n",
      "I_est(X, T) tensor(1.1103, grad_fn=<MeanBackward0>)\n",
      "Time running:  619.5271229743958\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  80\n",
      "Train: Accuracy - 1.000, Loss - 0.011\n",
      "Test: Accuracy - 1.000, Loss - 0.003\n",
      "I(X, T) -  [6.530590137027569, 4.7602881594475175, 3.8214116283769135, 2.7141956150090163]\n",
      "I(T, Y) -  [0.6931212603355564, 0.6931212603355554, 0.6931212603355599, 0.6931212603355612]\n",
      "I_est(X, T) tensor(1.1423, grad_fn=<MeanBackward0>)\n",
      "Time running:  629.9294490814209\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  81\n",
      "Train: Accuracy - 1.000, Loss - 0.010\n",
      "Test: Accuracy - 1.000, Loss - 0.002\n",
      "I(X, T) -  [6.539643156557417, 4.8088059259626235, 3.8608951797575974, 2.731445711903856]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6931212603355531, 0.6931212603355541, 0.6931212603355703]\n",
      "I_est(X, T) tensor(1.1754, grad_fn=<MeanBackward0>)\n",
      "Time running:  637.7080671787262\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  82\n",
      "Train: Accuracy - 1.000, Loss - 0.010\n",
      "Test: Accuracy - 1.000, Loss - 0.002\n",
      "I(X, T) -  [6.5384573528402115, 4.812293743570114, 3.8892522822403044, 2.6976072373925426]\n",
      "I(T, Y) -  [0.6931212603355569, 0.6931212603355487, 0.6931212603355583, 0.6931212603355805]\n",
      "I_est(X, T) tensor(1.1758, grad_fn=<MeanBackward0>)\n",
      "Time running:  644.9528992176056\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  83\n",
      "Train: Accuracy - 1.000, Loss - 0.009\n",
      "Test: Accuracy - 1.000, Loss - 0.002\n",
      "I(X, T) -  [6.553447062331306, 4.822134026772665, 3.8950115144253665, 2.6858738211541096]\n",
      "I(T, Y) -  [0.6931212603355565, 0.6931212603355479, 0.6931212603355572, 0.6931212603355689]\n",
      "I_est(X, T) tensor(1.2070, grad_fn=<MeanBackward0>)\n",
      "Time running:  652.280846118927\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  84\n",
      "Train: Accuracy - 1.000, Loss - 0.009\n",
      "Test: Accuracy - 1.000, Loss - 0.002\n",
      "I(X, T) -  [6.523853971047064, 4.8088979220244035, 3.9560243109411974, 2.734049082539908]\n",
      "I(T, Y) -  [0.6931212603355567, 0.6931212603355481, 0.6931212603355545, 0.6931212603355622]\n",
      "I_est(X, T) tensor(1.2077, grad_fn=<MeanBackward0>)\n",
      "Time running:  659.9061861038208\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  85\n",
      "Train: Accuracy - 1.000, Loss - 0.009\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.553515172553609, 4.819230042718024, 3.901059615351618, 2.6861518204885]\n",
      "I(T, Y) -  [0.6931212603355569, 0.6931212603355481, 0.6931212603355555, 0.6931212603355646]\n",
      "I_est(X, T) tensor(1.2282, grad_fn=<MeanBackward0>)\n",
      "Time running:  667.2214410305023\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  86\n",
      "Train: Accuracy - 1.000, Loss - 0.008\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.550040372027613, 4.866426178117506, 3.9307926109918254, 2.69421777057977]\n",
      "I(T, Y) -  [0.6931212603355567, 0.6931212603355483, 0.693121260335556, 0.6931212603355679]\n",
      "I_est(X, T) tensor(1.2643, grad_fn=<MeanBackward0>)\n",
      "Time running:  674.6481552124023\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  87\n",
      "Train: Accuracy - 1.000, Loss - 0.008\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.547269476215632, 4.88320658356242, 3.9517534042411313, 2.6304525713668325]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6931212603355479, 0.6931212603355537, 0.6931212603355672]\n",
      "I_est(X, T) tensor(1.2841, grad_fn=<MeanBackward0>)\n",
      "Time running:  682.1802592277527\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  88\n",
      "Train: Accuracy - 1.000, Loss - 0.008\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.536324989603589, 4.917204752074075, 3.9184523220849212, 2.67742872448514]\n",
      "I(T, Y) -  [0.693121260335557, 0.6931212603355481, 0.6931212603355534, 0.6931212603355629]\n",
      "I_est(X, T) tensor(1.2889, grad_fn=<MeanBackward0>)\n",
      "Time running:  689.494647026062\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  89\n",
      "Train: Accuracy - 1.000, Loss - 0.008\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.548609659857468, 4.917288040230441, 3.939497150669388, 2.672615954803514]\n",
      "I(T, Y) -  [0.6931212603355569, 0.6931212603355482, 0.6931212603355531, 0.6931212603355625]\n",
      "I_est(X, T) tensor(1.2980, grad_fn=<MeanBackward0>)\n",
      "Time running:  697.3318071365356\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  90\n",
      "Train: Accuracy - 1.000, Loss - 0.008\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.541154039786972, 4.9578307441891445, 3.92018879360433, 2.686998307728685]\n",
      "I(T, Y) -  [0.6931212603355569, 0.6931212603355487, 0.6931212603355531, 0.6931212603355631]\n",
      "I_est(X, T) tensor(1.3059, grad_fn=<MeanBackward0>)\n",
      "Time running:  704.6757702827454\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  91\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.5375400145099825, 4.979958009821466, 3.924658484118012, 2.705425683227654]\n",
      "I(T, Y) -  [0.693121260335557, 0.6931212603355484, 0.6931212603355531, 0.6931212603355615]\n",
      "I_est(X, T) tensor(1.3479, grad_fn=<MeanBackward0>)\n",
      "Time running:  712.0283920764923\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  92\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.529966498112722, 4.971790144080421, 3.9258481184117793, 2.6762380663324965]\n",
      "I(T, Y) -  [0.6931212603355572, 0.6931212603355482, 0.6931212603355534, 0.693121260335562]\n",
      "I_est(X, T) tensor(1.3120, grad_fn=<MeanBackward0>)\n",
      "Time running:  719.296637058258\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  93\n",
      "Train: Accuracy - 1.000, Loss - 0.008\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.522149120464404, 4.964993526398193, 3.953258127547329, 2.688884487924145]\n",
      "I(T, Y) -  [0.6931212603355574, 0.6931212603355481, 0.6931212603355538, 0.6931212603355613]\n",
      "I_est(X, T) tensor(1.0544, grad_fn=<MeanBackward0>)\n",
      "Time running:  726.5851609706879\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  94\n",
      "Train: Accuracy - 1.000, Loss - 0.008\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.520750203429237, 4.97176926021779, 3.9488840424151403, 2.6580153247356875]\n",
      "I(T, Y) -  [0.6931212603355573, 0.6931212603355486, 0.6931212603355535, 0.6931212603355613]\n",
      "I_est(X, T) tensor(1.2138, grad_fn=<MeanBackward0>)\n",
      "Time running:  733.8421492576599\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  95\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.53464697160691, 4.950262140871003, 3.913059314532357, 2.64492438424447]\n",
      "I(T, Y) -  [0.6931212603355572, 0.6931212603355477, 0.6931212603355537, 0.6931212603355653]\n",
      "I_est(X, T) tensor(1.3385, grad_fn=<MeanBackward0>)\n",
      "Time running:  741.1588962078094\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  96\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.524912092777147, 4.97295681893356, 3.9004063097707298, 2.66817488275116]\n",
      "I(T, Y) -  [0.6931212603355575, 0.6931212603355482, 0.6931212603355537, 0.693121260335563]\n",
      "I_est(X, T) tensor(1.4076, grad_fn=<MeanBackward0>)\n",
      "Time running:  749.2000341415405\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  97\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.523232017188968, 4.988468373641829, 3.9489020279556555, 2.6505246228894648]\n",
      "I(T, Y) -  [0.6931212603355575, 0.6931212603355483, 0.6931212603355544, 0.6931212603355592]\n",
      "I_est(X, T) tensor(1.3078, grad_fn=<MeanBackward0>)\n",
      "Time running:  757.1644620895386\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  98\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.522038753459727, 4.978722950551768, 3.953176417715469, 2.6394032916646153]\n",
      "I(T, Y) -  [0.6931212603355571, 0.6931212603355486, 0.693121260335554, 0.6931212603355568]\n",
      "I_est(X, T) tensor(1.2445, grad_fn=<MeanBackward0>)\n",
      "Time running:  764.5486762523651\n",
      "############################## \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Step -  99\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.533787085157637, 4.972812173572327, 3.944311745158786, 2.6163556689084926]\n",
      "I(T, Y) -  [0.6931212603355571, 0.6931212603355487, 0.6931212603355544, 0.6931212603355548]\n",
      "I_est(X, T) tensor(1.4024, grad_fn=<MeanBackward0>)\n",
      "Time running:  771.9294793605804\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.543801410949726, 4.974578724937102, 3.9270723113585637, 2.5884287344990486]\n",
      "I(T, Y) -  [0.6931212603355572, 0.6931212603355487, 0.6931212603355543, 0.6931212603355514]\n",
      "I_est(X, T) tensor(1.2618, grad_fn=<MeanBackward0>)\n",
      "Time running:  779.544233083725\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  101\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.5317750593024035, 4.981010311859585, 3.9139855457914354, 2.540550251278174]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6931212603355489, 0.6931212603355541, 0.6931212603355537]\n",
      "I_est(X, T) tensor(0.9903, grad_fn=<MeanBackward0>)\n",
      "Time running:  786.8479969501495\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  102\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.529749579389053, 4.992283660419918, 3.920110958703853, 2.48726390325048]\n",
      "I(T, Y) -  [0.6931212603355563, 0.6931212603355488, 0.6931212603355539, 0.6931212603355557]\n",
      "I_est(X, T) tensor(1.3898, grad_fn=<MeanBackward0>)\n",
      "Time running:  794.1159691810608\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  103\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.518824324202691, 4.957930665149478, 3.919519165996153, 2.46488394904046]\n",
      "I(T, Y) -  [0.6931212603355565, 0.6931212603355493, 0.6931212603355539, 0.6931212603355559]\n",
      "I_est(X, T) tensor(1.1643, grad_fn=<MeanBackward0>)\n",
      "Time running:  801.4226841926575\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  104\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.506945706402923, 4.962351264485852, 3.9003903085352527, 2.4637506736062273]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6931212603355497, 0.6931212603355545, 0.6931212603355554]\n",
      "I_est(X, T) tensor(1.3703, grad_fn=<MeanBackward0>)\n",
      "Time running:  808.6708691120148\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  105\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.507326556625582, 4.977232145703401, 3.9204389109693007, 2.447445079808593]\n",
      "I(T, Y) -  [0.693121260335557, 0.6931212603355494, 0.6931212603355547, 0.6931212603355553]\n",
      "I_est(X, T) tensor(1.2715, grad_fn=<MeanBackward0>)\n",
      "Time running:  816.1415030956268\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  106\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.001\n",
      "I(X, T) -  [6.498531914254305, 4.971669445774754, 3.945274883569378, 2.428119826073024]\n",
      "I(T, Y) -  [0.6931212603355568, 0.6931212603355492, 0.6931212603355544, 0.6931212603355555]\n",
      "I_est(X, T) tensor(1.4249, grad_fn=<MeanBackward0>)\n",
      "Time running:  823.6523652076721\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  107\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.503011230905886, 4.966394094877539, 3.927123285917774, 2.4250926423535577]\n",
      "I(T, Y) -  [0.6931212603355569, 0.6931212603355493, 0.6931212603355543, 0.6931212603355547]\n",
      "I_est(X, T) tensor(1.3940, grad_fn=<MeanBackward0>)\n",
      "Time running:  830.9246461391449\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  108\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.507519538892376, 4.955660541487697, 3.9310876084523265, 2.4775678867602755]\n",
      "I(T, Y) -  [0.6931212603355569, 0.6931212603355495, 0.6931212603355547, 0.693121260335549]\n",
      "I_est(X, T) tensor(1.4386, grad_fn=<MeanBackward0>)\n",
      "Time running:  838.1610960960388\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  109\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.507266266785538, 4.958750337659126, 3.9353283220685022, 2.490980491597554]\n",
      "I(T, Y) -  [0.6931212603355569, 0.6931212603355491, 0.6931212603355547, 0.6931212603355428]\n",
      "I_est(X, T) tensor(1.4589, grad_fn=<MeanBackward0>)\n",
      "Time running:  845.4140763282776\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  110\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.514544577801468, 4.9640277281489915, 3.938331083909596, 2.4891480209979617]\n",
      "I(T, Y) -  [0.693121260335557, 0.6931212603355488, 0.6931212603355543, 0.6931212603355396]\n",
      "I_est(X, T) tensor(1.3762, grad_fn=<MeanBackward0>)\n",
      "Time running:  852.6468441486359\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  111\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.513850760927209, 4.953060954756338, 3.9406486929943254, 2.4756642556115227]\n",
      "I(T, Y) -  [0.6931212603355571, 0.6931212603355483, 0.6931212603355544, 0.6931212603355411]\n",
      "I_est(X, T) tensor(1.4968, grad_fn=<MeanBackward0>)\n",
      "Time running:  859.87988114357\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  112\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.514046683880341, 4.949349613409198, 3.939439798422137, 2.454429809452618]\n",
      "I(T, Y) -  [0.6931212603355569, 0.6931212603355483, 0.6931212603355544, 0.6931212603355463]\n",
      "I_est(X, T) tensor(1.4776, grad_fn=<MeanBackward0>)\n",
      "Time running:  867.1715252399445\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  113\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.508993511347158, 4.955614673466809, 3.9408626321527804, 2.3622774017270616]\n",
      "I(T, Y) -  [0.693121260335557, 0.6931212603355482, 0.6931212603355547, 0.6931212603355533]\n",
      "I_est(X, T) tensor(1.5610, grad_fn=<MeanBackward0>)\n",
      "Time running:  874.4485950469971\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  114\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.513205434869046, 4.953899325986827, 3.934307753145531, 2.3651093445343383]\n",
      "I(T, Y) -  [0.6931212603355571, 0.6931212603355479, 0.6931212603355548, 0.693121260335553]\n",
      "I_est(X, T) tensor(1.4083, grad_fn=<MeanBackward0>)\n",
      "Time running:  881.6963510513306\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  115\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.518063297137754, 4.937573536503058, 3.9200255064921237, 2.3406286981659132]\n",
      "I(T, Y) -  [0.6931212603355571, 0.6931212603355478, 0.693121260335555, 0.6931212603355527]\n",
      "I_est(X, T) tensor(1.5506, grad_fn=<MeanBackward0>)\n",
      "Time running:  889.0162870883942\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  116\n",
      "Train: Accuracy - 1.000, Loss - 0.007\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.521815624762691, 4.9370820177307335, 3.9195404947281482, 2.3312383752739705]\n",
      "I(T, Y) -  [0.6931212603355571, 0.6931212603355479, 0.6931212603355552, 0.6931212603355523]\n",
      "I_est(X, T) tensor(1.4066, grad_fn=<MeanBackward0>)\n",
      "Time running:  896.749480009079\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  117\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.5227846432926215, 4.92993365646605, 3.917538766171922, 2.3464319386718153]\n",
      "I(T, Y) -  [0.6931212603355571, 0.6931212603355479, 0.6931212603355552, 0.6931212603355523]\n",
      "I_est(X, T) tensor(1.5346, grad_fn=<MeanBackward0>)\n",
      "Time running:  903.9755852222443\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  118\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.518504095311183, 4.931096923260694, 3.9224880667447235, 2.357572121316026]\n",
      "I(T, Y) -  [0.6931212603355571, 0.6931212603355478, 0.6931212603355552, 0.6931212603355515]\n",
      "I_est(X, T) tensor(1.4735, grad_fn=<MeanBackward0>)\n",
      "Time running:  911.3324501514435\n",
      "############################## \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Step -  119\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.518504095311183, 4.923679079122045, 3.9178832187264563, 2.3554349868820696]\n",
      "I(T, Y) -  [0.6931212603355571, 0.6931212603355477, 0.6931212603355551, 0.6931212603355515]\n",
      "I_est(X, T) tensor(1.5500, grad_fn=<MeanBackward0>)\n",
      "Time running:  918.5393841266632\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  120\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.515858291113695, 4.927549841586874, 3.9129959371775622, 2.340635373799184]\n",
      "I(T, Y) -  [0.693121260335557, 0.6931212603355476, 0.6931212603355549, 0.6931212603355513]\n",
      "I_est(X, T) tensor(1.5890, grad_fn=<MeanBackward0>)\n",
      "Time running:  925.7794041633606\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  121\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.5197243269929706, 4.9269853755216895, 3.908394758736074, 2.3432045151389826]\n",
      "I(T, Y) -  [0.693121260335557, 0.6931212603355477, 0.6931212603355548, 0.693121260335551]\n",
      "I_est(X, T) tensor(1.4671, grad_fn=<MeanBackward0>)\n",
      "Time running:  934.4759340286255\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  122\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.518054237155953, 4.927475218406059, 3.9018936555354284, 2.3317403818826565]\n",
      "I(T, Y) -  [0.693121260335557, 0.6931212603355478, 0.6931212603355549, 0.6931212603355507]\n",
      "I_est(X, T) tensor(1.5921, grad_fn=<MeanBackward0>)\n",
      "Time running:  941.8347692489624\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  123\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.521246343774397, 4.935477110620774, 3.898952653895723, 2.3149772293936897]\n",
      "I(T, Y) -  [0.6931212603355571, 0.6931212603355476, 0.6931212603355547, 0.6931212603355499]\n",
      "I_est(X, T) tensor(1.5518, grad_fn=<MeanBackward0>)\n",
      "Time running:  949.1166551113129\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  124\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.52523046811768, 4.946335593571863, 3.895927926519636, 2.310599988019904]\n",
      "I(T, Y) -  [0.6931212603355572, 0.693121260335548, 0.6931212603355544, 0.6931212603355498]\n",
      "I_est(X, T) tensor(1.5345, grad_fn=<MeanBackward0>)\n",
      "Time running:  956.3453161716461\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  125\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.525431749360342, 4.947481172334648, 3.8826075107076163, 2.306793582482379]\n",
      "I(T, Y) -  [0.6931212603355572, 0.6931212603355478, 0.6931212603355541, 0.693121260335549]\n",
      "I_est(X, T) tensor(1.5752, grad_fn=<MeanBackward0>)\n",
      "Time running:  963.6038122177124\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  126\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.523410826721997, 4.950960480334943, 3.87589951646824, 2.2953646891843067]\n",
      "I(T, Y) -  [0.6931212603355572, 0.693121260335548, 0.6931212603355538, 0.6931212603355481]\n",
      "I_est(X, T) tensor(1.5803, grad_fn=<MeanBackward0>)\n",
      "Time running:  970.9209380149841\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  127\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.523068454051312, 4.951415863657846, 3.8656953947635047, 2.289783057745575]\n",
      "I(T, Y) -  [0.6931212603355572, 0.6931212603355481, 0.693121260335554, 0.6931212603355479]\n",
      "I_est(X, T) tensor(1.5653, grad_fn=<MeanBackward0>)\n",
      "Time running:  978.1545889377594\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  128\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.523214053005774, 4.95373803635836, 3.860038482266933, 2.284083007952471]\n",
      "I(T, Y) -  [0.6931212603355572, 0.6931212603355481, 0.693121260335554, 0.6931212603355478]\n",
      "I_est(X, T) tensor(1.6013, grad_fn=<MeanBackward0>)\n",
      "Time running:  985.4627611637115\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  129\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.5215276484848195, 4.949936247026227, 3.8625843339523502, 2.2784951791592256]\n",
      "I(T, Y) -  [0.6931212603355571, 0.6931212603355483, 0.6931212603355541, 0.6931212603355476]\n",
      "I_est(X, T) tensor(1.6153, grad_fn=<MeanBackward0>)\n",
      "Time running:  992.8664939403534\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  130\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.5255141466349915, 4.953962596003758, 3.8725093003028865, 2.278408575986696]\n",
      "I(T, Y) -  [0.6931212603355571, 0.6931212603355484, 0.6931212603355542, 0.6931212603355476]\n",
      "I_est(X, T) tensor(1.5887, grad_fn=<MeanBackward0>)\n",
      "Time running:  1000.1364161968231\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  131\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.526883963417743, 4.957000162141235, 3.877904224699311, 2.2799880858688932]\n",
      "I(T, Y) -  [0.6931212603355571, 0.6931212603355488, 0.6931212603355539, 0.6931212603355476]\n",
      "I_est(X, T) tensor(1.6056, grad_fn=<MeanBackward0>)\n",
      "Time running:  1008.5190269947052\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  132\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.526510335720904, 4.953102564703786, 3.8769270752243083, 2.276793156564064]\n",
      "I(T, Y) -  [0.6931212603355571, 0.6931212603355488, 0.6931212603355538, 0.6931212603355474]\n",
      "I_est(X, T) tensor(1.6357, grad_fn=<MeanBackward0>)\n",
      "Time running:  1016.5810203552246\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  133\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.528506357485494, 4.955058184048763, 3.870445385646649, 2.2780051773844456]\n",
      "I(T, Y) -  [0.6931212603355571, 0.6931212603355487, 0.6931212603355539, 0.6931212603355473]\n",
      "I_est(X, T) tensor(1.6083, grad_fn=<MeanBackward0>)\n",
      "Time running:  1023.9309890270233\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  134\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.527501950647149, 4.954438079726896, 3.8719686149583215, 2.2723701194484685]\n",
      "I(T, Y) -  [0.6931212603355572, 0.6931212603355484, 0.6931212603355541, 0.6931212603355472]\n",
      "I_est(X, T) tensor(1.6346, grad_fn=<MeanBackward0>)\n",
      "Time running:  1031.2232131958008\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  135\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.528951128390452, 4.956117882834991, 3.871611544885353, 2.275256224416992]\n",
      "I(T, Y) -  [0.6931212603355572, 0.6931212603355484, 0.6931212603355541, 0.6931212603355471]\n",
      "I_est(X, T) tensor(1.6254, grad_fn=<MeanBackward0>)\n",
      "Time running:  1038.6612231731415\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  136\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.522253448632079, 4.960953870065867, 3.8666684736423806, 2.2691248815945144]\n",
      "I(T, Y) -  [0.6931212603355572, 0.6931212603355487, 0.6931212603355541, 0.6931212603355471]\n",
      "I_est(X, T) tensor(1.6164, grad_fn=<MeanBackward0>)\n",
      "Time running:  1045.8981051445007\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  137\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.525677314663011, 4.965176113648718, 3.8685119053582406, 2.267810918062899]\n",
      "I(T, Y) -  [0.6931212603355573, 0.6931212603355488, 0.6931212603355542, 0.6931212603355466]\n",
      "I_est(X, T) tensor(1.6553, grad_fn=<MeanBackward0>)\n",
      "Time running:  1053.17640209198\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  138\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.528664383767037, 4.968236983365849, 3.8676374161743987, 2.2598832264489337]\n",
      "I(T, Y) -  [0.6931212603355572, 0.6931212603355488, 0.6931212603355543, 0.6931212603355456]\n",
      "I_est(X, T) tensor(1.6117, grad_fn=<MeanBackward0>)\n",
      "Time running:  1060.4149341583252\n",
      "############################## \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Step -  139\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.531454428988392, 4.971538245919839, 3.8671130262454536, 2.2557494550671215]\n",
      "I(T, Y) -  [0.6931212603355572, 0.6931212603355487, 0.6931212603355542, 0.6931212603355453]\n",
      "I_est(X, T) tensor(1.6430, grad_fn=<MeanBackward0>)\n",
      "Time running:  1067.756599187851\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  140\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.5336204686634005, 4.9671943529235945, 3.866204105467226, 2.253322323802457]\n",
      "I(T, Y) -  [0.6931212603355573, 0.6931212603355484, 0.6931212603355543, 0.6931212603355451]\n",
      "I_est(X, T) tensor(1.5970, grad_fn=<MeanBackward0>)\n",
      "Time running:  1618.6409561634064\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  141\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.531773721826568, 4.954643251437505, 3.862566921655536, 2.246992514430624]\n",
      "I(T, Y) -  [0.6931212603355573, 0.6931212603355489, 0.6931212603355542, 0.6931212603355447]\n",
      "I_est(X, T) tensor(1.6469, grad_fn=<MeanBackward0>)\n",
      "Time running:  1629.5055720806122\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  142\n",
      "Train: Accuracy - 1.000, Loss - 0.006\n",
      "Test: Accuracy - 1.000, Loss - 0.000\n",
      "I(X, T) -  [6.533145244013984, 4.952427289766216, 3.8609063501184813, 2.234795013825977]\n",
      "I(T, Y) -  [0.6931212603355572, 0.6931212603355488, 0.6931212603355541, 0.6931212603355438]\n",
      "I_est(X, T) tensor(1.6016, grad_fn=<MeanBackward0>)\n",
      "Time running:  1637.405377149582\n",
      "############################## \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1cb90a6b03e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi_xt_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi_ty_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0mmi_xt_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmi_ty_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_with_mi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-1cb90a6b03e7>\u001b[0m in \u001b[0;36mtrain_with_mi\u001b[0;34m(x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hidden_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMLP_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mmi_gradient_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmi_estimation_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmi_estimator_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mmi_gradient_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmi_gradient_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mmi_estimation_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmi_estimation_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d021067ccc8f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# Gradient for JSD mutual information estimation and EB-based estimation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Positive Samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mneg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Predictions for shuffled (negative) samples from p(z1)p(z2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m#breakpoint()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn.functional import softplus\n",
    "from collections import OrderedDict\n",
    "from data_utils import ExponentialScheduler\n",
    "\n",
    "# Defining the schedule for the update of the hyper-parameter over time\n",
    "beta_scheduler = ExponentialScheduler(start_value=1e-3, end_value=1, n_iterations=100, start_iteration=50)\n",
    "\n",
    "\n",
    "num_epochs = 2000\n",
    "dnn_hidden_units = [10, 8, 6, 4]\n",
    "x_dim = dnn_input_units = x_train.shape[1]\n",
    "y_dim = dnn_output_units = y_train.shape[1]\n",
    "z_dim = 4\n",
    "eval_freq = 1\n",
    "beta = 0.01\n",
    "\n",
    "def get_hidden_layers(net, names, input_tensor):\n",
    "    with torch.no_grad():\n",
    "        #hidden_layers_output = {}\n",
    "        hidden_layers_output = []\n",
    "        for name in names:\n",
    "#             hidden_layers_output[name] = net(input_tensor.float(), exitLayer=name).data.numpy()\n",
    "            hidden_layers_output.append(net(input_tensor.float(), exitLayer=name))#.data.numpy())\n",
    "    return hidden_layers_output\n",
    "\n",
    "# train the neural network and obtain mutual information\n",
    "def train_with_mi(x_train, y_train, x_test, y_test):\n",
    "    t_names = ['Linear0', 'Linear1', 'Linear2', 'Linear3']\n",
    "    mi_xt_all = []; mi_ty_all = []; epochs = []\n",
    "    \n",
    "    MLP_object = MLP(dnn_input_units, dnn_hidden_units, dnn_output_units).to(device)\n",
    "    mi_estimator_X = MIEstimator(x_dim, z_dim) \n",
    "    mi_estimator_Y = MIEstimator(z_dim, y_dim)\n",
    "    print(get_named_layers(MLP_object))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    #optimizer = optim.SGD(MLP_object.parameters(), lr=0.1)#, momentum=0.2)\n",
    "\n",
    "    optimizer = Adam([\n",
    "    {'params': MLP_object.parameters(), 'lr':1e-1},\n",
    "#     {'params': encoder_v_2.parameters(), 'lr':1e-4}, # There is only one encoder in this example\n",
    "    {'params': mi_estimator_X.parameters(), 'lr':1e-2},\n",
    "    #{'params': mi_estimator_Y.parameters(), 'lr':1e-4},\n",
    "])\n",
    "    \n",
    "    X_test, Y_test = torch.tensor(x_test, requires_grad=False).to(device).float(), torch.tensor(y_test, requires_grad=False).to(device)\n",
    "    accuracy_evaluation = {'train': [], 'test': []}\n",
    "    loss_evaluation = {'train': [], 'test': []}\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        X_train, Y_train = torch.from_numpy(x_train).to(device).float(), torch.from_numpy(y_train).to(device)\n",
    "        encoding = get_hidden_layers(MLP_object, t_names, X_train)\n",
    "        mi_gradient_X, mi_estimation_X = mi_estimator_X(X_train, encoding[-1])\n",
    "        mi_gradient_X = mi_gradient_X.mean()\n",
    "        mi_estimation_X = mi_estimation_X.mean()\n",
    "\n",
    "#         mi_gradient_Y, mi_estimation_Y = mi_estimator_Y(encoding[-1], Y_train.float())\n",
    "#         mi_gradient_Y = mi_gradient_Y.mean()\n",
    "#         mi_estimation_Y = mi_estimation_Y.mean()\n",
    "        \n",
    "        beta = beta_scheduler(epoch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out =  MLP_object(X_train.float())\n",
    "        loss = criterion(out, Y_train.argmax(dim=1)) - beta * mi_gradient_X\n",
    "        #loss_mi = \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "        if epoch % eval_freq == 0 or epoch == num_epochs - 1:\n",
    "            mi_xt, mi_ty = get_mutual_information(encoding)\n",
    "            mi_xt_all.append(mi_xt)\n",
    "            mi_ty_all.append(mi_ty)\n",
    "            epochs.append(epoch)\n",
    "            #accuracy_evaluation['train'].append(accuracy(out, y_train))\n",
    "            #accuracy_evaluation['test'].append(accuracy(MLP_object(X_test), y_test))\n",
    "            #loss_evaluation['train'].append(loss)\n",
    "            #loss_evaluation['test'].append(criterion(MLP_object(X_test), Y_test.argmax(dim=1)))\n",
    "            print('#'*30)\n",
    "            print('Step - ', epoch)\n",
    "            print('Train: Accuracy - %0.3f, Loss - %0.3f' % (accuracy(out, Y_train), loss))\n",
    "            print('Test: Accuracy - %0.3f, Loss - %0.3f' % (accuracy(MLP_object(X_test), Y_test), criterion(MLP_object(X_test), Y_test.argmax(dim=1))))\n",
    "            print('I(X, T) - ', mi_xt)\n",
    "            print('I(T, Y) - ', mi_ty)\n",
    "            print('I_est(X, T)', mi_estimation_X)\n",
    "            print('Time running: ', time.time() - start_time)\n",
    "            print('#'*30,'\\n')\n",
    "    \n",
    "    return np.array(mi_xt_all), np.array(mi_ty_all), np.array(epochs)\n",
    "    \n",
    "mi_xt_all, mi_ty_all, epochs = train_with_mi(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,  100,  200,  300,  400,  500,  600,  700,  800,  900, 1000,\n",
       "       1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 1999])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a movie showing the evolution of the hidden layers with the training epochs in the information plane. We can clearly see two distinct optimization phases in the information plane, as discussed in the paper. During the first *empirical error minimization* (ERM) phase (until around epoch 1500), the information on the outputs $I_Y$ increases quickly, and then during the second *representation compression* phase (from around epoch 1500 onwards), the information on the inputs $I_X$ decreases. The evolution is not as smooth as shown in the paper, because it is the result of only one network, instead of average of multiple networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.set_xlim((3,7))\n",
    "ax.set_ylim((0.1,0.7))\n",
    "ax.set_xlabel('I(X;T)')\n",
    "ax.set_ylabel('I(T;Y)')\n",
    "title = ax.set_title('')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"576\" height=\"576\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAAA9uW1kYXQAAAKuBgX//6rcRem9\n",
       "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTUyIHIyODU0IGU5YTU5MDMgLSBILjI2NC9NUEVHLTQg\n",
       "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE3IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
       "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
       "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
       "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
       "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9NiBsb29r\n",
       "YWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFj\n",
       "ZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJh\n",
       "bWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdl\n",
       "aWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MTAgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVz\n",
       "aD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBx\n",
       "cG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAABISZYiE\n",
       "ABH//veIHzLLafk613IR560urR9Q7kZxXqS9/iAAAAMAAAMADhIIszNu7bARC4AAAgIANIoF6m88\n",
       "WmhmAK+BNhfdbcNmurDxe14S2SfGHsIdhslb2X3uqp7L80aXAOm544RxZZRaD2cTB72XmFqeVnr0\n",
       "ptpvtFq01CPRkm0mVpQjt6W7Gf/izCqe49m+hBII5iaGbXtRkw2oUKMV7rvVIsLr+YMHLbgueuUj\n",
       "pn2kgtOu2n2e/0i9zoULmiW9lb/i/qHqmSvdUUSCwJVL64Bt4cUkTCXamCQjPibvOVADWetXEUrT\n",
       "tLHH4YVNPKYcY5uBbs5Kva5IN3Tza5FWKRBOGxO5rmoZYofOaebelPNTu+iUdE3JN9OCY8dFqQmb\n",
       "uXpY1Ufx4rdN7TadSpN+wmBTedllbsmmmP/sai7OVwJv1gZbIR3vWl89GrBPx3cIr3cb5c9+F/xD\n",
       "lzf7w30udKWD9v48IfzO5RjpEitSFMwLql3wzPe2M5tf7lymOCgTZCvZHQbAWoadDVl8oBbtH3IW\n",
       "J6L23lrzUq9b4Cpj6kS9ntPpinTHwVuzqnQPIRfCvwzyfTfXW+UROGIH+JfhZ32s0zjSJM1XO7Kz\n",
       "FMUL9Q8rQtv/ne8E394s5VQYouemJwp2WUNSdWpzbFJxiza2Bf/fyh5dYF795OqN6hNYVo/VXuMl\n",
       "vTWWQzBhGy/KFAGe5tN6xQ3nfyB5xW0cudGsw7brMdB0bMFUvvA8jdCzjPqL766JV8aA79YObn8e\n",
       "xU3RZsb9aK+G4OJRKGN9wDqAsQHag1OyqomLYtA9MOB7fo8lwpj5YRxmPDSa1l/k5zgc5vPnAOqx\n",
       "uaBOWHy4w5Hde+NE4yr6VaXXfQAndul0RffnqCvD0wj2YDghtO2ugEt5fWSpPDWI/tOTFKw3+zo1\n",
       "urbU5TRTjFxpeT/yx4rgjKqM0XY3nmdcBNTt/c7cuLvafey0QIExm7lOfMiIgZLTTgYb0Juq9e+x\n",
       "EA9jHdbIwfYAB2By4vSBkghcBSZfD+dJcddXusALvcOPJa5uOOfQapcvqtGfmB5jqggUYMQ23Agv\n",
       "Hbs+yHPIp5JhyXZXSaAxgU3wzSZ+vZatCHriA032qS25yfIAX55G6rF+Vq0ndnMO+zee1G61dFXx\n",
       "+yZ+eatuM4rhkIPNpNNA8bZ6ZYKz8sj+BhtERNs6NpL35R50pqjvKM4z/LHeIwHiRfSdPAmEbool\n",
       "tUz2s5TvuK6zZqY6Eg1LWr1kjKDWQ47AiAqtDW3BgQz/T7avDl3zLWgfBVUqC8v5kVjZh8jccI71\n",
       "/sPmN3+tdg4X3cbAPnfCpaB4V3BBCr5ENfzt5XMk+AoMDnvem9AeFekZjh7TSb9osoduKzmMFGaW\n",
       "iMdOOThbNaGzwgDOmQnZwFqbwe5jx7ATFvIoXLPC6hQb41s+FCwx83VpHjDpFFUKHMXM4jAwp7bW\n",
       "7YvYZpdeJYJrz5NgB7v4LoNFskByHo8sOPHyAB/hUgKmkYVMYuJiHRf3ON/QTRIt0u0sm25z44jF\n",
       "glsPAUChBYFCg4B32rUg1Y0MKPKzQFTYEASWflVuBtmMol54S23ZEvPimMwajwu1w3SYX4mEk64Y\n",
       "hxiJiAvQvQnDf5wU1N/udj2+qZgEnOoOkI3hQhWmZfu++RoBN5vxlxvWd0uLAKRAcAWYWTD++cq5\n",
       "oBQaXdTiEmLsY+PeHtPfKESIRb4EeRLFXjwKr0GB92Ovcy0uLOB3kZvTPB9z0gmKdN+eCrZkLg/t\n",
       "E9ITwv23zTVKCJ7/nacd/Ftu0OpkOHxamAydQuQKkoLSNwg8wvwpgArbjOt9QqrbJg8hvuxBq1Tg\n",
       "/HDKxHShegGzXXwx1IQienZXY3Ea9lxaEF9YmPTGrc6Uh9H77tFlf/EflIirI3q+Sl/Wj9rODssE\n",
       "VHK+LETK234WXfMyD8gqCbnVVdphqVIUrMKh996z+WVADXjmMdbNj+yRYwzUCBY3vmeB76qgur0Z\n",
       "aeIHVVdLpPDF1tsEMs56Rs2cp7hY7dRg3GYBJQiQgvPokBdvczqh6E/saIfN164RI0DIAUtGLcmi\n",
       "jYN9tcnA9dk5uM4HGzgi1h52C5NKUcdm2xoZXVXFgbNaj3Vgu77pN01dVKJQiUr+y8BjqD0+omTj\n",
       "EDS531zbrU2xy9ErVp1jXPW+976EBvwwBXKerRfE06tst/7kVj235gpAnJK6NbFu9ZHNeOLTGrZO\n",
       "kr3tKsCn/kN66l0RCsPc7xkKyVCrYfRvHXDW7Sm+5euZMCCZ/UPp1hgnFmZuzVVwh2Q6xQd4XQ6o\n",
       "Z9Pn9b5k+HLK7AacmujGHVPNzwBy4JiEpcqJSsqtEkGz+9/vfVMaRgxGLhPb2xUoIbRnQmDllE0g\n",
       "48pfvUAAARndlyx2fxmQyrX3q12NwDTsN0qJh84QNYF7x04hkbNwyzsAC+Ws8I8C+CJCmvCqJ2AZ\n",
       "C8EqIruCsrOBr46PLk6UKs8Bbd7XNwm9/78UNPI1e2ghCMx27TDQkLSKWZrZuNNEBEUTWgpMXpnu\n",
       "aD/guzpKo3/dluzbX1hi+C00xij//5B7EtBEcMQGVShiQDnRGTxHgAZOuIQWJzGoQdbhemnEr3Gy\n",
       "pIk8XMXBDWXAy0csIL4wtUdh/Jan0NwzFiPugJEzS02A76DKDJ6sYfXLaeQxjb7HnExSymsNDdUW\n",
       "ZkOZ86y7l49FIgeL20kT9WpjN29pB4sATzmqpE0rtvC//FsXi6u64Nx58DOznLCuw+yRqPy9enV2\n",
       "peviEQA/GIvrRlGGyJziae2EpExjBN2Hvh13oMhB08I29rup00GN6Q9ELymBSUBxNmSlF+e1PFH2\n",
       "p70ASAqliLcdOCriqTXQeIAL0lVu51h9s0yP1ETtI9/W8T02yqlvku4AgNfgTtm7LMnWfFW5hjDG\n",
       "ri4c3Ututir+UY9cpN+f88QfEyZJGDTRb0wivD3REapZPTeFVt1h/d7k+F13l5gZT0lrDjSqtwWJ\n",
       "S2ThUxPhwvBsCYJOZq//X+3lgqeciwkAlOncGKuYHqVpAnNpzZdmzCFOtKFWQBS7vCF71VN16+wf\n",
       "+5tES8aJUyWdckqhUjmXYYy2Z7Pvj2kh1TlD7Hj0ZsrjptzNIj9mcFBe+JbRMjd/o75/TYSuclnd\n",
       "KU5y2zA0RIQA14vHjyVoCqW8woqlKYToP4eN+ZQJ1hYCq54z9EgIGAm1x9x8P6L49JPbxdtlJgCl\n",
       "GvSsIApNwwiLi4WUCfsOdDjWCdWmZVjzUMl6rzvoycRUXkd7QpAIg8QOe6ntwvjHu5T+4Tr8V8mt\n",
       "pVsOpXkHVzeTMNdYIWI7fBSzX30cYJKNHJqIS7968p5wPvwwnCvl/O/JWzCy+DSnYJ3jwc9vudwR\n",
       "kmZB3MoJap7QYfNxPj/hGUgQLOZzDUwDE4imw9dfy4ufrDgIkmqoWd2c7tnODIQFfb5jr1xHqE8i\n",
       "mrE9PK97ws47sUdniVKvPMsClmf+gsyCb9nqqlAO0bQf6E1kA/tbIdk5Wd0GKl946vJdURcT7vgI\n",
       "olnzgJPDeOCZRt1V+5DxaeiUJJneB+6/75/B82Ddu+PAUMthPI8jTYQVMgCYPwFuTrG491K66GIs\n",
       "n+jN9zMhZsIoVDNE8+FaX5KZPCJVx09ohic30U30D5oKGlSKY7x1n+tTzk7F5tUWnIhEx2tp+HHc\n",
       "KUiM/PzgShu091skcDT+1LhWyBgcPsutuZxKlQW7bo3ec6AIMApNT9j5/8XGTwqtUmneB8LnwRBl\n",
       "KrI4D3M5zwhRdq02XAG0F4uOKO7hZoBm6q9LQmi/I3RKfL68PcxJQg2AoyfcVeLmwhtqqRbToAIx\n",
       "QMOhyQAGyOm9XeDERHdolWQeHUR/eCx/XWOxy/gI+95pB69J28H1EfuwTMO9Lr7KYQ1fs0PmDpQ6\n",
       "/tLNCNh79qCKwVm+tNKpENQGlR9DnioAdb3jMOcAAAMAAMxHHPT4kPj6b7LYo1uR7iSsUQYUEnXL\n",
       "dLkaPU9u4zoX4FKzvnoSgCCig/qmNy1XpXG6/ecx5FOyAx9rLUpkYxsJYqcIJfDAEAwVSpdkuvEj\n",
       "8ALRgeR+Fu6CMgquyTgxZs7Bj4kLmx5sgIdT8X7VPJeU2kvYkgTZqNtywZxadDCkEbzy5RKGSTpy\n",
       "cOMVMBn2f2zsMmwST4Ed5NTMGW8xfzSwSkQdpsqSO1neoWo0++ifnRIOuHFmtxNGdXXKAdH6RC7k\n",
       "jPJTJ+aFaSVj7leY7NzHKx8PQUjwzcREHDBRpX9ebetZfKHefnn1ILbbVcW4uqUQv8qzOsjbYF2c\n",
       "8UL4t2PlXpd0nYFxjKPcS8VbjpuhDXJ/NyDkmC8tTrV+5fAfuXYHe64dIBwmwaea++uDa8/FL/7i\n",
       "wNC7/ciPaQWM9oEzzGG7Lh/ti6x1a5YW3k9/vuT7hpJPPvOfSlQ4UNNO0Z58JdpkBfiCsirnwqm/\n",
       "v3aiV4JBMAh/xg01ulsKHm6uX7sTS1YRP6cEUyJJlhnQknLLkdvzdP7WGs+Rumk0HT/HAKs0Qvxr\n",
       "l0OsGrwDO5O4gPkqtk/5rZJz/8UqwvJkCtpgcc4fYsEaAuvlzNReXRnksRQilRKtw0kg10CqApQd\n",
       "SK9bwnBcG+eZkKJgTJ/sP4qSItZirWP5ZUVUk/Yrcgp8CcXcaeu05nROPwmYDWZEYJ0F6nGLMGzz\n",
       "n3zV8X3+KjKE5/YhGUdxsxl9JIF0jW8Jk1RfrU4Rh/K9RUILf75YvsnFkdmNNykRUSwg4xoJZG/1\n",
       "5UQQj2OvkrEmZ2D/A2iEoZpOXG6khF8zFjIv7yxodgAtWOR+ahSDhY0FK/NNtdGGVPiJ29O2Lnpw\n",
       "R54E13uMOTg64g5NQqVoDDX4jzK/UuDUHjEvABaMKQ6H2tUIpRGHSxDTX0vdPVVKWTKKSRB6Lwe0\n",
       "oH37CZGizp6fkkarWZ0UXeVodGSkNRTEmsFKaqFQBgycRdREaYtPxjDL5mEDF7AbaZCX/Fbs4bgp\n",
       "fpGGSFIfEmuTpIXWPsKCbuAI1wedaxE/ImuUCcQA9aj+wkPs9VFg8Hk12LFAR1X+AsMEtTJC2ySG\n",
       "y/Ux1/8+pBnlTLUYpJbReWJ5vcgaD/+8SmM/a0e3XZgVv2OW4TWk2AyNt+aDNyi/OoooytpGsTnW\n",
       "oo37gCcLeUNiGyzbb/tmJD7wb1mXDz8CvYTB7w55arwrzwap7nddIDsI3gFXU1Ao0tNhDaW8hDHN\n",
       "G4f9hq2NOorVuD9QZhqeTb3YElMioLXLuObeXqRjTUuVjhEpLqsIt6OC32GAV5OkQkuB6RIjvIIn\n",
       "8HYZV7yooDRPRVdLi23vFRWgyfAiy2eahmeK9s5WZCs34j67y90gfXq7RSwU7bjqY25Sxq568+8W\n",
       "GmEhDJ0NRlIhB1pl5ceazm1LOiY117Mdq9Gu8FMdvHNDZAIYYD0K8BJL0NYyjqI+jinCFNBsLLSa\n",
       "A+Dc/W6scYc34zU5lsy+JeRXSw6NKKVQbTFLM7ecggr0tnYPyw1BAkC8cHaXFR8aBsGQw0lVL4hE\n",
       "ZpULk5v22ZkoFpnQqh8yYxLfJXy7Hg4cKnfkr8yfiu4woyu75lCO1smveeMPFmXeOUC/YAKMiDHw\n",
       "F3F7p4uXF+/Y4E09VaKgJFjOpjsHDIwZGCPVxB8lvhXFbU23zhD8CtK+5Ujlf/TYhA1qgzfP9gld\n",
       "VE1+cjuIjOlxqqmrWikmEed8tnaUlS0GNa0UnRMKtmzMGKs1VZUHEtvbaRwgVe9hDlPH1TslpXia\n",
       "wcKhycqXiIskqj3JYiPch9tGXqqf5N4cBcZb1e6H/+rYyq0pjygHtkaQGvAxzb2we3l33FTsIKoR\n",
       "HctjHIFUsYdQ37DS6zQUEmwVSLm9VLJPEH5FyQRa4SDUaOjZWx6dMO6qlrV5n3FTD+67WaVlVMrD\n",
       "PnfCKMZXF+4g9yKRBWjkG+bJ1as1ncqDbTEo6Qb1vLX/cILpG+zIXX95sx7xefurQpdD2631n9yv\n",
       "o4Q8YdTEbbmaZOW8ONFMgT8+U+2rjjlMu21lJzFPy6g559XZtuy4S+AAGoNWqBHs/XFjRm9QKFAM\n",
       "N9VbV+6/Bsdk7rBjmNzmQ44MArtOh9DGreuuBACC7HVhB9EZ0OMCq8gOMQHx8mEFQ1J+VnVzKmlU\n",
       "toEfe/g39e8vnLv6Ypjg5eLm9xLeOD4ysr+34fB20nLABo0gbIFcCxN18CyIy0ykv4GPlJujMBoA\n",
       "AAMAAJmBAAAO4UGaJGxBH/61KoAEwbhwAHOTNFwOm9XaIn8PXguf7m20MkrkUkDddsb16MuwBFVf\n",
       "/CVx5Sh4VjO3JFov9rCcHMfjlIyotyaMtTjT8jNRu/Jt9e5FMcpS11/CBZon5/EREKcEPcQE97bv\n",
       "FcYyxeDcKc6+4hjB8kL9FON4vO+WtiQ/SzjJX8uXAhonD8WigQ5HNUJD4ZLoDSc29t6jc1jM6Y86\n",
       "Q7ATEXhQzU706TuPGm98qFbZTmCB0h4eXaTmS/4kCxAgdEw3Jp77Hh/ogMv7NV+fdXKNkonml4M4\n",
       "cC5MKV4HqewQ57lVRJKGYvwsVJokf45BzWIUy9VLaf0quCuNrzoarSfQYzvzVRJ26XwLGCehD+my\n",
       "/r+ztlYfwxErxOaDamncHk+54hF29xY50GMwPLBJ3Y6zsOyyeRe+AmzT34eAIUa7VHWp7I1HmzIj\n",
       "cAEld1oVMFmSWyQrJYKi5SaIHZyx8e3PIsnKfAzkXzhsnxPzKcrytmYZS5LTiPHrzps4gPdBens9\n",
       "6y1hKb1iLu9s3uVMUD7wxRUgNEIw135FWaHndOezypj8Dw/Qk8XTuBPuxHUYyhuNEAVWG805qXS0\n",
       "ZKm92yVx+iPFHWSsiHNx9oVaG1ifUCQ7aI0SO2PzTByl9a+qeF3ar/etDh251WZ6E3/WxL1xTbJM\n",
       "bKFZZlIz3eM2uz2AsMvseUFs1RJ4JZHEKWtgMzgg5v4RX73mg3wHDTT+uuy6pwNX+OYH7NLzeP0w\n",
       "VlqY9EGALglJGdrpqM7wDc4HST4lGuGsQUJD4QspnS3kj+EguqpLSQ8sCDqa7Qh4eHyqvGFbjUn9\n",
       "NggTSnCEarME1qUa/sKAXgpg1yplTN6LxZYGnEE6MrdFiwi1VjmLv3X9eT7/KqfdQnMfxmqKH8z8\n",
       "LwAgZE6j72icTnXMOGGjED+zufqd3My6Sg0lFBbD1UryE5tXpX6NPX6L64swlDwTaooelP1y80cb\n",
       "dv6jh6N/OW+OnY83DAQmXFLCRgv4UKhZE+5IMQYQNCrtCMTIrJ350AbJwHSzqr5DFco+ojKNm5AM\n",
       "E4KGzUXGr16RhHJotC4j94J/9TWLldP241DUXNGQCilIFkZlIO6NPnHb4IWTlp7c8HvJ3IqbnTvN\n",
       "gZpotvhfqgVNJxxqp8QCBP5EIEsp8B8KaiqHQthHbO+DTXcbifpYFdq8FrBII07nW7Ei300KA7Fr\n",
       "mR9uS8NOmyuN//TKjpo/jvzvObkGH/99pWmj/f8iJ7X4PJDKwlLjhv/5aW4lDV9Mg6kzMPPuUR5K\n",
       "2R+ZytCjvLHuitp9effIbIQTw10VtAKhxo20z0GRsHmhArjd3tQRpocN44s2YXr5TaISnYL6BOOd\n",
       "g6qcRjB6kUhLyPQNuAOKT6G46eUCL1ArEXE7xP75+i61EAOsEErBuQI+f97HGOqBXfsObPCHPkZv\n",
       "/yazlhJQoNFBYogJi82icxHTBpqV5olXlPABbC0ltMVRXvtVa9J9NJQcnHe128Nj+g0TzKPW99YO\n",
       "BdPrYnaIm1wENbTqEPp6V4Rexb4SyGAVZgHSRnwzaS2RfnrALgOq8p3ab6EmKPSk5ToHS2vgSQkP\n",
       "deNYtAMh4/2q9H1wIDJT2h89jARi/gGugCHdRiyVqOevS2VGQL7/EclpdnZZpvYueSR3uHuP5Qbs\n",
       "5QvkvkAGiRYEF0ILIg2U3kxi/PrR7uz/78mt2t2t5rxSye9JLAJ1gXoWEh2C+/tLy+wsSv652HdA\n",
       "p976mfqPHOElrYmvuWfmD4DkAMFvFYPD8BeLf4Ma5/cceiVLA0f8X1TbEUiggyFrhtKS+tBuQOH+\n",
       "3E8RHMUy4oxFz3qqa9sgE+wZQ+lGUGRc5hWSxlfD0x1OWUBmCwm6lQ6MbjK0svf1Xfj4MilV+iMp\n",
       "5pW5lUsDPWpxY3NbikPgvPboflHCfb2T2k2g8NG3kBiD60XMt+0OTL/QciYFAW4QgQMIAkyHHoAe\n",
       "eoTkM70ejmBEpkI3+ffa8HwIYub9KtUj6cw2WUxoA48xhCxs7yHoKxYCscjc+hbzTWKG9Il666tQ\n",
       "cuaQM/pQdPJlpOZkNkTiFPHocAuXK2pn4l2t0Juu0/6iWAYOdVSAgjNXkyCbfP10oQyErUZhkZWt\n",
       "py6XXpUxCglWod3H2//65rQLsATp0aDipyB52ada8L0+ArsFfD5s1BDoTclRNBM9ttBIj6Omk1VO\n",
       "MVoql7HeDuxKGvlIMLK0BA/wvXl6/aSgEDVB9jSVsNcq+YqL89vWPUQoSwgKjgRrk3Gaxwca8G1K\n",
       "OPt/T1AhIiPPQom300KSJwrs+Omeh3hqAuU7vKYFh+UNx+QnNvmGur9cM21ZsbCzJKTsQnFRZtG+\n",
       "B8O8k0GEG1H4BF0paeRQz4D62HoMjze+FwygHifH6gxoxyu8wJ7WMBUV165ntXmxP52iwDeMtcPl\n",
       "UsegMosR0xmwmDHMMV3e7gjD/fJbfUl6ECV6vEdCB8MigBuNKoBQvlL+Mcl2E83FtbIzWpPBpGh9\n",
       "49If1z4Y1PXGTSpO2tAMhmYdt/tYgXTxMMISKzforY/0VsfLrlGobLhvtKik3ZYMC4SIU+MrtsGU\n",
       "AVAPCt9M0r7mcZYlrp0pSONI+WuYYVYPTf1gLDsIekEso6BVcF5edXkbI3ZslyfLpCt6kVNz3OtI\n",
       "fYBsxfMlu/zJPIf7f23zrg2k6wqJ33l4QaG3Zv8zwRYs5vB83gFHhRf0BzhjIA3RMDVnO3nuVhP3\n",
       "1P1Zjrv4YiJqvwoSJzoo+RlNa0WgbsvDsVvINfKlLS7mLVhEOLK7DUx5ICExEyxhzKGBfsQat2JZ\n",
       "EQAQzfuAS6OEfG8iNFdMuyKP0BNRjVIdQeatcX3tOznXt+1CtL+TkdLqPLbQmispugiL1CMORbNd\n",
       "H8i/L+PEKBA/KxHFRRKlnVVllAIV2IC4VGgaN7Od2pXaHGTn3RGBSzm7wdUhhXNfz6M7aDw/Wqif\n",
       "+yHpU6joFMO/2D/UemI9aPIQ0YoM+BWl/d3woCsgxPzYLNxgZV0S3CtVAlcPRF+NumaT5/rQybty\n",
       "Uu4a0FgdoWDe47A132rOyc9D9xTuab/+QzynBZHpA3Or9aFxQLMGADfWNudjDonyyy3LboibSYF4\n",
       "g0bVY4/a0l0rWBDK0LvuTYCpW4hcRmfKjKpzvvwKVKmY+gQYOMfjpoM2YteQN8eeIz1upVF+LYWt\n",
       "46F8uKMWHxQG6EiQW8qNfAkZfqo7XcVADWiSASKZnGCmGoeCF1g5iaRElcdNhglL+lwoZmLHUve0\n",
       "dqjanLOWhR8WdzP9Nt8UyiW0zcNxflp8HKxiKMJwEfwpmDMWxPIMHgJqqfYmR+lStQr/m0WdwExl\n",
       "L7Z8uHgjDuSi47p2nQMO2CqeoJpTla07vGvlwjzn9Ez+Hf30VRZwY7p0+zrj/qpsXDwkM9s9zVjV\n",
       "q/2LNfECkFk5l+pQbHT/bNuKatrzul2PCDoJ8COQvd6vRsng0UnzXvDxdwm/ZrmG5a3hsIXZcHfU\n",
       "iiIKSFcNXv5quHaVfNFN6QF2f7O4OmhNNVwe6RfxG0y0zlF+SWjz1hoTkUEZTkE8L6sI0KRWH/R+\n",
       "C43ptUmlnuIVc6nopveuaXQPUwJ+aPS6ZTvgIEJhJ3YofeiwUJTphBIISZ9iX1yWy32Gr15XF15q\n",
       "dmUdHG+zEe5s9gxp14i6vygOlfHYECNLlVdNeZbgEEnENiId7KN3Hks1yErEmM+s+3AVro1hp9HZ\n",
       "6ZR+gRUjTlDtRJDMoqPOvQgHKf1934e5jA2Wrz7bBzkzgC0zc/cHSoK7ZnIpdFTsuDgQorsMLmjB\n",
       "KWJb9a7c2k7SswIaHFjEamHgzh6GihyD5bvhnAzTP8OBCbFWUR739G/2lDSDBncb8BwCgfdgC5T0\n",
       "QFLIDsPBmXImgV6puuu9V4Jo2lTRWnFvTuqEg+rY/98BR36Zwl1Hj1GhpnKwcprN1aR6Akkc4WKM\n",
       "R6R093fDtfYKfgEd6bMH5Zkmo+q+3R+XLs2o4ZXpNQ1qcqgFNoMYI/OGwUMr4p943TgSaZ+Fj/eZ\n",
       "Csu22piN4BLEp0ztGYpj+Yhpw51YbmDHfZ3HECNCANLDOByOrNGcLjJZukun0UGv0bXNKddwQ7ZL\n",
       "Re9omYAwy9uaxCLk3jDEn1nMDVL9IxZlqsP8TJtxu+XA48nmEmzYa/6NWyjsC5ozcR0y+NzGkcc5\n",
       "K7Jy59Va4vT/x1rv2EQTwMy9VCmrNi/5WQkk6wM8YtGZ5vI/6CD80obGOPKZIigQiSFpRQxjrd6V\n",
       "+Z+8rxDvM8EQnl3vtZjWklukP/yytyJIIO2cgz3ogx8zVyA4n0MUxHLQgmNkJwATtKQ3dYGBXlUf\n",
       "D97WElb66vnIObI8yzrh0gAVH/323U4Cavsa0o5eSZmkGxrADr1W3Q/uhOGIO3b+nHk9q1lAxVuX\n",
       "IsPbKpMoZM0gPqKOc+38BB7R9HN5nUX0tMFX/p3lrAyTlufC6wjHciCmbkOFZKK913QawxRv4F9g\n",
       "O+yQbMT9JVuHbqgejtKfMlgexcbp7K3A8kEu7XxmQ4sOkY2QVBKCIzfvREQ9Sz3uVG6aVFUyB/2s\n",
       "3Mnl7D+WSd5g3ggeV+Shl1IkBpLo+tWx2jZXO/AVz58Ijf0N9eQCtt6U6wJCTHSyFJYWra4hYgAH\n",
       "OwKttScRQ1HtGYWsXf1lURU9cVs9+0JyJfkWqSpgs39w4gjzgoMFRMuAvvjfhHeQvYkLRRdWHN6R\n",
       "YY2OBOhvBcMoxaHiTBRcFgW4Q9IyL0g+mspdpR6sdWaQcooI1dXaVazzMnn1MBacaqU5YGG/3nkp\n",
       "yS/o0gUfscKh/XanC8Q+f9nq/VCSPv4vtxLVTncP/sEXegvcQV8PGqmkk5D4uvG5pa43Dya4t6lu\n",
       "SKD18uBMSHi0Q0kPZ7SNO5lRvIkWluHhUGIXm7Q1RmbEW4mp1iYAP7Hu8uf8O3IUFnwwf/nyzwlB\n",
       "IK8q2Fk9qVJ0JmQOWPnftUq8yZYyTMoNMdE1PLEYhXWCJijnvDBPmW0XZhw2cSHpAb+nQ9Gr0qTD\n",
       "m0BMoynDgpHhZiVPlLPY7AOxpLcHNpEke/ti5atPDrXyGI1Hun52GzWbWOqosLb9n6PUTnhkTBQw\n",
       "AAABDUGeQniHfwASST06ycAIUjIGiIzwKx9ZUban8+SGsncClElpv1aE2WZuw5+8O80SCy3dw2Uo\n",
       "xas+JijOa152CDKxThuneh4Hm5nsNPAVa1E6obhMKhXLzv4+NRZHEQ8YuJ2p+9h8CAoiQSsg9vqu\n",
       "iklvjRqOO2X1iJw7aFQGgaVAOF80VIJc/peRYQO0hqLPP0UU+4ZX93IQwj36oNbZ4pVs06a54yDn\n",
       "rWAB8Qqj2YvkQTYAFimmxCiZiYtZH67WplBSyF0fyQwVCaUsZSKY098YRCrW541LPjQGemGeYU5q\n",
       "aQgnYJfCLVnIrMuaMADk36YBOqW6F+JBT7jmnPwePU/SgF5lrmH2dftNwD0hAAABpQGeYXRDfwAa\n",
       "EK7SaABEHoJ/tpUfpVKi/ji5okZ3b87wUpxgDAm7e3Gpic8F7dAxYGPKQvLu4FNXW6YyrCxT1kRx\n",
       "pHljou068/8kjnnpy4634ChpEJTm4Gig9Y1mFF42/w9JnYdeib7YnGh4LDtcCDah2YdrmL2X2+fz\n",
       "tb3udoJvEQTP6szv7SLefLD25yjRs7wcJn/9oEUSgftGSAkMQjEo7B85GzfiDFLP+rGT8XMA2siq\n",
       "W/f8vpcpP9NeC5fBVLY+JDZAPQJchj65HQkQSdwJLFPJPZNDDt8tYPo+Ja2C9MAG84q6I4OCsEiC\n",
       "ERq6zKeaFOXHXvuj3XFSDM7fHpGgOXejq4DBJDlDkL4F9ytMcIWi0dAkBUSKkcky9E+0cpnBbZsI\n",
       "WTPCmvMgCLZD8k5vSmW5ml+/6oenAqWxtdKuexUxKTZHCV31H/1+1A6DKLAei4AWpFsZztZVZR2S\n",
       "9Wvic3KeRo0jH6uIVL+nE86mXhkrZzhNybtj5+SwgnFt8taxNNhVLPZexGFkdZXuXH+vW1+z9BhW\n",
       "T3oqBZAJEIymkzIUc44AAACjAZ5jakN/ABpjWiQAIgz/HjXs+arW7QqU8PdvP16CfKwpZNCghz1l\n",
       "u0iZJtVYHP9O5h3yAqo6xuL3sxVvlFqdjnmxLKXQqFVAJlexYBrmfBIT6JAG+hdCHUu1lgq4U1Y0\n",
       "805ULemntLcY9/fv1iofdiQZrgSg4oW6fLK7K6KH4iOOxe0eHkbrbax8PsuliajAoSDBw91ksHSx\n",
       "+S1NcBWAANUCRwAABl5BmmhJqEFomUwII//+tSqABMKZPFwAHNtiO+/EX4o0MRXsiC2osRNMgKu0\n",
       "FgnzNVbTuUhQ+QBVkAh+ou6a6s7q+hAIs5bWbqILiiKBvMs7GmStIxvMxHEWAQplKWnCwRYJKIvv\n",
       "aRBzwWY05k/fDv2mTmKmtV0SncSfbwMFXHlcqqSQKxgZTupZZdSUdf2loUMw+vQyvgeAAZheI+Pp\n",
       "IvQoyd67fkgn9dOhLRC+mDGh6C2e17fHgLvuCyt6938JDYHEZ+Kbd8k9Ky0Zu4vpvu6Rv/IHuEmD\n",
       "iifmKr5Po6XROG6FMcozddxlrkQvTXkcFXp9aiCwV7fmX19JsPFWreHlZZaOjWVjzmKCZw85mEu0\n",
       "hxvbSEfhxwbBLgj9//uT+zTBoOXTIg6yMOAiNZyHCRyJ0DHpYVlAxnMFuJOCnzlGtjPRDkWim4cj\n",
       "xz/Byuv/roz4VjHCxlUykLBj5CVnvzdoxNvOrXBXjoMIZ7i/DENG/TzjWZrum49ccKmQGjCZqzbt\n",
       "EwQj3toAr5KdR8ACB4Lw7supnOOTwnzXt7LJd4QpAPth/1flLToOS5zI6G25zI4HNZV+XPfvlCRb\n",
       "I16lhjJh+jTDCpQwByCRKh88tWqDhszNCMQC6XLZz1YdsMT3FMEHjdfx5rStEsFTnr9pI4qaJd9a\n",
       "KYC6b3gVGItRrHMnnVAdNW6aboYuCjQMNhAVrsxOzD+8G9JBe+9AdaDNdxKP5Lvp+jt8tQeMWPSm\n",
       "EuJrU3VvFL8pPyG9l5h4ZlO+jA35DqttGzVSBrAy60e7kvZ4hX/qOm9g5ahMMLlfxqPYU4OOqBZL\n",
       "DlknWv6kWVh+BOqE/ItVgS6vNKO4ZMqZ04DCYN+kzujD8HBxnJ9O5WpOqKiVJ/VejDOPZBN8QKuo\n",
       "88Dn3nomz3DB62qZLZbatVG+vL0W0dxqdjNF+Y04fbwamr0Tbekfl0zkCPJhRiiMmY1TMT9Iv1LO\n",
       "d4K5WU9Rahdr4RjJwrouc2obQ1+jkj9z5fcJgFbjbzWtHaIDi7gcX696pNPMdcVvkX3qoS9IVB4g\n",
       "voq+kx+lgTQj/w0gTpzKu7ymRmY2w/0MtpwpDwapgTigbvX4mcTLgI7L5cV2TcIR10u16qEs1nSn\n",
       "i5Ax4LkrOn5/1NRUO0UKVH800veitKEQli+MkVMMgt9Nk0ziGJuKXddIRXYHebsVdeMJYjZNY8i6\n",
       "+8BgT4Q2FoMWyww9Q2Xwn4EWYVSzPlD2JMyCWtC1AREp0yVJ+6UDaFxclRtxIp46tHtfQXBlUbBM\n",
       "wWWlQdxfE7biF9ObvvvU0RFE7ElZ56qp1EGIx9NZeXvf0aoARSlwauR1h1IPsPLz9VDknUp0BKM/\n",
       "zbKxszVdrsOwNOvvunGOCPyoXF1v2JIgt7hONxHpXKn3S5hLBUFyMkwlwyS+CottbLDkkCQieslh\n",
       "uNC8yxaioiZqiFqjF4CfYlYm+kcDkJB6vAKzpM/yza2dz4WiVC2VoSeo+vVcH9Qdy/hN3hdAdHBv\n",
       "ljzSTB1IkX3ZtsA+ow1T9PB+vmjBA+TjyTcTh3iGOtpgQQU6V/KzCcwtbkpuxv7dPkcZDfqberaP\n",
       "tC2oqlR30cE3QeLSJscXwD/yDmIxVcJjQeuj66NmeM9xACLPoiccelGhZajvtXoZX8YjJSOrH0Cw\n",
       "195y/0Q+3ukHq5Zsy3hiJfxXeX8p4AHTZSY2R23fcE8t53TNTtwygSg2P4r1FvTgeNbM8V71G1fK\n",
       "vmomA5UEOy1pHhrZed4ionP0/YlqjXAHiYtC8CUYf425e4HH/15hK4YMESAr86+v1VJQ+rhGro71\n",
       "YFHcHfA7cwqZHCKQq41Q451xgXzpl2LcV90hvYyMDhXUXiTeu3C76SkUqNJTiwFHzGJQStWr5IwY\n",
       "8bVyILIqoDgw3dNh+zHSQZkCBJn1yC4/WwibXEzB99Z2YyMqnE5lJx866MdpsGW321Jc9Uq85MaA\n",
       "npPaRHf4e+LAko2KyGSURjWiIcCGie+qC5lqQEfq8uQOmIPdKGGMTGY5GjgaEBzAjDyDJx8XyPgI\n",
       "92ynsgqvSpHpCcl4/oNKnfOiLwwI1K/+oMW9g/iMNh9AIj00kMYSrZCl33H8sOh7VdChcjW/z9YF\n",
       "sAvucuFBaN0H/KMSRiyeW71mPFMy/aLVEEtKXfpfmbfbpzWe0gCvPwTgh3XUAAYtAAAA7EGehkUR\n",
       "LDv/ABJJ4Nss9AAF8Af+IJPDV4/X06EVnkd7KVvz1iaywyK7ey4YAtscWREWXVBVe05aJigBDrhz\n",
       "albncIRO5Va4mL7fDV9E1wovnyhqi7R3az/mqOebuFq2B77vNe23ELzw3+czCgVcCjaI6eSV69kL\n",
       "tovwPAUj8U5oWGFKlY2BZD9OWsDKzTZmwPT+6rFuZul1BwszxwV2y9dW8BjajScL9AnxW2mS/OwK\n",
       "j0tSELBfClQWEvXVpnwAFFc3ULOn3vb9jyzspMjPI7z4GQqe82hPt8SnaEgj3hWFDfw4RVRQ2Bd6\n",
       "HjphAAAAmwGepXRDfwAaDSUfXPU0ACHg4SI1jKn2VsYr5R/X4HJo3bpxqFOnDC21rzy/X/LJ38QB\n",
       "3erB3T+DL8atIKd62uCIxNaqWlMyo+WRZlKqKguiHpHlCP/ck/AIll4Y40lzbKHaDmTIev8WgNIJ\n",
       "uqPCD5jDSo6HuGxm24p8pHEgi7zaVnFLs0x98nYTv+0ctBDA6hOJ/fgkZgMQACmhAAAAyAGep2pD\n",
       "fwAaXLMCwAhT3F/nf4WXHl/PVgrGZObpuDhkEJ98WbYLgDuInus67b++evCLprleWb+OrdKbI4Z/\n",
       "U8PE72rpfLsJk8jya9hyLFXgvPFbPYrGkqEK+2X58SEQ/A6wcFGxL4x6dzKm/QfNgHWjQFnYZgYF\n",
       "9pcrsfxmTIscn8BBKNY23PuwaF8YnEKo9AfTZfdO2YsgzClKxoDPJwLvOxvoJR29runqnskhxq80\n",
       "eMpQkCCrLmy2GqBC8B8x390o3EHMAAPWAAAEnUGarEmoQWyZTAgh//6qVQAJwh5MAIx91NYT4oHt\n",
       "k/U2CrLRVZQJXeoelpn87w9/+80m/0PTUhGnlVmUOjRoq0TwMBWy39ANwjL6Dc/rA3oMCuQcjTKQ\n",
       "04X5iLhe0HwuckZjMzq2fqJ6WaVAUETDrFkyc05N9CmgADQZQr193Ly+epH8jpfY3FOPeLm/9Hu1\n",
       "xP9R8WUxVnkz5wRndvazTL9iFAaAmNddSaa7WjQUzmLS971JRfCz6qHOkvktKjfgw540n1YSfbLR\n",
       "1VaJjMLfqP+B4n+0VvysUWGqdLO3idtA0HTAEqGwxJf/n2uGUBwiSbCxdRVLMSr2jI9eSyEKLysE\n",
       "h3CduWenBj7epsBCvppSNtjvfW8d12fnpKHh5EdNH6SomDzdU8F95CtSUJBy+O76MzvegojXSQXE\n",
       "l9AhCV8mP0MFH/kHkNzGn66JV/jLriWcv89Xy6Ed25XXg5W1QrTioECACkD2aX/iG5DjijOauUff\n",
       "eOoD8dyw+Y7F/JtXuyS9pv3o6M8jCpYpBQGY2K20WOhCE26LCuaZ1ybgCKzaL/WUWXqqCrFLDvwG\n",
       "rtCdxd7pmQXfV5J/ggJB5c3a41zOJGOHEGEhKzu88MCoHt8OhFw1yWTCpRqvBrilhx6EDx25Iwot\n",
       "zgTknaM1qRA/rwnMO4bZvvtqagyRcDkzlFFAQq3CL8onXCAYene1gwge7Wgxqwl53QPmpQn2a4d4\n",
       "bNPSnx3q+rtChyvTBux9QrhRSKLqSKZcP6j4dNxdmL7OWwUlW6nehjcbBaUlB6b0ljO7Gd5hM752\n",
       "U+u6nVbqyMa7koLgws7pvQ5Jr7e52ZkGYOCV/VVPg0zvbPHTPfrzVV4HFgK4uIs9PqUkUVFIFawA\n",
       "qEpLwqVTWCO9C3oVdO3zwbAG+Dad9n16oEKrIHH6FsAlXJDMHyXdVFl6MAplviFh3Rzicgp3k+Fq\n",
       "HRuPVL0jwV5xADWucuUrLXhaRrFBKmN0CsxgOe1M7HAlCISK2JR6c4ZUf47uXGt4ud9CgfIamZs6\n",
       "ktY9muVMyuV0j61FX1uWWrBoRoSZigIs8MNs07XEwa9ZK2IrtZ02rsxrOgKUTQInTT6SMpEvDw2K\n",
       "PfevjEfQidNwuBprh1SrdmHfouBJ0eoodFDOOVx7bWWfdYRLFeXM6WT1C6Igzg93YttaEoczem4r\n",
       "W8JFrFmnTaWSlex1Lf8BaUCHJQcKyfIjqwzvbz1n1CIw92d1m/rbmHIJe1Wh8Zo4/0/5OhQjwKT7\n",
       "3bBprPv9QNDYHPCTtQXYNt84njNpo+2FvkLpkVfUiWdnUbBXv2IkQ7CHvQCcYGmmWvB0wNUFpeRs\n",
       "OaTVHxh2WCQ8C7pw3R6POf+0KejvFsgGWhqNig5bXpbZDKb+7f94shlqIceS7mKh/3sq0xx0OXRW\n",
       "NnRzbevNOvBE9wIwmJOiQ2A4jj/Unt67J2NPu8aCLnxBSygE/AMxvPn8kAXm4Ddu6KIx/VG8Jlja\n",
       "KgYAGCs6zODyh8opgsfwoMPk6G97du8Ky+JWw8Tj1AyEUxvSZIUdYGICWgk51kh1XPO0mDuw/p5H\n",
       "EHs1QAABuxDkAAi4AAABMUGeykUVLDv/ABMHGah5zNp9NAA5wekymnWPbhGFk393z/5vKc4Y7TX0\n",
       "eerXvzLaUpph0i3GzWWMsblAZUw+gfJ+6QaqLSMG9nJgP2MTD2/iHWfO7ooa7a05oZGIvFVL+gVj\n",
       "jN3mdgXz+vgp4JbWwNJAKqX/613DqZ5wSa2ASq5I9Vuofw5QFJomNf2Q/Vpg3oVFAdXfRvNffwWZ\n",
       "cchv8a033g/BhgC5or7OIpSJNVcrZzSPFlHVyVBry8tw29G3utHa+h1QKt5bdMlLL7QRmxOfUwHg\n",
       "VgKjm5IzLoyBoB39HTiR4JdhZxkm4B/17xUbH6nTuHLjyia7/kVKJYp3z/7bk8XYCtqY+nGX8qKo\n",
       "iCFJAaoh3XHZPGZmB8KRA/hI5weKtyQwtdlcc2iQJwZUTRAhAAAAqQGe6XRDfwAbBCIBjPABtQ6y\n",
       "G9bM5iom4y4eyPIK5rzSt9lNTFyrpB/UjSN6zFJO1t7lnFyvfXJuqG8coYKmKpbkh7CM09kpJuTK\n",
       "WVpm9pdm5LZoFvB41Jra565nnLlAe0otBG/Eut2xZ9JT+8hbjUvTwsdpi1+g1E/YymjeRWUAPcL2\n",
       "VbfPy6MxHgfyHlL7YYnLj0fDfBXI9wAFCC5Of5n2EUYjhkAAZUAAAACSAZ7rakN/ABp8lAAiDz1Q\n",
       "smb11zF4/m2wsungJF7hXdbsN/G/82aUAEzdmZGdjsxET8Luk5TLj2OLngaWJNfchiyp09cJdjGJ\n",
       "G+qJ5l7NMp7mkn2n1/DfX+yelr2Pv2+b/QLA7eWMVcARMxH83DITQwgxTIwSAwWHz0owYxoWuH9d\n",
       "guAABtY/br/Rpn7/b+QABZQAAAJPQZrwSahBbJlMCCH//qpVAAmHNWYAA5yxKI6FsF2J+i94PTGu\n",
       "WctlubK7dwI56VxuUDVzepxb4PIJnvRrkoZk6TJZKmovPQtrnfOJ3Qr9dd2cI9CL1v9OQ1AJioHD\n",
       "/sItE+kqmEDHzmK9YQYu9azRnnxjdF4wkp4xmyzEdpLhUdKX/GeuDr7xYLqQNsg/UaMZG4w5y6ev\n",
       "oeUcq16QJ2j/K79HCaw2+jlem+7tAsCyvwU95riemxTvo+fFDxr7SL+VX/XdjnWilTkKXXTLxZr+\n",
       "XZKWFVDpMQ1DmF1wbDcYC8nMAEFIUtwFFmrBRkknHqpQUNLmJS29aIT+epI3XRm+j1bNaIOoSbGZ\n",
       "RKnEswZFygodGqUmmPbQJSrH+TDZ/KI6wN5lGoZNt1h2lIx/EejoX8QTDElTSepU2pI7io9GFgdw\n",
       "mDJ6y2IQTy7yHGMY+/P+cyz6MGyVgdb31ICLGINUh9upZVQOLCDyXpLzT6SZvyzaNnL4BpaL/0Op\n",
       "ut4C6y5sLyVZWd3Mh17Yikgz4wuXur0nxbRmf8FBBdRK/dZJJSRCvRZ+8NM7O6jMyn6Xbc0Mdv6/\n",
       "xJ0rl1M5KQJ01k/oQomUgISxKGDblsG+EqFkFAn7BYbrmL1yUYom8vAfC4dAqJXOARUFMBlRAykY\n",
       "hSBicWapNEEi39uDBTgZgX6VVMHXfp+ufopWkLZfGjH51ZmWdF/KEfDafvHjkNxcq0lTvwRFJH9T\n",
       "ZXpPshCT1ITVQV7/hn47ZTmNYzg+Z72IQ1ASbuzF4miOpVAAAAMAABnxAAAAskGfDkUVLDv/ABKK\n",
       "aCYAL6+GlY2kdSPo2AfyLy5aqS+P7LOWLZkOlO+sjfGhWMDagSTN6kN5ay+4/E1sAmJv8uSN4wwr\n",
       "11lAfuZbvJIXcNEKSKfvciQ0ok1kWBWmE2rpgD8RyOhDkJIUVSGp/e4z+2NHsEz1iJYECvn/ZIe6\n",
       "+P56vvKH7MGeyHSYAnfDVhcxNqgxUwy1tvwzs38yMWRHOYdY8d5+6k4w+fkf7OAAVlzRHTEAAABz\n",
       "AZ8tdEN/AB8T6OnaTpbcQAAiDQ6/x7XPf8UqzNP7SSnY9KJNdvReRX8svpWtvPEcGlk80PHigXAr\n",
       "mh/Tm8dav/aVWc9MgL2RxWe7sCDBxfO9MDinuSBbP8oUtLtCfoxnHFiY24AAIX2GKgFslkzRE0AB\n",
       "IwAAAGQBny9qQ38AHw7mPRMLakB4ANqgKGUYpVmoxk7zmgMPx7SwXDNFrYqts+FP8C+6qtRhznQK\n",
       "gntqbs3o0/nPnC5kMAMT4BDWpg68Hx/xRvvV5q5g/AQAAGlgUoAOL7kGcC+wADegAAABQkGbNEmo\n",
       "QWyZTAhv//6nhABJVxyYANp46W1t8no64Tzzh/eTh6amcX3lWsCLacoGY1Tt5lepeoRDLmAQB8t8\n",
       "+Qk+tDdT0iIwzAFdqOzu9WjwyeIh3FND5D58jPDJ2rjeNI7yMmKfeQYExDiqBIppEwNgd1jVxpfd\n",
       "d6FtAf+TjFGG3tdzdGgxi6CSXM2f14fguxYEWVxm9bfn+bvEXYBljCd1uF18/AhWG5dpqxQYVfi3\n",
       "w+cOMg3PHEnPmXYMyXsJQ6SGsjJkpdCE2L71Ndh44zc2SWJJmp7urp2469b6BWCEe4ZUE6Zu/x0U\n",
       "/yhK8iHq5udQCDVnhnkcFawHHLnx3MNmFvHw1eIDaxYmqK7M37mFSEJec7MRqtwVl0V48cRh0uCY\n",
       "yBmUwIBfrkgt7FuLQgzBizj7Qkef7taMsAAAAwAAFDAAAADDQZ9SRRUsO/8AEkvOQw3AANqUQWqu\n",
       "TrHijtGLJVEW4CeazeHYX7u1PFaA2sz4QSTixA3x32BoE90UB0EBESluCmDl6u3y65ZQ8wgE9Cr1\n",
       "pHiz5ByEWWsSXR/oDYE8JzMHaseUU89iENmRC624L0R8ou1Z0eXm2bmQmazbIhf8Os/zlWm7clRA\n",
       "/2JW7FiH1bB1VmrQAoAd5vc+i5upqgb7ujHV/s9AMUi8FPMqfMFtoAD31G4MswVgkS1MgSbFAfwE\n",
       "U2rBAAAAeAGfcXRDfwAafJQAIgi+NwGz7VJqsr2Zdjga/rWM35p+eX3xv/h3es6sBx+GvZtC6ODH\n",
       "eKFVSKs4Agt3w/FzSmW7bUfstuWipvdGqKJFna5c54tBSyKv24cJoQv8/y2wDWFF8A0Tn/Z90AAJ\n",
       "X9P8dn1oVtCHAAA1oAAAAFgBn3NqQ38AGmB5oAEQL9jRLv+3v+/6uZ4pr/OQeDuSz2KxAwBeeJMw\n",
       "nQDzSiQc3tl727A3QbpzJEPP+psw3VzsaF5einOsjT2NIAAo17uo+heh2hwoAAKGAAAEKm1vb3YA\n",
       "AABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAAg0AAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAA\n",
       "AAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAANUdHJh\n",
       "awAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAAg0AAAAAAAAAAAAAAAAAAAAAAABAAAAAAAA\n",
       "AAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAJAAAACQAAAAAAAJGVkdHMAAAAcZWxzdAAAAAAA\n",
       "AAABAAAINAAACAAAAQAAAAACzG1kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAKAAAAFQAVcQAAAAA\n",
       "AC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAAAndtaW5mAAAAFHZt\n",
       "aGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAAI3c3Ri\n",
       "bAAAALNzdHNkAAAAAAAAAAEAAACjYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAJAAkAASAAA\n",
       "AEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAADFhdmNDAWQA\n",
       "Fv/hABhnZAAWrNlAkBJoQAAAAwBAAAAFA8WLZYABAAZo6+PLIsAAAAAcdXVpZGtoQPJfJE/Fujml\n",
       "G88DI/MAAAAAAAAAGHN0dHMAAAAAAAAAAQAAABUAAAQAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAAC4\n",
       "Y3R0cwAAAAAAAAAVAAAAAQAACAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEA\n",
       "ABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAA\n",
       "BAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAA\n",
       "AAAAAAEAAAQAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAAAVAAAAAQAAAGhzdHN6AAAAAAAAAAAAAAAV\n",
       "AAAUyAAADuUAAAERAAABqQAAAKcAAAZiAAAA8AAAAJ8AAADMAAAEoQAAATUAAACtAAAAlgAAAlMA\n",
       "AAC2AAAAdwAAAGgAAAFGAAAAxwAAAHwAAABcAAAAFHN0Y28AAAAAAAAAAQAAACwAAABidWR0YQAA\n",
       "AFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0\n",
       "b28AAAAdZGF0YQAAAAEAAAAATGF2ZjU4LjEyLjEwMA==\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmap = plt.cm.get_cmap('cool')\n",
    "\n",
    "def animate(i):\n",
    "    title.set_text('Epoch %s' % str(epochs[i]).zfill(4))\n",
    "    ax.plot(mi_xt_all[i,:], mi_ty_all[i,:], 'k-',alpha=0.2)\n",
    "    if i > 0:\n",
    "        for j in range(n_hidden_layers):\n",
    "            ax.plot(mi_xt_all[(i-1):(i+1),j],mi_ty_all[(i-1):(i+1),j],'.-',c=cmap(j*.2),ms=10)\n",
    "    return\n",
    "\n",
    "anim = animation.FuncAnimation(fig,\n",
    "                               animate,\n",
    "                               init_func=None,\n",
    "                               frames=len(epochs),\n",
    "                               interval=100)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax.set_title('Epoch 0000 - 2999')\n",
    "fig # show full evolution process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for Linear1 10000\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.498, Loss - 0.740\n",
      "Test: Accuracy - 0.498, Loss - 0.733\n",
      "Time after last eval:  0.007537364959716797\n",
      "############################## \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ntokoven/miniconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.573, Loss - 0.685\n",
      "Test: Accuracy - 0.586, Loss - 0.685\n",
      "Time after last eval:  0.3782060146331787\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.576, Loss - 0.683\n",
      "Test: Accuracy - 0.587, Loss - 0.682\n",
      "Time after last eval:  0.6896970272064209\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  300\n",
      "Train: Accuracy - 0.580, Loss - 0.680\n",
      "Test: Accuracy - 0.589, Loss - 0.679\n",
      "Time after last eval:  1.0402953624725342\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  400\n",
      "Train: Accuracy - 0.584, Loss - 0.678\n",
      "Test: Accuracy - 0.590, Loss - 0.677\n",
      "Time after last eval:  1.3735401630401611\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  499\n",
      "Train: Accuracy - 0.579, Loss - 0.677\n",
      "Test: Accuracy - 0.587, Loss - 0.675\n",
      "Time after last eval:  1.7910621166229248\n",
      "############################## \n",
      "\n",
      "Running for Linear1 15000\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.503, Loss - 0.730\n",
      "Test: Accuracy - 0.497, Loss - 0.728\n",
      "Time after last eval:  0.011073112487792969\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.532, Loss - 0.690\n",
      "Test: Accuracy - 0.536, Loss - 0.690\n",
      "Time after last eval:  0.44704222679138184\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.577, Loss - 0.686\n",
      "Test: Accuracy - 0.577, Loss - 0.685\n",
      "Time after last eval:  1.136538028717041\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  300\n",
      "Train: Accuracy - 0.587, Loss - 0.682\n",
      "Test: Accuracy - 0.590, Loss - 0.681\n",
      "Time after last eval:  1.6778450012207031\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  400\n",
      "Train: Accuracy - 0.589, Loss - 0.679\n",
      "Test: Accuracy - 0.594, Loss - 0.679\n",
      "Time after last eval:  2.306807041168213\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  499\n",
      "Train: Accuracy - 0.592, Loss - 0.677\n",
      "Test: Accuracy - 0.598, Loss - 0.676\n",
      "Time after last eval:  2.9344139099121094\n",
      "############################## \n",
      "\n",
      "Running for Linear1 20000\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.497, Loss - 0.695\n",
      "Test: Accuracy - 0.503, Loss - 0.695\n",
      "Time after last eval:  0.010529041290283203\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.553, Loss - 0.689\n",
      "Test: Accuracy - 0.557, Loss - 0.688\n",
      "Time after last eval:  0.8111000061035156\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.556, Loss - 0.686\n",
      "Test: Accuracy - 0.564, Loss - 0.685\n",
      "Time after last eval:  1.5252430438995361\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  300\n",
      "Train: Accuracy - 0.568, Loss - 0.683\n",
      "Test: Accuracy - 0.578, Loss - 0.682\n",
      "Time after last eval:  3.5945091247558594\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  400\n",
      "Train: Accuracy - 0.566, Loss - 0.681\n",
      "Test: Accuracy - 0.576, Loss - 0.680\n",
      "Time after last eval:  5.0278480052948\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  499\n",
      "Train: Accuracy - 0.571, Loss - 0.679\n",
      "Test: Accuracy - 0.579, Loss - 0.678\n",
      "Time after last eval:  6.185112237930298\n",
      "############################## \n",
      "\n",
      "Running for Linear1 25000\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.495, Loss - 0.716\n",
      "Test: Accuracy - 0.502, Loss - 0.709\n",
      "Time after last eval:  0.013930320739746094\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.576, Loss - 0.685\n",
      "Test: Accuracy - 0.586, Loss - 0.684\n",
      "Time after last eval:  0.8812031745910645\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.588, Loss - 0.681\n",
      "Test: Accuracy - 0.591, Loss - 0.681\n",
      "Time after last eval:  1.8653910160064697\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  300\n",
      "Train: Accuracy - 0.592, Loss - 0.678\n",
      "Test: Accuracy - 0.596, Loss - 0.678\n",
      "Time after last eval:  2.8852882385253906\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  400\n",
      "Train: Accuracy - 0.587, Loss - 0.676\n",
      "Test: Accuracy - 0.591, Loss - 0.676\n",
      "Time after last eval:  3.912379026412964\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  499\n",
      "Train: Accuracy - 0.592, Loss - 0.674\n",
      "Test: Accuracy - 0.597, Loss - 0.674\n",
      "Time after last eval:  4.942373991012573\n",
      "############################## \n",
      "\n",
      "Running for Linear1 30000\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.498, Loss - 0.733\n",
      "Test: Accuracy - 0.503, Loss - 0.725\n",
      "Time after last eval:  0.012273788452148438\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.553, Loss - 0.688\n",
      "Test: Accuracy - 0.558, Loss - 0.688\n",
      "Time after last eval:  1.0395188331604004\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.565, Loss - 0.685\n",
      "Test: Accuracy - 0.569, Loss - 0.685\n",
      "Time after last eval:  2.1074917316436768\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  300\n",
      "Train: Accuracy - 0.570, Loss - 0.682\n",
      "Test: Accuracy - 0.574, Loss - 0.682\n",
      "Time after last eval:  3.2926647663116455\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  400\n",
      "Train: Accuracy - 0.574, Loss - 0.680\n",
      "Test: Accuracy - 0.579, Loss - 0.680\n",
      "Time after last eval:  4.513655662536621\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  499\n",
      "Train: Accuracy - 0.574, Loss - 0.679\n",
      "Test: Accuracy - 0.577, Loss - 0.679\n",
      "Time after last eval:  5.580305814743042\n",
      "############################## \n",
      "\n",
      "Running for Linear1 35000\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.502, Loss - 0.712\n",
      "Test: Accuracy - 0.494, Loss - 0.713\n",
      "Time after last eval:  0.02342510223388672\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.489, Loss - 0.693\n",
      "Test: Accuracy - 0.484, Loss - 0.694\n",
      "Time after last eval:  1.3408839702606201\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.540, Loss - 0.689\n",
      "Test: Accuracy - 0.528, Loss - 0.691\n",
      "Time after last eval:  2.4335951805114746\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  300\n",
      "Train: Accuracy - 0.551, Loss - 0.686\n",
      "Test: Accuracy - 0.539, Loss - 0.688\n",
      "Time after last eval:  3.650822162628174\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  400\n",
      "Train: Accuracy - 0.565, Loss - 0.683\n",
      "Test: Accuracy - 0.552, Loss - 0.686\n",
      "Time after last eval:  5.00854229927063\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  499\n",
      "Train: Accuracy - 0.569, Loss - 0.681\n",
      "Test: Accuracy - 0.557, Loss - 0.684\n",
      "Time after last eval:  6.34366512298584\n",
      "############################## \n",
      "\n",
      "Running for Linear1 40000\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.502, Loss - 0.743\n",
      "Test: Accuracy - 0.496, Loss - 0.741\n",
      "Time after last eval:  0.03294992446899414\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.535, Loss - 0.690\n",
      "Test: Accuracy - 0.522, Loss - 0.693\n",
      "Time after last eval:  1.5149941444396973\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.547, Loss - 0.687\n",
      "Test: Accuracy - 0.534, Loss - 0.690\n",
      "Time after last eval:  3.2262442111968994\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  300\n",
      "Train: Accuracy - 0.557, Loss - 0.685\n",
      "Test: Accuracy - 0.544, Loss - 0.688\n",
      "Time after last eval:  4.377676963806152\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  400\n",
      "Train: Accuracy - 0.561, Loss - 0.682\n",
      "Test: Accuracy - 0.550, Loss - 0.686\n",
      "Time after last eval:  5.979866027832031\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  499\n",
      "Train: Accuracy - 0.572, Loss - 0.680\n",
      "Test: Accuracy - 0.559, Loss - 0.684\n",
      "Time after last eval:  7.501934051513672\n",
      "############################## \n",
      "\n",
      "Running for Linear1 45000\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.499, Loss - 0.747\n",
      "Test: Accuracy - 0.515, Loss - 0.731\n",
      "Time after last eval:  0.01893019676208496\n",
      "############################## \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.550, Loss - 0.691\n",
      "Test: Accuracy - 0.549, Loss - 0.691\n",
      "Time after last eval:  1.5768342018127441\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.573, Loss - 0.686\n",
      "Test: Accuracy - 0.578, Loss - 0.686\n",
      "Time after last eval:  3.356574296951294\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  300\n",
      "Train: Accuracy - 0.574, Loss - 0.683\n",
      "Test: Accuracy - 0.580, Loss - 0.683\n",
      "Time after last eval:  4.754821300506592\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  400\n",
      "Train: Accuracy - 0.588, Loss - 0.680\n",
      "Test: Accuracy - 0.590, Loss - 0.680\n",
      "Time after last eval:  6.143790245056152\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  499\n",
      "Train: Accuracy - 0.593, Loss - 0.678\n",
      "Test: Accuracy - 0.594, Loss - 0.678\n",
      "Time after last eval:  7.420387268066406\n",
      "############################## \n",
      "\n",
      "Running for Linear1 50000\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.498, Loss - 0.718\n",
      "Test: Accuracy - 0.506, Loss - 0.713\n",
      "Time after last eval:  0.018567800521850586\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.514, Loss - 0.692\n",
      "Test: Accuracy - 0.501, Loss - 0.694\n",
      "Time after last eval:  1.798933982849121\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.544, Loss - 0.689\n",
      "Test: Accuracy - 0.539, Loss - 0.690\n",
      "Time after last eval:  3.5125539302825928\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  300\n",
      "Train: Accuracy - 0.553, Loss - 0.686\n",
      "Test: Accuracy - 0.549, Loss - 0.687\n",
      "Time after last eval:  5.1297221183776855\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  400\n",
      "Train: Accuracy - 0.565, Loss - 0.683\n",
      "Test: Accuracy - 0.561, Loss - 0.685\n",
      "Time after last eval:  7.031667947769165\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  499\n",
      "Train: Accuracy - 0.579, Loss - 0.681\n",
      "Test: Accuracy - 0.573, Loss - 0.683\n",
      "Time after last eval:  8.951871871948242\n",
      "############################## \n",
      "\n",
      "Running for Linear2 10000\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.495, Loss - 0.696\n",
      "Test: Accuracy - 0.496, Loss - 0.696\n",
      "Time after last eval:  0.012855052947998047\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.539, Loss - 0.692\n",
      "Test: Accuracy - 0.541, Loss - 0.692\n",
      "Time after last eval:  0.38973093032836914\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.561, Loss - 0.690\n",
      "Test: Accuracy - 0.557, Loss - 0.690\n",
      "Time after last eval:  0.8588948249816895\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  300\n",
      "Train: Accuracy - 0.566, Loss - 0.688\n",
      "Test: Accuracy - 0.568, Loss - 0.688\n",
      "Time after last eval:  1.3482580184936523\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  400\n",
      "Train: Accuracy - 0.570, Loss - 0.687\n",
      "Test: Accuracy - 0.573, Loss - 0.686\n",
      "Time after last eval:  1.7563400268554688\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  499\n",
      "Train: Accuracy - 0.570, Loss - 0.686\n",
      "Test: Accuracy - 0.576, Loss - 0.685\n",
      "Time after last eval:  2.281672954559326\n",
      "############################## \n",
      "\n",
      "Running for Linear2 15000\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.498, Loss - 0.764\n",
      "Test: Accuracy - 0.503, Loss - 0.754\n",
      "Time after last eval:  0.010979175567626953\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.563, Loss - 0.686\n",
      "Test: Accuracy - 0.560, Loss - 0.687\n",
      "Time after last eval:  0.7506310939788818\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.567, Loss - 0.685\n",
      "Test: Accuracy - 0.564, Loss - 0.686\n",
      "Time after last eval:  1.2592389583587646\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  300\n",
      "Train: Accuracy - 0.574, Loss - 0.683\n",
      "Test: Accuracy - 0.567, Loss - 0.685\n",
      "Time after last eval:  1.7984259128570557\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  400\n",
      "Train: Accuracy - 0.574, Loss - 0.682\n",
      "Test: Accuracy - 0.568, Loss - 0.684\n",
      "Time after last eval:  2.2909321784973145\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  499\n",
      "Train: Accuracy - 0.574, Loss - 0.682\n",
      "Test: Accuracy - 0.568, Loss - 0.683\n",
      "Time after last eval:  2.7760679721832275\n",
      "############################## \n",
      "\n",
      "Running for Linear2 20000\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.525, Loss - 0.693\n",
      "Test: Accuracy - 0.532, Loss - 0.693\n",
      "Time after last eval:  0.010953187942504883\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.543, Loss - 0.691\n",
      "Test: Accuracy - 0.547, Loss - 0.691\n",
      "Time after last eval:  0.6391170024871826\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.552, Loss - 0.689\n",
      "Test: Accuracy - 0.554, Loss - 0.689\n",
      "Time after last eval:  1.257514238357544\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  300\n",
      "Train: Accuracy - 0.572, Loss - 0.687\n",
      "Test: Accuracy - 0.571, Loss - 0.687\n",
      "Time after last eval:  1.8793342113494873\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  400\n",
      "Train: Accuracy - 0.566, Loss - 0.686\n",
      "Test: Accuracy - 0.563, Loss - 0.686\n",
      "Time after last eval:  2.4963271617889404\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  499\n",
      "Train: Accuracy - 0.566, Loss - 0.685\n",
      "Test: Accuracy - 0.562, Loss - 0.685\n",
      "Time after last eval:  3.108340263366699\n",
      "############################## \n",
      "\n",
      "Running for Linear2 25000\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.499, Loss - 0.707\n",
      "Test: Accuracy - 0.510, Loss - 0.704\n",
      "Time after last eval:  0.012850284576416016\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.449, Loss - 0.698\n",
      "Test: Accuracy - 0.455, Loss - 0.697\n",
      "Time after last eval:  0.766308069229126\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.478, Loss - 0.694\n",
      "Test: Accuracy - 0.479, Loss - 0.694\n",
      "Time after last eval:  1.5176172256469727\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  300\n",
      "Train: Accuracy - 0.536, Loss - 0.692\n",
      "Test: Accuracy - 0.533, Loss - 0.692\n",
      "Time after last eval:  2.2710671424865723\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  400\n",
      "Train: Accuracy - 0.562, Loss - 0.689\n",
      "Test: Accuracy - 0.565, Loss - 0.690\n",
      "Time after last eval:  3.0212531089782715\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  499\n",
      "Train: Accuracy - 0.564, Loss - 0.688\n",
      "Test: Accuracy - 0.564, Loss - 0.688\n",
      "Time after last eval:  3.7726571559906006\n",
      "############################## \n",
      "\n",
      "Running for Linear2 30000\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.504, Loss - 0.698\n",
      "Test: Accuracy - 0.498, Loss - 0.698\n",
      "Time after last eval:  0.01397395133972168\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.517, Loss - 0.693\n",
      "Test: Accuracy - 0.517, Loss - 0.693\n",
      "Time after last eval:  0.9214789867401123\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.551, Loss - 0.690\n",
      "Test: Accuracy - 0.562, Loss - 0.690\n",
      "Time after last eval:  1.8196089267730713\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  300\n",
      "Train: Accuracy - 0.567, Loss - 0.688\n",
      "Test: Accuracy - 0.576, Loss - 0.688\n",
      "Time after last eval:  2.7205469608306885\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  400\n",
      "Train: Accuracy - 0.569, Loss - 0.687\n",
      "Test: Accuracy - 0.575, Loss - 0.686\n",
      "Time after last eval:  3.627316951751709\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  499\n",
      "Train: Accuracy - 0.570, Loss - 0.685\n",
      "Test: Accuracy - 0.575, Loss - 0.685\n",
      "Time after last eval:  4.510875940322876\n",
      "############################## \n",
      "\n",
      "Running for Linear2 35000\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.502, Loss - 0.762\n",
      "Test: Accuracy - 0.506, Loss - 0.752\n",
      "Time after last eval:  0.02461981773376465\n",
      "############################## \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.563, Loss - 0.687\n",
      "Test: Accuracy - 0.563, Loss - 0.687\n",
      "Time after last eval:  1.366257905960083\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.567, Loss - 0.685\n",
      "Test: Accuracy - 0.566, Loss - 0.685\n",
      "Time after last eval:  2.8408658504486084\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  300\n",
      "Train: Accuracy - 0.569, Loss - 0.684\n",
      "Test: Accuracy - 0.568, Loss - 0.684\n",
      "Time after last eval:  4.306330919265747\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  400\n",
      "Train: Accuracy - 0.572, Loss - 0.683\n",
      "Test: Accuracy - 0.572, Loss - 0.683\n",
      "Time after last eval:  5.496225833892822\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  499\n",
      "Train: Accuracy - 0.573, Loss - 0.682\n",
      "Test: Accuracy - 0.573, Loss - 0.682\n",
      "Time after last eval:  6.53233003616333\n",
      "############################## \n",
      "\n",
      "Running for Linear2 40000\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.499, Loss - 0.720\n",
      "Test: Accuracy - 0.493, Loss - 0.721\n",
      "Time after last eval:  0.01856207847595215\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.464, Loss - 0.695\n",
      "Test: Accuracy - 0.458, Loss - 0.695\n",
      "Time after last eval:  1.5165691375732422\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.533, Loss - 0.692\n",
      "Test: Accuracy - 0.536, Loss - 0.692\n",
      "Time after last eval:  2.891735076904297\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  300\n",
      "Train: Accuracy - 0.554, Loss - 0.690\n",
      "Test: Accuracy - 0.562, Loss - 0.690\n",
      "Time after last eval:  4.399616003036499\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  400\n",
      "Train: Accuracy - 0.561, Loss - 0.688\n",
      "Test: Accuracy - 0.565, Loss - 0.688\n",
      "Time after last eval:  5.607693195343018\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  499\n",
      "Train: Accuracy - 0.566, Loss - 0.687\n",
      "Test: Accuracy - 0.571, Loss - 0.686\n",
      "Time after last eval:  7.25052809715271\n",
      "############################## \n",
      "\n",
      "Running for Linear2 45000\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.501, Loss - 0.746\n",
      "Test: Accuracy - 0.494, Loss - 0.746\n",
      "Time after last eval:  0.02169322967529297\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.441, Loss - 0.696\n",
      "Test: Accuracy - 0.431, Loss - 0.696\n",
      "Time after last eval:  1.934948205947876\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.508, Loss - 0.693\n",
      "Test: Accuracy - 0.507, Loss - 0.693\n",
      "Time after last eval:  3.343398094177246\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  300\n",
      "Train: Accuracy - 0.554, Loss - 0.691\n",
      "Test: Accuracy - 0.562, Loss - 0.691\n",
      "Time after last eval:  4.827588081359863\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  400\n",
      "Train: Accuracy - 0.567, Loss - 0.689\n",
      "Test: Accuracy - 0.571, Loss - 0.688\n",
      "Time after last eval:  7.069437265396118\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  499\n",
      "Train: Accuracy - 0.568, Loss - 0.687\n",
      "Test: Accuracy - 0.571, Loss - 0.687\n",
      "Time after last eval:  8.932571172714233\n",
      "############################## \n",
      "\n",
      "Running for Linear2 50000\n",
      "##############################\n",
      "Step -  0\n",
      "Train: Accuracy - 0.499, Loss - 0.736\n",
      "Test: Accuracy - 0.496, Loss - 0.733\n",
      "Time after last eval:  0.028772830963134766\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  100\n",
      "Train: Accuracy - 0.523, Loss - 0.692\n",
      "Test: Accuracy - 0.525, Loss - 0.692\n",
      "Time after last eval:  2.178661823272705\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  200\n",
      "Train: Accuracy - 0.556, Loss - 0.690\n",
      "Test: Accuracy - 0.553, Loss - 0.690\n",
      "Time after last eval:  4.563814878463745\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  300\n",
      "Train: Accuracy - 0.564, Loss - 0.688\n",
      "Test: Accuracy - 0.557, Loss - 0.689\n",
      "Time after last eval:  6.640890836715698\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  400\n",
      "Train: Accuracy - 0.572, Loss - 0.687\n",
      "Test: Accuracy - 0.566, Loss - 0.687\n",
      "Time after last eval:  8.335783004760742\n",
      "############################## \n",
      "\n",
      "##############################\n",
      "Step -  499\n",
      "Train: Accuracy - 0.580, Loss - 0.685\n",
      "Test: Accuracy - 0.574, Loss - 0.686\n",
      "Time after last eval:  9.796777963638306\n",
      "############################## \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden, n_classes):\n",
    "        super(Predictor, self).__init__()\n",
    "\n",
    "        self.layers = []\n",
    "        self.num_neurons = [n_inputs] + n_hidden + [n_classes]\n",
    "        self.models = {}\n",
    "        \n",
    "        if n_hidden == []:\n",
    "            self.layers.append(nn.Linear(self.num_neurons[0], self.num_neurons[1]))\n",
    "        else:\n",
    "            for i in range(len(self.num_neurons) - 2):\n",
    "                self.layers.append(nn.Linear(self.num_neurons[i], self.num_neurons[i+1]))\n",
    "                # self.layers.append(nn.LeakyReLU(neg_slope))\n",
    "                self.layers.append(nn.Tanh())\n",
    "                #self.layers['linear{}'.format(i+1)] = nn.Linear(self.num_neurons[i], self.num_neurons[i+1])\n",
    "                #self.layers['tanh{}'.format(i+1)] = nn.Tanh()\n",
    "                self.models['Linear{}'.format(i)] = nn.Sequential(*self.layers)\n",
    "\n",
    "\n",
    "            self.layers.append(nn.Linear(self.num_neurons[i+1], self.num_neurons[i+2]))\n",
    "        self.models['Output'] = nn.Sequential(*self.layers)\n",
    "        self.full_model = self.models['Output']\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x, exitLayer=None): \n",
    "        if exitLayer is not None:\n",
    "            out = self.models[exitLayer](x)\n",
    "        else:\n",
    "            out = self.full_model(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "    \n",
    "def train_given_z(n_train_samples, exit_layer, num_epochs=2000, dnn_hidden_units=[]):\n",
    "    \n",
    "    x_train, y_train, x_train_int = generate_samples(n_train_samples) # training dataset\n",
    "    x_test, y_test, _ = generate_samples(n_test_samples) # testing dataset\n",
    "    X_test, Y_test = torch.tensor(x_test, requires_grad=False).to(device), torch.tensor(y_test, requires_grad=False).to(device)\n",
    "\n",
    "    z_test = torch.tensor(MLP_object(X_test.float(), exitLayer=exit_layer), requires_grad=False).to(device)\n",
    "    predictor = Predictor(z_test.size(1), dnn_hidden_units, Y_test.size(1)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(predictor.parameters(), lr=0.1)#, momentum=0.2)\n",
    "\n",
    "    accuracy_evaluation = {'train': [], 'test': []}\n",
    "    loss_evaluation = {'train': [], 'test': []}\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        X_train, Y_train = torch.from_numpy(x_train).to(device), torch.from_numpy(y_train).to(device)\n",
    "        z_train = MLP_object(X_train.float(), exitLayer=exit_layer)\n",
    "        optimizer.zero_grad()\n",
    "        out =  predictor(z_train.float())\n",
    "        loss = criterion(out, Y_train.argmax(dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % eval_freq == 0 or epoch == num_epochs - 1:\n",
    "            accuracy_evaluation['train'].append(accuracy(out, Y_train))\n",
    "            accuracy_evaluation['test'].append(accuracy(predictor(MLP_object(X_test.float(), exitLayer=exit_layer)), Y_test))\n",
    "            #loss_evaluation['train'].append(loss)\n",
    "            #loss_evaluation['test'].append(criterion(MLP_object(X_test), Y_test.argmax(dim=1)))\n",
    "            print('#'*30)\n",
    "            print('Step - ', epoch)\n",
    "            print('Train: Accuracy - %0.3f, Loss - %0.3f' % (accuracy(out, Y_train), loss))\n",
    "            print('Test: Accuracy - %0.3f, Loss - %0.3f' % (accuracy(predictor(z_test.float()), Y_test), criterion(predictor(z_test.float()), Y_test.argmax(dim=1))))\n",
    "            print('Time after last eval: ', time.time() - start_time)\n",
    "            print('#'*30,'\\n')\n",
    "    return np.max(accuracy_evaluation['test'])#np.mean(accuracy_evaluation['test'][-5:])\n",
    "\n",
    "data_step = 5000\n",
    "acc = {}\n",
    "num_labels_range = np.arange(10000, n_train_samples+data_step, data_step)\n",
    "for layer in ['Linear1', 'Linear2']:\n",
    "    acc[layer] = []\n",
    "    for num_labels in num_labels_range:\n",
    "        print('Running for %s %s' % (layer, num_labels))\n",
    "        acc[layer].append(train_given_z(num_labels, layer, num_epochs=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(num_labels_range, acc['Linear1'], label='Linear1')\n",
    "plt.plot(num_labels_range, acc['Linear2'], label='Linear2')\n",
    "plt.xlabel('# labeled samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(num_labels_range, acc['Linear1'], label='Linear1')\n",
    "plt.plot(num_labels_range, acc['Linear2'], label='Linear2')\n",
    "plt.xlabel('# labeled samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
