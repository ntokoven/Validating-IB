{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "10.03 toy to mnist colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "igLHoZPbUwXk",
        "outputId": "93acea51-c683-43f1-81c5-3d870234cb9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "%pylab inline\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np\n",
        "from random import randint, seed\n",
        "\n",
        "# Flag to enable execution on GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "cuda = torch.cuda.is_available()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['randint', 'seed']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpfpprCfvc2r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b20cf76-e0ea-4887-9c52-8bc9de2ed855"
      },
      "source": [
        "device"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emsSbOzJLwCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Loading the MNIST dataset\n",
        "train_set = MNIST('./data/MNIST', download=True, train=True, transform=ToTensor())\n",
        "test_set = MNIST('./data/MNIST', download=True, train=True, transform=ToTensor())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gwfaUsKLxu3",
        "colab_type": "code",
        "outputId": "00c4d650-d2e3-42ac-c4ce-7ac46221fe57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(test_set)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./data/MNIST\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hTHGDGBxUwXu",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "n_train_samples = 60000 # number of train samples\n",
        "n_test_samples = 60000 # number of test samples\n",
        "\n",
        "np.random.seed(1234)\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "# generate samples\n",
        "seed(1234)\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Initialization of the data loader\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8 if cuda else 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZEzcIfE-UwYP",
        "colab": {}
      },
      "source": [
        "from torch.nn.functional import softplus, softmax\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, n_inputs, n_hidden, n_classes, neg_slope=0.02):\n",
        "        super(MLP, self).__init__()\n",
        "        self.n_inputs = n_inputs,\n",
        "        self.n_hidden = n_hidden,\n",
        "        self.n_classes = n_classes\n",
        "        \n",
        "        self.layers = []\n",
        "        self.num_neurons = [n_inputs] + n_hidden + [n_classes]\n",
        "        self.models = {}\n",
        "        for i in range(len(self.num_neurons) - 2):\n",
        "            self.layers.append(nn.Linear(self.num_neurons[i], self.num_neurons[i+1]))\n",
        "            self.layers.append(nn.Tanh())\n",
        "            self.models['Linear{}'.format(i)] = nn.Sequential(*self.layers)\n",
        "            \n",
        "\n",
        "        self.layers.append(nn.Linear(self.num_neurons[i+1], self.num_neurons[i+2]))\n",
        "        self.models['Output'] = nn.Sequential(*self.layers)\n",
        "        self.full_model = self.models['Output']\n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self, x, exitLayer=None): \n",
        "        if exitLayer is not None:\n",
        "            out = self.models[exitLayer](x)\n",
        "        else:\n",
        "            out = self.full_model(x)\n",
        "        return out\n",
        "'''\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, z_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        self.z_dim = z_dim\n",
        "        \n",
        "        # Vanilla MLP\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(10, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, z_dim*2),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0),-1) # Flatten the input\n",
        "        params = self.net(x)\n",
        "        \n",
        "        mu, sigma = params[:,:self.z_dim], params[:,self.z_dim:]\n",
        "        sigma = softplus(sigma) + 1e-7  # Make sigma always positive\n",
        "        \n",
        "        return Independent(Normal(loc=mu, scale=sigma), 1) # Return a factorized Normal distribution\n",
        "'''\n",
        "\n",
        "\n",
        "class VAE(nn.Module):\n",
        "\n",
        "    def __init__(self, x_dim, y_dim, z_dim=6):\n",
        "        super(VAE, self).__init__()\n",
        "        self.K = z_dim\n",
        "\n",
        "        self.encode = nn.Sequential(\n",
        "            nn.Linear(x_dim, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, 2*self.K))\n",
        "\n",
        "        self.decode = nn.Sequential(\n",
        "                nn.Linear(self.K, y_dim))\n",
        "\n",
        "    def forward(self, x, num_sample=1):\n",
        "        if x.dim() > 2 : x = x.view(x.size(0),-1)\n",
        "\n",
        "        statistics = self.encode(x)\n",
        "        mu = statistics[:,:self.K]\n",
        "        std = softplus(statistics[:,self.K:]-5,beta=1)\n",
        "\n",
        "        encoding = self.reparametrize_n(mu,std,num_sample)\n",
        "        logit = self.decode(encoding)\n",
        "\n",
        "        if num_sample == 1 : pass\n",
        "        elif num_sample > 1 : logit = softmax(logit, dim=2).mean(0)\n",
        "\n",
        "        return (mu, std), logit, encoding\n",
        "\n",
        "    def reparametrize_n(self, mu, std, n=1):\n",
        "        # reference :\n",
        "        # http://pytorch.org/docs/0.3.1/_modules/torch/distributions.html#Distribution.sample_n\n",
        "        def expand(v):\n",
        "            if isinstance(v, Number):\n",
        "                return torch.Tensor([v]).expand(n, 1)\n",
        "            else:\n",
        "                return v.expand(n, *v.size())\n",
        "\n",
        "        if n != 1 :\n",
        "            mu = expand(mu)\n",
        "            std = expand(std)\n",
        "\n",
        "        eps = Variable(std.data.new(std.size()).normal_().to(device))\n",
        "\n",
        "        return mu + eps * std\n",
        "\n",
        "    def weight_init(self):\n",
        "        for m in self._modules:\n",
        "            xavier_init(self._modules[m])\n",
        "\n",
        "\n",
        "def xavier_init(ms):\n",
        "    for m in ms :\n",
        "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "            nn.init.xavier_uniform(m.weight,gain=nn.init.calculate_gain('relu'))\n",
        "            m.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSnyGR1-sG78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x, y in train_loader:\n",
        "  x = x.flatten(start_dim=1)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tfwUDM2_UwYV",
        "colab": {}
      },
      "source": [
        "def get_named_layers(net):\n",
        "    conv2d_idx = 0\n",
        "    convT2d_idx = 0\n",
        "    linear_idx = 0\n",
        "    batchnorm2d_idx = 0\n",
        "    named_layers = {}\n",
        "    for mod in net.modules():\n",
        "        if isinstance(mod, torch.nn.Conv2d):\n",
        "            layer_name = 'Conv2d{}_{}-{}'.format(\n",
        "                conv2d_idx, mod.in_channels, mod.out_channels\n",
        "            )\n",
        "            named_layers[layer_name] = mod\n",
        "            conv2d_idx += 1\n",
        "        elif isinstance(mod, torch.nn.ConvTranspose2d):\n",
        "            layer_name = 'ConvT2d{}_{}-{}'.format(\n",
        "                conv2d_idx, mod.in_channels, mod.out_channels\n",
        "            )\n",
        "            named_layers[layer_name] = mod\n",
        "            convT2d_idx += 1\n",
        "        elif isinstance(mod, torch.nn.BatchNorm2d):\n",
        "            layer_name = 'BatchNorm2D{}_{}'.format(\n",
        "                batchnorm2d_idx, mod.num_features)\n",
        "            named_layers[layer_name] = mod\n",
        "            batchnorm2d_idx += 1\n",
        "        elif isinstance(mod, torch.nn.Linear):\n",
        "            layer_name = 'Linear{}_{}-{}'.format(\n",
        "                linear_idx, mod.in_features, mod.out_features\n",
        "            )\n",
        "            named_layers[layer_name] = mod\n",
        "            linear_idx += 1\n",
        "    return named_layers\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    accuracy = (predictions.argmax(dim=1) == targets.argmax(dim=1)).type(torch.FloatTensor).mean().item()\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GeHMyJCMUwYZ",
        "outputId": "cbfd92ee-8529-4364-a0ed-2d0487fbad8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "num_epochs = 2000\n",
        "dnn_hidden_units = [16, 12, 8, 6, 4]\n",
        "dnn_input_units = x.shape[1]\n",
        "dnn_output_units = y.shape[-1] if y.ndim > 1 else 1\n",
        "eval_freq = 100\n",
        "\n",
        "MLP_object = VAE(dnn_input_units, dnn_output_units).to(device)\n",
        "get_named_layers(MLP_object)\n",
        "#MLP_object.parameters()\n",
        "#print(MLP_object.models)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-b53755ac5431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0meval_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mMLP_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnn_input_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdnn_output_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mget_named_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMLP_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#MLP_object.parameters()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xr1RbbhZpvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "#Calculate real MI throughout training\n",
        "def calc_mutual_information(hidden):\n",
        "    n_neurons = hidden.shape[-1]\n",
        "  \n",
        "    # discretization \n",
        "    n_bins = 30\n",
        "    bins = np.linspace(-1, 1, n_bins+1)\n",
        "    indices = np.digitize(hidden, bins)\n",
        "    \n",
        "    # initialize pdfs\n",
        "    pdf_x = Counter(); pdf_y = Counter(); pdf_t = Counter(); pdf_xt = Counter(); pdf_yt = Counter()\n",
        "\n",
        "    for i in range(n_train_samples):\n",
        "        pdf_x[x_train_int[i]] += 1/float(n_train_samples)\n",
        "        pdf_y[y_train[i,0]] += 1/float(n_train_samples)      \n",
        "        pdf_xt[(x_train_int[i],)+tuple(indices[i,:])] += 1/float(n_train_samples)\n",
        "        pdf_yt[(y_train[i,0],)+tuple(indices[i,:])] += 1/float(n_train_samples)\n",
        "        pdf_t[tuple(indices[i,:])] += 1/float(n_train_samples)\n",
        "    \n",
        "    # calcuate encoder mutual information I(X;T)\n",
        "    mi_xt = 0\n",
        "    for i in pdf_xt:\n",
        "        # P(x,t), P(x) and P(t)\n",
        "        p_xt = pdf_xt[i]; p_x = pdf_x[i[0]]; p_t = pdf_t[i[1:]]\n",
        "        # I(X;T)\n",
        "        mi_xt += p_xt * np.log(p_xt / p_x / p_t)\n",
        " \n",
        "    # calculate decoder mutual information I(T;Y)\n",
        "    mi_ty = 0\n",
        "    for i in pdf_yt:\n",
        "        # P(t,y), P(t) and P(y)\n",
        "        p_yt = pdf_yt[i]; p_t = pdf_t[i[1:]]; p_y = pdf_y[i[0]]\n",
        "        # I(T;Y)\n",
        "        try:\n",
        "          mi_ty += p_yt * np.log(p_yt / p_t / p_y)\n",
        "        except ZeroDivisionError:\n",
        "          mi_ty += p_yt * np.log(p_yt / (p_t + 1e-5) / (p_y + 1e-5))\n",
        "            \n",
        "    return mi_xt, mi_ty\n",
        "\n",
        "# get mutual information for all hidden layers\n",
        "def get_mutual_information(hidden):\n",
        "    mi_xt_list = []; mi_ty_list = []\n",
        "    # for hidden in hiddens:\n",
        "    if True:\n",
        "        mi_xt, mi_ty = calc_mutual_information(hidden)\n",
        "        mi_xt_list.append(mi_xt)\n",
        "        mi_ty_list.append(mi_ty)\n",
        "    return mi_xt_list, mi_ty_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u_OKUCe-UwYf",
        "outputId": "8e78e45b-fb72-4b12-9abe-c1466d749a58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        }
      },
      "source": [
        "def train_encoder(z_dim = 6, enc_type='MLP', layer='Linear3', weight_decay=0):\n",
        "  \n",
        "    if enc_type == 'MLP':\n",
        "        Net = MLP(dnn_input_units, dnn_hidden_units, dnn_output_units).to(device)\n",
        "    elif enc_type =='VAE':\n",
        "        Net = VAE(dnn_input_units, dnn_output_units, z_dim).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(Net.parameters(), lr=3e-3, weight_decay=weight_decay)#, momentum=0.2)\n",
        "    \n",
        "    # X_test, Y_test = torch.tensor(x_test, requires_grad=False).float().to(device), torch.tensor(y_test, requires_grad=False).float().to(device)\n",
        "    accuracy_evaluation = {'train': [], 'test': []}\n",
        "    loss_evaluation = {'train': [], 'test': []}\n",
        "    mi_xt_all = []; mi_ty_all = []; epochs = []\n",
        "    start_time = time.time()\n",
        "    max_accuracy = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        for x_train, y_train in train_loader:\n",
        "            X_train, Y_train = x_train.float().to(device), y_train.to(device)\n",
        "        \n",
        "            optimizer.zero_grad()\n",
        "            if enc_type =='VAE':\n",
        "                (mu, std), out, z_train = Net(X_train)\n",
        "                #z_train = \n",
        "            else:\n",
        "                out = Net(X_train)\n",
        "            print(Y_train)\n",
        "            loss = criterion(out, Y_train)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if epoch % eval_freq == 0 or epoch == num_epochs - 1:\n",
        "            # if enc_type =='MLP':\n",
        "            #     mi_xt, mi_ty = get_mutual_information(Net.models[layer](X_train).cpu().data.numpy())\n",
        "            # else:\n",
        "            #     mi_xt, mi_ty = get_mutual_information(z_train.cpu().data.numpy())\n",
        "            # mi_xt_all.append(mi_xt)\n",
        "            # mi_ty_all.append(mi_ty)\n",
        "            print('#'*30)\n",
        "            print('Step - ', epoch)\n",
        "            if enc_type == 'VAE':\n",
        "                (_, _), out_test, z_test = Net(X_test)\n",
        "            else:\n",
        "                out_test = Net(X_test)\n",
        "            # test_loss = criterion(out_test, Y_test.argmax(dim=1))\n",
        "            print('Train: Accuracy - %0.3f, Loss - %0.3f' % (accuracy(out, Y_train), loss))\n",
        "            # print('Test: Accuracy - %0.3f, Loss - %0.3f' % (accuracy(out_test, Y_test), test_loss))\n",
        "            # print('I(X, %s) - %s' % (layer, mi_xt))\n",
        "            # print('I(%s, Y) - %s' % (layer, mi_ty))\n",
        "            print('Elapse time: ', time.time() - start_time)\n",
        "            print('#'*30,'\\n')\n",
        "            # if accuracy(out_test, Y_test) == 1 and test_loss == 0:\n",
        "            if accuracy(out, Y_train) == 1 and loss == 0:\n",
        "                break\n",
        "\n",
        "    return Net, mi_xt, mi_ty\n",
        "Encoder, true_MI_x, true_MI_y = train_encoder(enc_type='VAE', weight_decay=0.01)\n",
        "print(Encoder)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-232ee4039615>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmi_xt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmi_ty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_MI_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_MI_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'VAE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-232ee4039615>\u001b[0m in \u001b[0;36mtrain_encoder\u001b[0;34m(z_dim, enc_type, layer, weight_decay)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnn_input_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdnn_hidden_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdnn_output_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0menc_type\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m'VAE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnn_input_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdnn_output_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, momentum=0.2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z3qZ1W8XUwYr",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Neural approximation of MI starts here\n",
        "# Auxiliary network for mutual information estimation\n",
        "class MIEstimator(nn.Module):\n",
        "    def __init__(self, size1, size2):\n",
        "        super(MIEstimator, self).__init__()\n",
        "        \n",
        "        # Vanilla MLP\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(size1 + size2, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, 1),\n",
        "        )\n",
        "    \n",
        "    # Gradient for JSD mutual information estimation and EB-based estimation\n",
        "    def forward(self, x1, x2):\n",
        "        # breakpoint()\n",
        "        pos = self.net(torch.cat([x1, x2], 1)) #Positive Samples \n",
        "        neg = self.net(torch.cat([torch.roll(x1, 1, 0), x2], 1)) #Predictions for shuffled (negative) samples from p(z1)p(z2)\n",
        "        #breakpoint()\n",
        "        return -softplus(-pos).mean() - softplus(neg).mean(), pos.mean() - neg.exp().mean() + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_FkycCh9UwYw"
      },
      "source": [
        "We are now able to estimate the mutual information while training the network. We'll save the mutual information for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4rHCT2r8YuyO",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Subset\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "class Scheduler:\n",
        "    def __call__(self, **kwargs):\n",
        "        raise NotImplemented()\n",
        "\n",
        "class LinearScheduler(Scheduler):\n",
        "    def __init__(self, start_value, end_value, n_iterations, start_iteration=0):\n",
        "        self.start_value = start_value\n",
        "        self.end_value = end_value\n",
        "        self.n_iterations = n_iterations\n",
        "        self.start_iteration = start_iteration\n",
        "        self.m = (end_value - start_value) / n_iterations\n",
        "\n",
        "    def __call__(self, iteration):\n",
        "        if iteration > self.start_iteration + self.n_iterations:\n",
        "            return self.end_value\n",
        "        elif iteration <= self.start_iteration:\n",
        "            return self.start_value\n",
        "        else:\n",
        "            return (iteration - self.start_iteration) * self.m + self.start_value\n",
        "\n",
        "class ExponentialScheduler(LinearScheduler):\n",
        "    def __init__(self, start_value, end_value, n_iterations, start_iteration=0, base=10):\n",
        "        self.base = base\n",
        "\n",
        "        super(ExponentialScheduler, self).__init__(start_value=math.log(start_value, base),\n",
        "                                                   end_value=math.log(end_value, base),\n",
        "                                                   n_iterations=n_iterations,\n",
        "                                                   start_iteration=start_iteration)\n",
        "\n",
        "    def __call__(self, iteration):\n",
        "        linear_value = super(ExponentialScheduler, self).__call__(iteration)\n",
        "        return self.base ** linear_value\n",
        "\n",
        "def split(dataset, size, split_type):\n",
        "    if split_type == 'Random':\n",
        "        data_split, _ = torch.utils.data.random_split(dataset, [size, len(dataset) - size])\n",
        "    elif split_type == 'Balanced':\n",
        "        class_ids = {}\n",
        "        for idx, (_, y) in enumerate(dataset):\n",
        "            try:\n",
        "                y = int(y.item())\n",
        "            except:\n",
        "                pass\n",
        "            if y not in class_ids:\n",
        "                class_ids[y] = []\n",
        "            class_ids[y].append(idx)\n",
        "\n",
        "        ids_per_class = size // len(class_ids)\n",
        "\n",
        "        selected_ids = []\n",
        "\n",
        "        for ids in class_ids.values():\n",
        "            selected_ids += list(np.random.choice(ids, min(ids_per_class, len(ids)), replace=False))\n",
        "        data_split = torch.utils.data.Subset(dataset, selected_ids)\n",
        "\n",
        "    return data_split\n",
        "\n",
        "\n",
        "class EmbeddedDataset:\n",
        "    BLOCK_SIZE = 256xw\n",
        "\n",
        "    def __init__(self, base_dataset, encoder, enc_type, cuda=True):\n",
        "        if cuda:\n",
        "            encoder = encoder.cuda()\n",
        "        self.means, self.target = self._embed(encoder, base_dataset, cuda)\n",
        "\n",
        "    def _embed(self, encoder, dataset, cuda):\n",
        "        encoder.eval()\n",
        "\n",
        "        data_loader = torch.utils.data.DataLoader(\n",
        "            dataset,\n",
        "            batch_size=self.BLOCK_SIZE,\n",
        "            shuffle=False)\n",
        "\n",
        "        ys = []\n",
        "        reps = []\n",
        "        with torch.no_grad():\n",
        "            for x, y in data_loader:\n",
        "                if cuda:\n",
        "                    x = x.cuda()\n",
        "                    y = y.cuda()\n",
        "                if enc_type == 'VAE':\n",
        "                    (_, _), _, p_z_given_x = encoder(x)\n",
        "                else: \n",
        "                    p_z_given_x = encoder(x)\n",
        "                reps.append(p_z_given_x.detach())\n",
        "                ys.append(y)\n",
        "\n",
        "            ys = torch.cat(ys, 0)\n",
        "\n",
        "        encoder.train()\n",
        "        return reps, ys\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        y = self.target[index]\n",
        "        # x = self.means[index][0]\n",
        "        x = self.means[index // self.BLOCK_SIZE][index % self.BLOCK_SIZE]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.target.size(0)\n",
        "\n",
        "def train_and_evaluate_linear_model(train_set, test_set, solver='saga', multi_class='multinomial', tol=.1, C=2):\n",
        "    model = LogisticRegression(solver=solver, multi_class=multi_class, tol=tol, C=C)\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    x_train, y_train = build_matrix(train_set)\n",
        "    x_test, y_test = build_matrix(test_set)\n",
        "    x_train = scaler.fit_transform(x_train)\n",
        "    x_test = scaler.transform(x_test)\n",
        "\n",
        "    model.fit(x_train, y_train)\n",
        "    test_accuracy = model.score(x_test, y_test)\n",
        "    train_accuracy = model.score(x_train, y_train)\n",
        "\n",
        "    return train_accuracy, test_accuracy\n",
        "\n",
        "\n",
        "def build_matrix(dataset):\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "    xs = []\n",
        "    ys = []\n",
        "\n",
        "    for x, y in data_loader:\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "\n",
        "    xs = torch.cat(xs, 0)\n",
        "    ys = torch.cat(ys, 0)\n",
        "\n",
        "    if xs.is_cuda:\n",
        "        xs = xs.cpu()\n",
        "    if ys.is_cuda:\n",
        "        ys = ys.cpu()\n",
        "\n",
        "    return xs.data.numpy(), ys.data.numpy()\n",
        "\n",
        "def evaluate(encoder, enc_type, train_on, test_on, cuda):\n",
        "    embedded_train = EmbeddedDataset(train_on, encoder, enc_type, cuda=cuda)\n",
        "    embedded_test = EmbeddedDataset(test_on, encoder, enc_type, cuda=cuda)\n",
        "    return train_and_evaluate_linear_model(embedded_train, embedded_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91duTE0CUrud",
        "colab_type": "code",
        "outputId": "7c7066bd-ca7b-4d70-e396-a078f9129b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def train_MI(encoder, beta=None, num_epochs=2000):\n",
        "    \n",
        "    #x_train, y_train, x_train_int = generate_samples(n_train_samples) # training dataset\n",
        "    #x_test, y_test, _ = generate_samples(n_test_samples) # testing dataset\n",
        "    mi_xt_all = []; mi_ty_all = []; epochs = []\n",
        "    mi_xz = []; mi_zy = []\n",
        "\n",
        "    X_test, Y_test = torch.tensor(x_test, requires_grad=False).to(device), torch.tensor(y_test, requires_grad=False).to(device)\n",
        "    if enc_type == 'VAE':\n",
        "        (_, _), _, z_test = encoder(X_test.float())#\n",
        "    else:\n",
        "        z_test = encoder(X_test.float())#\n",
        "    z_test = torch.tensor(z_test, requires_grad=False).to(device)\n",
        "\n",
        "    x_dim, y_dim, z_dim = x_test.shape[-1], y_test.shape[-1], z_test.shape[-1]\n",
        "    print(x_dim, y_dim, z_dim)\n",
        "    mi_estimator_X = MIEstimator(x_dim, z_dim).to(device)\n",
        "    mi_estimator_Y = MIEstimator(z_dim, y_dim).to(device)\n",
        "\n",
        "    optimizer = optim.Adam([\n",
        "    {'params': mi_estimator_X.parameters(), 'lr':1e-3},\n",
        "    {'params': mi_estimator_Y.parameters(), 'lr':1e-3},\n",
        "    ])\n",
        "    if beta is None:\n",
        "        use_scheduler = True\n",
        "        beta_scheduler = ExponentialScheduler(start_value=1e-9, end_value=1e-1, n_iterations=500, start_iteration=1)\n",
        "    else:\n",
        "        use_scheduler = False\n",
        "    accuracy_evaluation = {'train': [], 'test': []}\n",
        "    loss_evaluation = {'train': [], 'test': []}\n",
        "\n",
        "    start_time = time.time()\n",
        "    max_MI_x, max_MI_y = 0, 0\n",
        "    mi_est_all = {'X': [], 'Y': []}\n",
        "    for epoch in range(num_epochs):\n",
        "        if use_scheduler:\n",
        "            beta = beta_scheduler(epoch)\n",
        "\n",
        "        X_train, Y_train = torch.from_numpy(x_train).to(device).float(), torch.from_numpy(y_train).to(device).float()\n",
        "        if enc_type == 'VAE':\n",
        "            (_, _), _, z_train = encoder(X_train.float())\n",
        "        else:\n",
        "            z_train = encoder(X_train.float())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        mi_gradient_X, mi_estimation_X = mi_estimator_X(X_train, z_train)\n",
        "        mi_gradient_X = mi_gradient_X.mean()\n",
        "        mi_estimation_X = mi_estimation_X.mean()\n",
        "\n",
        "        mi_gradient_Y, mi_estimation_Y = mi_estimator_Y(z_train, Y_train.float())\n",
        "        mi_gradient_Y = mi_gradient_Y.mean()\n",
        "        mi_estimation_Y = mi_estimation_Y.mean()\n",
        "                \n",
        "        loss_mi = - mi_gradient_Y - beta * mi_gradient_X\n",
        "        loss_mi.backward()\n",
        "        optimizer.step()\n",
        "        mi_est_all['X'].append(mi_estimation_X.item())\n",
        "        mi_est_all['Y'].append(mi_estimation_Y.item())\n",
        "        if mi_estimation_X.item() > max_MI_x:\n",
        "            max_MI_x = mi_estimation_X.item()\n",
        "            max_MI_y = mi_estimation_Y.item()\n",
        "        eval_freq = 10\n",
        "        \n",
        "        if epoch >= 100 and np.mean(mi_est_all['X'][-100]) > max_MI_x - 1e-1:\n",
        "            break\n",
        "        if epoch % eval_freq == 0 or epoch == num_epochs - 1:\n",
        "            mi_xt, mi_ty = get_mutual_information(z_train.cpu().data.numpy())\n",
        "            mi_xt_all.append(mi_xt)\n",
        "            mi_ty_all.append(mi_ty)\n",
        "            print('#'*30)\n",
        "            print('Step - ', epoch)\n",
        "            print('Beta - ', beta)\n",
        "            # print('Train: Accuracy - %0.3f, Loss - %0.3f' % (accuracy(out, Y_train), loss))\n",
        "            # print('Test: Accuracy - %0.3f, Loss - %0.3f' % (accuracy(predictor(z_test.float()), Y_test), criterion(predictor(z_test.float()), Y_test.argmax(dim=1))))\n",
        "            print('I(X, %s) - %s' % (layer, mi_xt[0]))\n",
        "            print('I(%s, Y) - %s' % (layer, mi_ty[0]))\n",
        "            print('I_est(X, %s) - %s' % (layer, mi_estimation_X.item()))\n",
        "            #print('Grad I_est(X, T)', mi_gradient_X)\n",
        "            print('I_est(%s, Y) - %s' % (layer, mi_estimation_Y.item()))\n",
        "            print('Max I_est(X, %s) - %s' % (layer, max_MI_x))\n",
        "            #print('Grad I_est(X, T)', mi_gradient_X)\n",
        "            print('Max I_est(%s, Y) - %s' % (layer, max_MI_y))\n",
        "            #print('Grad I_est(T, Y)', mi_gradient_Y)\n",
        "            print('Elapsed time training MI for %s: %s' % (layer, time.time() - start_time))\n",
        "            print('#'*30,'\\n')\n",
        "            \n",
        "    return max_MI_x, max_MI_y\n",
        "\n",
        "n_train_samples = 50000\n",
        "n_test_samples = 10000\n",
        "\n",
        "\n",
        "num_labels_range = [2**i for i in range(1, int(np.log2(n_train_samples)-8))]\n",
        "\n",
        "layers = ['Linear2', 'Linear3', 'Linear4']\n",
        "\n",
        "acc = {layer:{i:[] for i in num_labels_range} for layer in layers}\n",
        "# acc = {i:[] for i in num_labels_range}\n",
        "print(num_labels_range)\n",
        "seeds = [9, 42, 103, 48, 79]\n",
        "# enc_type = 'VAE'\n",
        "enc_type = 'MLP'\n",
        "mi_layers = {} #probably make for different seeds as well\n",
        "start_time = time.time()\n",
        "for i in range(len(seeds)):\n",
        "\n",
        "    \n",
        "    print('\\nRunning with seed %d out of %d' % (i, len(seeds)))\n",
        "    torch.manual_seed(seeds[i])\n",
        "    np.random.seed(seeds[i])\n",
        "    seed(seeds[i])\n",
        "    \n",
        "    \n",
        "    for layer in layers:\n",
        "\n",
        "        x_train, y_train, x_train_int = generate_samples(n_train_samples) # training dataset\n",
        "        x_test, y_test, _ = generate_samples(10*n_test_samples) # testing dataset\n",
        "        if seeds[i] == 9:\n",
        "            if enc_type == 'MLP':\n",
        "                MI_X, MI_Y = train_MI(Encoder.models[layer], beta=1, num_epochs=2000)\n",
        "            else:\n",
        "                MI_X, MI_Y = train_MI(Encoder, num_epochs=2000)\n",
        "            mi_layers[layer] = (MI_X, MI_Y)\n",
        "            print('MI values for %s - %s, %s' % (layer, MI_X, MI_Y))\n",
        "        y_train = y_train.argmax(axis=1)\n",
        "        y_test = y_test.argmax(axis=1)\n",
        "        train_set = torch.utils.data.TensorDataset(torch.Tensor(x_train).to(device), torch.Tensor(y_train).to(device)) \n",
        "        test_set = torch.utils.data.TensorDataset(torch.Tensor(x_test).to(device), torch.Tensor(y_test).to(device))\n",
        "    \n",
        "        \n",
        "        for num_labels in num_labels_range:\n",
        "            print('Evaluating for %s %s' % (layer, num_labels))\n",
        "            #acc[layer].append(train_MI(num_labels, Encoder, num_epochs=2000))\n",
        "            \n",
        "            train_subset = split(train_set, num_labels, 'Balanced') \n",
        "            test_subset = split(train_set, n_test_samples, 'Random') \n",
        "            if enc_type == 'MLP':\n",
        "                train_accuracy, test_accuracy = evaluate(encoder=Encoder.models[layer], enc_type=enc_type, train_on=train_subset, test_on=test_subset, cuda=torch.cuda.is_available())\n",
        "            else:\n",
        "                train_accuracy, test_accuracy = evaluate(encoder=Encoder, enc_type=enc_type, train_on=train_subset, test_on=test_subset, cuda=torch.cuda.is_available())\n",
        "            #train_accuracy, test_accuracy = train_and_evaluate_linear_model(train_subset, test_set, C=2)\n",
        "            print('Train Accuracy: %f'% train_accuracy)\n",
        "            print('Test Accuracy: %f'% test_accuracy)\n",
        "            if enc_type == 'MLP':\n",
        "                acc[layer][num_labels].append(test_accuracy)\n",
        "            else:\n",
        "                acc[num_labels].append(test_accuracy)\n",
        "    print('Elapsed time - ', time.time() - start_time)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 4, 8, 16, 32, 64]\n",
            "\n",
            "Running with seed 0 out of 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10 2 8\n",
            "##############################\n",
            "Step -  0\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - -0.0022646188735961914\n",
            "I_est(Linear2, Y) - -0.002984762191772461\n",
            "Max I_est(X, Linear2) - 0\n",
            "Max I_est(Linear2, Y) - 0\n",
            "Elapsed time training MI for Linear2: 0.6783268451690674\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  10\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 0.27531856298446655\n",
            "I_est(Linear2, Y) - 0.4115351438522339\n",
            "Max I_est(X, Linear2) - 0.27531856298446655\n",
            "Max I_est(Linear2, Y) - 0.4115351438522339\n",
            "Elapsed time training MI for Linear2: 3.1007955074310303\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  20\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 0.653921365737915\n",
            "I_est(Linear2, Y) - 0.6468857526779175\n",
            "Max I_est(X, Linear2) - 0.653921365737915\n",
            "Max I_est(Linear2, Y) - 0.6468857526779175\n",
            "Elapsed time training MI for Linear2: 5.516437292098999\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  30\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 1.0786000490188599\n",
            "I_est(Linear2, Y) - 0.6816496849060059\n",
            "Max I_est(X, Linear2) - 1.0786000490188599\n",
            "Max I_est(Linear2, Y) - 0.6816496849060059\n",
            "Elapsed time training MI for Linear2: 7.941037178039551\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  40\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 1.5606396198272705\n",
            "I_est(Linear2, Y) - 0.6927034854888916\n",
            "Max I_est(X, Linear2) - 1.5606396198272705\n",
            "Max I_est(Linear2, Y) - 0.6927034854888916\n",
            "Elapsed time training MI for Linear2: 10.361504554748535\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  50\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 1.9328606128692627\n",
            "I_est(Linear2, Y) - 0.695600152015686\n",
            "Max I_est(X, Linear2) - 1.9328606128692627\n",
            "Max I_est(Linear2, Y) - 0.695600152015686\n",
            "Elapsed time training MI for Linear2: 12.787463426589966\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  60\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.1997482776641846\n",
            "I_est(Linear2, Y) - 0.6966497302055359\n",
            "Max I_est(X, Linear2) - 2.1997482776641846\n",
            "Max I_est(Linear2, Y) - 0.6966497302055359\n",
            "Elapsed time training MI for Linear2: 15.212363004684448\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  70\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.3330130577087402\n",
            "I_est(Linear2, Y) - 0.696857750415802\n",
            "Max I_est(X, Linear2) - 2.3601737022399902\n",
            "Max I_est(Linear2, Y) - 0.6969252824783325\n",
            "Elapsed time training MI for Linear2: 17.634265661239624\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  80\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.4906110763549805\n",
            "I_est(Linear2, Y) - 0.6971780061721802\n",
            "Max I_est(X, Linear2) - 2.4906110763549805\n",
            "Max I_est(Linear2, Y) - 0.6971780061721802\n",
            "Elapsed time training MI for Linear2: 20.074292182922363\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  90\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.5149667263031006\n",
            "I_est(Linear2, Y) - 0.6972984671592712\n",
            "Max I_est(X, Linear2) - 2.527623414993286\n",
            "Max I_est(Linear2, Y) - 0.6972574591636658\n",
            "Elapsed time training MI for Linear2: 22.51603412628174\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  100\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.604494571685791\n",
            "I_est(Linear2, Y) - 0.6973642110824585\n",
            "Max I_est(X, Linear2) - 2.6065964698791504\n",
            "Max I_est(Linear2, Y) - 0.69737309217453\n",
            "Elapsed time training MI for Linear2: 24.94356346130371\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  110\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.487765312194824\n",
            "I_est(Linear2, Y) - 0.6883890628814697\n",
            "Max I_est(X, Linear2) - 2.6244871616363525\n",
            "Max I_est(Linear2, Y) - 0.6970208883285522\n",
            "Elapsed time training MI for Linear2: 27.3804874420166\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  120\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.0897676944732666\n",
            "I_est(Linear2, Y) - 0.6942400336265564\n",
            "Max I_est(X, Linear2) - 2.6244871616363525\n",
            "Max I_est(Linear2, Y) - 0.6970208883285522\n",
            "Elapsed time training MI for Linear2: 29.812708139419556\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  130\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.3567166328430176\n",
            "I_est(Linear2, Y) - 0.6958603858947754\n",
            "Max I_est(X, Linear2) - 2.6244871616363525\n",
            "Max I_est(Linear2, Y) - 0.6970208883285522\n",
            "Elapsed time training MI for Linear2: 32.23904871940613\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  140\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.625807285308838\n",
            "I_est(Linear2, Y) - 0.6967951655387878\n",
            "Max I_est(X, Linear2) - 2.625807285308838\n",
            "Max I_est(Linear2, Y) - 0.6967951655387878\n",
            "Elapsed time training MI for Linear2: 34.67705035209656\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  150\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.66369891166687\n",
            "I_est(Linear2, Y) - 0.6975470781326294\n",
            "Max I_est(X, Linear2) - 2.672626256942749\n",
            "Max I_est(Linear2, Y) - 0.6975576877593994\n",
            "Elapsed time training MI for Linear2: 37.100666522979736\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  160\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.6667652130126953\n",
            "I_est(Linear2, Y) - 0.6975851058959961\n",
            "Max I_est(X, Linear2) - 2.6856343746185303\n",
            "Max I_est(Linear2, Y) - 0.697412371635437\n",
            "Elapsed time training MI for Linear2: 39.54114079475403\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  170\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.699878215789795\n",
            "I_est(Linear2, Y) - 0.6962867379188538\n",
            "Max I_est(X, Linear2) - 2.703399181365967\n",
            "Max I_est(Linear2, Y) - 0.6970260739326477\n",
            "Elapsed time training MI for Linear2: 41.979247093200684\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  180\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.722583293914795\n",
            "I_est(Linear2, Y) - 0.6863300800323486\n",
            "Max I_est(X, Linear2) - 2.722583293914795\n",
            "Max I_est(Linear2, Y) - 0.6863300800323486\n",
            "Elapsed time training MI for Linear2: 44.40277409553528\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  190\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.731776475906372\n",
            "I_est(Linear2, Y) - 0.6975085139274597\n",
            "Max I_est(X, Linear2) - 2.7327866554260254\n",
            "Max I_est(Linear2, Y) - 0.692804217338562\n",
            "Elapsed time training MI for Linear2: 46.83555054664612\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  200\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.746587038040161\n",
            "I_est(Linear2, Y) - 0.6957451105117798\n",
            "Max I_est(X, Linear2) - 2.746587038040161\n",
            "Max I_est(Linear2, Y) - 0.6957451105117798\n",
            "Elapsed time training MI for Linear2: 49.25418400764465\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  210\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.759375810623169\n",
            "I_est(Linear2, Y) - 0.6976341605186462\n",
            "Max I_est(X, Linear2) - 2.759375810623169\n",
            "Max I_est(Linear2, Y) - 0.6976341605186462\n",
            "Elapsed time training MI for Linear2: 51.67240333557129\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  220\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.7726619243621826\n",
            "I_est(Linear2, Y) - 0.6976192593574524\n",
            "Max I_est(X, Linear2) - 2.7726619243621826\n",
            "Max I_est(Linear2, Y) - 0.6976192593574524\n",
            "Elapsed time training MI for Linear2: 54.10500144958496\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  230\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.781850576400757\n",
            "I_est(Linear2, Y) - 0.6976876854896545\n",
            "Max I_est(X, Linear2) - 2.781850576400757\n",
            "Max I_est(Linear2, Y) - 0.6976876854896545\n",
            "Elapsed time training MI for Linear2: 56.5259313583374\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  240\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.7857778072357178\n",
            "I_est(Linear2, Y) - 0.6976470947265625\n",
            "Max I_est(X, Linear2) - 2.7930619716644287\n",
            "Max I_est(Linear2, Y) - 0.6977011561393738\n",
            "Elapsed time training MI for Linear2: 58.947752237319946\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  250\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.8026607036590576\n",
            "I_est(Linear2, Y) - 0.6976917386054993\n",
            "Max I_est(X, Linear2) - 2.8026607036590576\n",
            "Max I_est(Linear2, Y) - 0.6976917386054993\n",
            "Elapsed time training MI for Linear2: 61.369423389434814\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  260\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.8104121685028076\n",
            "I_est(Linear2, Y) - 0.6973579525947571\n",
            "Max I_est(X, Linear2) - 2.8104121685028076\n",
            "Max I_est(Linear2, Y) - 0.6973579525947571\n",
            "Elapsed time training MI for Linear2: 63.794267654418945\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  270\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.824023962020874\n",
            "I_est(Linear2, Y) - 0.6892629861831665\n",
            "Max I_est(X, Linear2) - 2.824023962020874\n",
            "Max I_est(Linear2, Y) - 0.6892629861831665\n",
            "Elapsed time training MI for Linear2: 66.23514342308044\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  280\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.7984418869018555\n",
            "I_est(Linear2, Y) - 0.6974746584892273\n",
            "Max I_est(X, Linear2) - 2.8291807174682617\n",
            "Max I_est(Linear2, Y) - 0.6937925219535828\n",
            "Elapsed time training MI for Linear2: 68.66308689117432\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  290\n",
            "Beta -  1\n",
            "I(X, Linear2) - 3.227249965379161\n",
            "I(Linear2, Y) - 0.693142187751178\n",
            "I_est(X, Linear2) - 2.8032872676849365\n",
            "I_est(Linear2, Y) - 0.6967539191246033\n",
            "Max I_est(X, Linear2) - 2.837010145187378\n",
            "Max I_est(Linear2, Y) - 0.6976982355117798\n",
            "Elapsed time training MI for Linear2: 71.0847806930542\n",
            "############################## \n",
            "\n",
            "MI values for Linear2 - 2.838330030441284, 0.6971135139465332\n",
            "Evaluating for Linear2 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.627900\n",
            "Evaluating for Linear2 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.693400\n",
            "Evaluating for Linear2 8\n",
            "Train Accuracy: 0.625000\n",
            "Test Accuracy: 0.620100\n",
            "Evaluating for Linear2 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.998700\n",
            "Evaluating for Linear2 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear2 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10 2 6\n",
            "##############################\n",
            "Step -  0\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - -0.000667572021484375\n",
            "I_est(Linear3, Y) - 0.00927037000656128\n",
            "Max I_est(X, Linear3) - 0\n",
            "Max I_est(Linear3, Y) - 0\n",
            "Elapsed time training MI for Linear3: 0.6597020626068115\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  10\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 0.027049779891967773\n",
            "I_est(Linear3, Y) - 0.6539182066917419\n",
            "Max I_est(X, Linear3) - 0.03644514083862305\n",
            "Max I_est(Linear3, Y) - 0.6147993803024292\n",
            "Elapsed time training MI for Linear3: 3.035413980484009\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  20\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 0.12515419721603394\n",
            "I_est(Linear3, Y) - 0.6848745942115784\n",
            "Max I_est(X, Linear3) - 0.12515419721603394\n",
            "Max I_est(Linear3, Y) - 0.6848745942115784\n",
            "Elapsed time training MI for Linear3: 5.390952825546265\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  30\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 0.2500441074371338\n",
            "I_est(Linear3, Y) - 0.688778817653656\n",
            "Max I_est(X, Linear3) - 0.2500441074371338\n",
            "Max I_est(Linear3, Y) - 0.688778817653656\n",
            "Elapsed time training MI for Linear3: 7.766409635543823\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  40\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 0.43319016695022583\n",
            "I_est(Linear3, Y) - 0.6898530125617981\n",
            "Max I_est(X, Linear3) - 0.43319016695022583\n",
            "Max I_est(Linear3, Y) - 0.6898530125617981\n",
            "Elapsed time training MI for Linear3: 10.137714385986328\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  50\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 0.6929792165756226\n",
            "I_est(Linear3, Y) - 0.6908107995986938\n",
            "Max I_est(X, Linear3) - 0.6929792165756226\n",
            "Max I_est(Linear3, Y) - 0.6908107995986938\n",
            "Elapsed time training MI for Linear3: 12.49642038345337\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  60\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 0.9781641960144043\n",
            "I_est(Linear3, Y) - 0.691386878490448\n",
            "Max I_est(X, Linear3) - 0.9781641960144043\n",
            "Max I_est(Linear3, Y) - 0.691386878490448\n",
            "Elapsed time training MI for Linear3: 14.864093542098999\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  70\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.1757400035858154\n",
            "I_est(Linear3, Y) - 0.6914392709732056\n",
            "Max I_est(X, Linear3) - 1.1960809230804443\n",
            "Max I_est(Linear3, Y) - 0.6913881897926331\n",
            "Elapsed time training MI for Linear3: 17.22892737388611\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  80\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.3350706100463867\n",
            "I_est(Linear3, Y) - 0.6915193200111389\n",
            "Max I_est(X, Linear3) - 1.3350706100463867\n",
            "Max I_est(Linear3, Y) - 0.6915193200111389\n",
            "Elapsed time training MI for Linear3: 19.57858896255493\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  90\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.440777063369751\n",
            "I_est(Linear3, Y) - 0.6915138959884644\n",
            "Max I_est(X, Linear3) - 1.440777063369751\n",
            "Max I_est(Linear3, Y) - 0.6915138959884644\n",
            "Elapsed time training MI for Linear3: 21.929720163345337\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  100\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.434804916381836\n",
            "I_est(Linear3, Y) - 0.691563606262207\n",
            "Max I_est(X, Linear3) - 1.49530029296875\n",
            "Max I_est(Linear3, Y) - 0.6915563941001892\n",
            "Elapsed time training MI for Linear3: 24.290159702301025\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  110\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.5371084213256836\n",
            "I_est(Linear3, Y) - 0.687393069267273\n",
            "Max I_est(X, Linear3) - 1.5518977642059326\n",
            "Max I_est(Linear3, Y) - 0.6899991035461426\n",
            "Elapsed time training MI for Linear3: 26.65617299079895\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  120\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.5897860527038574\n",
            "I_est(Linear3, Y) - 0.6817708611488342\n",
            "Max I_est(X, Linear3) - 1.5897860527038574\n",
            "Max I_est(Linear3, Y) - 0.6817708611488342\n",
            "Elapsed time training MI for Linear3: 29.008371591567993\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  130\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.6261680126190186\n",
            "I_est(Linear3, Y) - 0.6888149380683899\n",
            "Max I_est(X, Linear3) - 1.6261680126190186\n",
            "Max I_est(Linear3, Y) - 0.6888149380683899\n",
            "Elapsed time training MI for Linear3: 31.37157917022705\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  140\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.6297179460525513\n",
            "I_est(Linear3, Y) - 0.6914425492286682\n",
            "Max I_est(X, Linear3) - 1.6579121351242065\n",
            "Max I_est(Linear3, Y) - 0.690082311630249\n",
            "Elapsed time training MI for Linear3: 33.72629261016846\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  150\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.644018292427063\n",
            "I_est(Linear3, Y) - 0.6909235715866089\n",
            "Max I_est(X, Linear3) - 1.6828936338424683\n",
            "Max I_est(Linear3, Y) - 0.6915419697761536\n",
            "Elapsed time training MI for Linear3: 36.08525276184082\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  160\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.6768701076507568\n",
            "I_est(Linear3, Y) - 0.6912704110145569\n",
            "Max I_est(X, Linear3) - 1.7161067724227905\n",
            "Max I_est(Linear3, Y) - 0.6914976835250854\n",
            "Elapsed time training MI for Linear3: 38.455233097076416\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  170\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.7371896505355835\n",
            "I_est(Linear3, Y) - 0.691511332988739\n",
            "Max I_est(X, Linear3) - 1.7371896505355835\n",
            "Max I_est(Linear3, Y) - 0.691511332988739\n",
            "Elapsed time training MI for Linear3: 40.827954053878784\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  180\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.7237191200256348\n",
            "I_est(Linear3, Y) - 0.691632866859436\n",
            "Max I_est(X, Linear3) - 1.769227147102356\n",
            "Max I_est(Linear3, Y) - 0.6916133761405945\n",
            "Elapsed time training MI for Linear3: 43.189271688461304\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  190\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.7137151956558228\n",
            "I_est(Linear3, Y) - 0.6916236281394958\n",
            "Max I_est(X, Linear3) - 1.7870076894760132\n",
            "Max I_est(Linear3, Y) - 0.6916273236274719\n",
            "Elapsed time training MI for Linear3: 45.56069993972778\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  200\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.723863124847412\n",
            "I_est(Linear3, Y) - 0.6916427612304688\n",
            "Max I_est(X, Linear3) - 1.8129441738128662\n",
            "Max I_est(Linear3, Y) - 0.6916470527648926\n",
            "Elapsed time training MI for Linear3: 47.959372997283936\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  210\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.832249641418457\n",
            "I_est(Linear3, Y) - 0.6915529370307922\n",
            "Max I_est(X, Linear3) - 1.8378599882125854\n",
            "Max I_est(Linear3, Y) - 0.6916483640670776\n",
            "Elapsed time training MI for Linear3: 50.320348501205444\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  220\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.855254054069519\n",
            "I_est(Linear3, Y) - 0.6915947198867798\n",
            "Max I_est(X, Linear3) - 1.855254054069519\n",
            "Max I_est(Linear3, Y) - 0.6915947198867798\n",
            "Elapsed time training MI for Linear3: 52.69445466995239\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  230\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.7823708057403564\n",
            "I_est(Linear3, Y) - 0.6916475296020508\n",
            "Max I_est(X, Linear3) - 1.863694667816162\n",
            "Max I_est(Linear3, Y) - 0.6916626691818237\n",
            "Elapsed time training MI for Linear3: 55.07516384124756\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  240\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.8453919887542725\n",
            "I_est(Linear3, Y) - 0.6912425756454468\n",
            "Max I_est(X, Linear3) - 1.863694667816162\n",
            "Max I_est(Linear3, Y) - 0.6916626691818237\n",
            "Elapsed time training MI for Linear3: 57.44247484207153\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  250\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.897925615310669\n",
            "I_est(Linear3, Y) - 0.6835139393806458\n",
            "Max I_est(X, Linear3) - 1.897925615310669\n",
            "Max I_est(Linear3, Y) - 0.6835139393806458\n",
            "Elapsed time training MI for Linear3: 59.81853151321411\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  260\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.9171255826950073\n",
            "I_est(Linear3, Y) - 0.6914663910865784\n",
            "Max I_est(X, Linear3) - 1.92176353931427\n",
            "Max I_est(Linear3, Y) - 0.6898690462112427\n",
            "Elapsed time training MI for Linear3: 62.19899797439575\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  270\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.9162983894348145\n",
            "I_est(Linear3, Y) - 0.6911339163780212\n",
            "Max I_est(X, Linear3) - 1.9473309516906738\n",
            "Max I_est(Linear3, Y) - 0.690651535987854\n",
            "Elapsed time training MI for Linear3: 64.558767080307\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  280\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.932281255722046\n",
            "I_est(Linear3, Y) - 0.6913998126983643\n",
            "Max I_est(X, Linear3) - 1.9695851802825928\n",
            "Max I_est(Linear3, Y) - 0.6915748715400696\n",
            "Elapsed time training MI for Linear3: 66.91947627067566\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  290\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.904714584350586\n",
            "I_est(Linear3, Y) - 0.6915251612663269\n",
            "Max I_est(X, Linear3) - 1.9791605472564697\n",
            "Max I_est(Linear3, Y) - 0.691673994064331\n",
            "Elapsed time training MI for Linear3: 69.28264689445496\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  300\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.977792739868164\n",
            "I_est(Linear3, Y) - 0.6915919780731201\n",
            "Max I_est(X, Linear3) - 1.9917311668395996\n",
            "Max I_est(Linear3, Y) - 0.6915748119354248\n",
            "Elapsed time training MI for Linear3: 71.64128494262695\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  310\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.993819236755371\n",
            "I_est(Linear3, Y) - 0.69167560338974\n",
            "Max I_est(X, Linear3) - 2.007591962814331\n",
            "Max I_est(Linear3, Y) - 0.6916667819023132\n",
            "Elapsed time training MI for Linear3: 74.01170372962952\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  320\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.8852648735046387\n",
            "I_est(Linear3, Y) - 0.6906052231788635\n",
            "Max I_est(X, Linear3) - 2.0272507667541504\n",
            "Max I_est(Linear3, Y) - 0.6914753913879395\n",
            "Elapsed time training MI for Linear3: 76.37921571731567\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  330\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.739828109741211\n",
            "I_est(Linear3, Y) - 0.6914889812469482\n",
            "Max I_est(X, Linear3) - 2.0272507667541504\n",
            "Max I_est(Linear3, Y) - 0.6914753913879395\n",
            "Elapsed time training MI for Linear3: 78.75632333755493\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  340\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.9167815446853638\n",
            "I_est(Linear3, Y) - 0.6910985112190247\n",
            "Max I_est(X, Linear3) - 2.0272507667541504\n",
            "Max I_est(Linear3, Y) - 0.6914753913879395\n",
            "Elapsed time training MI for Linear3: 81.11221575737\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  350\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.6097174882888794\n",
            "I_est(Linear3, Y) - 0.6897675395011902\n",
            "Max I_est(X, Linear3) - 2.0272507667541504\n",
            "Max I_est(Linear3, Y) - 0.6914753913879395\n",
            "Elapsed time training MI for Linear3: 83.48474502563477\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  360\n",
            "Beta -  1\n",
            "I(X, Linear3) - 2.8881543078792293\n",
            "I(Linear3, Y) - 0.6931206811254412\n",
            "I_est(X, Linear3) - 1.9233243465423584\n",
            "I_est(Linear3, Y) - 0.6915152668952942\n",
            "Max I_est(X, Linear3) - 2.0272507667541504\n",
            "Max I_est(Linear3, Y) - 0.6914753913879395\n",
            "Elapsed time training MI for Linear3: 85.84669494628906\n",
            "############################## \n",
            "\n",
            "MI values for Linear3 - 2.0272507667541504, 0.6914753913879395\n",
            "Evaluating for Linear3 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10 2 4\n",
            "##############################\n",
            "Step -  0\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - -0.0007137060165405273\n",
            "I_est(Linear4, Y) - 0.015172004699707031\n",
            "Max I_est(X, Linear4) - 0\n",
            "Max I_est(Linear4, Y) - 0\n",
            "Elapsed time training MI for Linear4: 0.646918535232544\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  10\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 0.037377357482910156\n",
            "I_est(Linear4, Y) - 0.6725636720657349\n",
            "Max I_est(X, Linear4) - 0.04186201095581055\n",
            "Max I_est(Linear4, Y) - 0.582690954208374\n",
            "Elapsed time training MI for Linear4: 2.9846456050872803\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  20\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 0.11822640895843506\n",
            "I_est(Linear4, Y) - 0.6843471527099609\n",
            "Max I_est(X, Linear4) - 0.11822640895843506\n",
            "Max I_est(Linear4, Y) - 0.6843471527099609\n",
            "Elapsed time training MI for Linear4: 5.3521881103515625\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  30\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 0.22664964199066162\n",
            "I_est(Linear4, Y) - 0.6874751448631287\n",
            "Max I_est(X, Linear4) - 0.22664964199066162\n",
            "Max I_est(Linear4, Y) - 0.6874751448631287\n",
            "Elapsed time training MI for Linear4: 7.700817584991455\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  40\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 0.3951603174209595\n",
            "I_est(Linear4, Y) - 0.6882799863815308\n",
            "Max I_est(X, Linear4) - 0.3951603174209595\n",
            "Max I_est(Linear4, Y) - 0.6882799863815308\n",
            "Elapsed time training MI for Linear4: 10.039936065673828\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  50\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 0.6293926239013672\n",
            "I_est(Linear4, Y) - 0.6891089677810669\n",
            "Max I_est(X, Linear4) - 0.6293926239013672\n",
            "Max I_est(Linear4, Y) - 0.6891089677810669\n",
            "Elapsed time training MI for Linear4: 12.387228727340698\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  60\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 0.8944615721702576\n",
            "I_est(Linear4, Y) - 0.689255952835083\n",
            "Max I_est(X, Linear4) - 0.8944615721702576\n",
            "Max I_est(Linear4, Y) - 0.689255952835083\n",
            "Elapsed time training MI for Linear4: 14.733338117599487\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  70\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.140892744064331\n",
            "I_est(Linear4, Y) - 0.6893104314804077\n",
            "Max I_est(X, Linear4) - 1.140892744064331\n",
            "Max I_est(Linear4, Y) - 0.6893104314804077\n",
            "Elapsed time training MI for Linear4: 17.08391547203064\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  80\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.2592973709106445\n",
            "I_est(Linear4, Y) - 0.6890630125999451\n",
            "Max I_est(X, Linear4) - 1.2592973709106445\n",
            "Max I_est(Linear4, Y) - 0.6890630125999451\n",
            "Elapsed time training MI for Linear4: 19.418790578842163\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  90\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.293036699295044\n",
            "I_est(Linear4, Y) - 0.6887978315353394\n",
            "Max I_est(X, Linear4) - 1.3888757228851318\n",
            "Max I_est(Linear4, Y) - 0.6804943084716797\n",
            "Elapsed time training MI for Linear4: 21.760966062545776\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  100\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.354276418685913\n",
            "I_est(Linear4, Y) - 0.6860466599464417\n",
            "Max I_est(X, Linear4) - 1.4553226232528687\n",
            "Max I_est(Linear4, Y) - 0.6890355348587036\n",
            "Elapsed time training MI for Linear4: 24.108999252319336\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  110\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.4642733335494995\n",
            "I_est(Linear4, Y) - 0.6889113783836365\n",
            "Max I_est(X, Linear4) - 1.5217852592468262\n",
            "Max I_est(Linear4, Y) - 0.6877936720848083\n",
            "Elapsed time training MI for Linear4: 26.446150302886963\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  120\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.558728575706482\n",
            "I_est(Linear4, Y) - 0.6892342567443848\n",
            "Max I_est(X, Linear4) - 1.558728575706482\n",
            "Max I_est(Linear4, Y) - 0.6892342567443848\n",
            "Elapsed time training MI for Linear4: 28.813430070877075\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  130\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.5551282167434692\n",
            "I_est(Linear4, Y) - 0.6893107891082764\n",
            "Max I_est(X, Linear4) - 1.610870361328125\n",
            "Max I_est(Linear4, Y) - 0.6893342137336731\n",
            "Elapsed time training MI for Linear4: 31.15813183784485\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  140\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.6362301111221313\n",
            "I_est(Linear4, Y) - 0.6892495155334473\n",
            "Max I_est(X, Linear4) - 1.6404565572738647\n",
            "Max I_est(Linear4, Y) - 0.6892635822296143\n",
            "Elapsed time training MI for Linear4: 33.52120518684387\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  150\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.6499128341674805\n",
            "I_est(Linear4, Y) - 0.6892616152763367\n",
            "Max I_est(X, Linear4) - 1.6690855026245117\n",
            "Max I_est(Linear4, Y) - 0.6893351674079895\n",
            "Elapsed time training MI for Linear4: 35.84965443611145\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  160\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.6678179502487183\n",
            "I_est(Linear4, Y) - 0.6889362931251526\n",
            "Max I_est(X, Linear4) - 1.680174469947815\n",
            "Max I_est(Linear4, Y) - 0.6892644762992859\n",
            "Elapsed time training MI for Linear4: 38.187631130218506\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  170\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.704625129699707\n",
            "I_est(Linear4, Y) - 0.6858881115913391\n",
            "Max I_est(X, Linear4) - 1.7110073566436768\n",
            "Max I_est(Linear4, Y) - 0.6708292365074158\n",
            "Elapsed time training MI for Linear4: 40.53317475318909\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  180\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.706056833267212\n",
            "I_est(Linear4, Y) - 0.6891944408416748\n",
            "Max I_est(X, Linear4) - 1.736460566520691\n",
            "Max I_est(Linear4, Y) - 0.6833608150482178\n",
            "Elapsed time training MI for Linear4: 42.885013818740845\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  190\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.7464473247528076\n",
            "I_est(Linear4, Y) - 0.6874983906745911\n",
            "Max I_est(X, Linear4) - 1.7590688467025757\n",
            "Max I_est(Linear4, Y) - 0.6883677244186401\n",
            "Elapsed time training MI for Linear4: 45.22282099723816\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  200\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.7215933799743652\n",
            "I_est(Linear4, Y) - 0.6892728805541992\n",
            "Max I_est(X, Linear4) - 1.7849067449569702\n",
            "Max I_est(Linear4, Y) - 0.6890893578529358\n",
            "Elapsed time training MI for Linear4: 47.56631636619568\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  210\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.7932684421539307\n",
            "I_est(Linear4, Y) - 0.6893348097801208\n",
            "Max I_est(X, Linear4) - 1.8038502931594849\n",
            "Max I_est(Linear4, Y) - 0.6890305280685425\n",
            "Elapsed time training MI for Linear4: 49.89774680137634\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  220\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.8027653694152832\n",
            "I_est(Linear4, Y) - 0.6893559098243713\n",
            "Max I_est(X, Linear4) - 1.8203485012054443\n",
            "Max I_est(Linear4, Y) - 0.6892752647399902\n",
            "Elapsed time training MI for Linear4: 52.23351836204529\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  230\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.8390750885009766\n",
            "I_est(Linear4, Y) - 0.6893420219421387\n",
            "Max I_est(X, Linear4) - 1.8390750885009766\n",
            "Max I_est(Linear4, Y) - 0.6893420219421387\n",
            "Elapsed time training MI for Linear4: 54.57526707649231\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  240\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.841806411743164\n",
            "I_est(Linear4, Y) - 0.6893657445907593\n",
            "Max I_est(X, Linear4) - 1.841806411743164\n",
            "Max I_est(Linear4, Y) - 0.6893657445907593\n",
            "Elapsed time training MI for Linear4: 56.919819593429565\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  250\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.8160630464553833\n",
            "I_est(Linear4, Y) - 0.6893699765205383\n",
            "Max I_est(X, Linear4) - 1.8446910381317139\n",
            "Max I_est(Linear4, Y) - 0.6893684267997742\n",
            "Elapsed time training MI for Linear4: 59.258403062820435\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  260\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.6072665452957153\n",
            "I_est(Linear4, Y) - 0.6893418431282043\n",
            "Max I_est(X, Linear4) - 1.8446910381317139\n",
            "Max I_est(Linear4, Y) - 0.6893684267997742\n",
            "Elapsed time training MI for Linear4: 61.613320112228394\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  270\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.7985020875930786\n",
            "I_est(Linear4, Y) - 0.6838188171386719\n",
            "Max I_est(X, Linear4) - 1.8446910381317139\n",
            "Max I_est(Linear4, Y) - 0.6893684267997742\n",
            "Elapsed time training MI for Linear4: 63.966448068618774\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  280\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.860734462738037\n",
            "I_est(Linear4, Y) - 0.678778886795044\n",
            "Max I_est(X, Linear4) - 1.872615933418274\n",
            "Max I_est(Linear4, Y) - 0.6681814193725586\n",
            "Elapsed time training MI for Linear4: 66.30939388275146\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  290\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.8837530612945557\n",
            "I_est(Linear4, Y) - 0.6892550587654114\n",
            "Max I_est(X, Linear4) - 1.894366979598999\n",
            "Max I_est(Linear4, Y) - 0.6869917511940002\n",
            "Elapsed time training MI for Linear4: 68.6517448425293\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  300\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.9078497886657715\n",
            "I_est(Linear4, Y) - 0.688325047492981\n",
            "Max I_est(X, Linear4) - 1.908187747001648\n",
            "Max I_est(Linear4, Y) - 0.6892971992492676\n",
            "Elapsed time training MI for Linear4: 70.99583172798157\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  310\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.8795740604400635\n",
            "I_est(Linear4, Y) - 0.6892950534820557\n",
            "Max I_est(X, Linear4) - 1.9290624856948853\n",
            "Max I_est(Linear4, Y) - 0.6889690160751343\n",
            "Elapsed time training MI for Linear4: 73.33478784561157\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  320\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.878989338874817\n",
            "I_est(Linear4, Y) - 0.6893311738967896\n",
            "Max I_est(X, Linear4) - 1.9364285469055176\n",
            "Max I_est(Linear4, Y) - 0.6892725229263306\n",
            "Elapsed time training MI for Linear4: 75.66901731491089\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  330\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.9231693744659424\n",
            "I_est(Linear4, Y) - 0.6893328428268433\n",
            "Max I_est(X, Linear4) - 1.9414265155792236\n",
            "Max I_est(Linear4, Y) - 0.6893281936645508\n",
            "Elapsed time training MI for Linear4: 78.01126742362976\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  340\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.5175800323486328\n",
            "I_est(Linear4, Y) - 0.6893621683120728\n",
            "Max I_est(X, Linear4) - 1.9464826583862305\n",
            "Max I_est(Linear4, Y) - 0.6893627643585205\n",
            "Elapsed time training MI for Linear4: 80.35697650909424\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  350\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.5396310091018677\n",
            "I_est(Linear4, Y) - 0.6893796324729919\n",
            "Max I_est(X, Linear4) - 1.9464826583862305\n",
            "Max I_est(Linear4, Y) - 0.6893627643585205\n",
            "Elapsed time training MI for Linear4: 82.70849823951721\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  360\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.676674246788025\n",
            "I_est(Linear4, Y) - 0.6893807053565979\n",
            "Max I_est(X, Linear4) - 1.9464826583862305\n",
            "Max I_est(Linear4, Y) - 0.6893627643585205\n",
            "Elapsed time training MI for Linear4: 85.04036259651184\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  370\n",
            "Beta -  1\n",
            "I(X, Linear4) - 2.7508064086030433\n",
            "I(Linear4, Y) - 0.6931471805595298\n",
            "I_est(X, Linear4) - 1.9246550798416138\n",
            "I_est(Linear4, Y) - 0.6893860101699829\n",
            "Max I_est(X, Linear4) - 1.9464826583862305\n",
            "Max I_est(Linear4, Y) - 0.6893627643585205\n",
            "Elapsed time training MI for Linear4: 87.38444709777832\n",
            "############################## \n",
            "\n",
            "MI values for Linear4 - 1.9464826583862305, 0.6893627643585205\n",
            "Evaluating for Linear4 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Elapsed time -  314.9851174354553\n",
            "\n",
            "Running with seed 1 out of 5\n",
            "Evaluating for Linear2 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.619600\n",
            "Evaluating for Linear2 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.620600\n",
            "Evaluating for Linear2 8\n",
            "Train Accuracy: 0.875000\n",
            "Test Accuracy: 0.627500\n",
            "Evaluating for Linear2 16\n",
            "Train Accuracy: 0.625000\n",
            "Test Accuracy: 0.631300\n",
            "Evaluating for Linear2 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear2 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.993400\n",
            "Evaluating for Linear3 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Elapsed time -  383.39558362960815\n",
            "\n",
            "Running with seed 2 out of 5\n",
            "Evaluating for Linear2 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.623400\n",
            "Evaluating for Linear2 4\n",
            "Train Accuracy: 0.750000\n",
            "Test Accuracy: 0.776900\n",
            "Evaluating for Linear2 8\n",
            "Train Accuracy: 0.625000\n",
            "Test Accuracy: 0.622500\n",
            "Evaluating for Linear2 16\n",
            "Train Accuracy: 0.875000\n",
            "Test Accuracy: 0.628400\n",
            "Evaluating for Linear2 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear2 64\n",
            "Train Accuracy: 0.953125\n",
            "Test Accuracy: 0.976600\n",
            "Evaluating for Linear3 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Elapsed time -  451.57237243652344\n",
            "\n",
            "Running with seed 3 out of 5\n",
            "Evaluating for Linear2 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.626400\n",
            "Evaluating for Linear2 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.628200\n",
            "Evaluating for Linear2 8\n",
            "Train Accuracy: 0.875000\n",
            "Test Accuracy: 0.750000\n",
            "Evaluating for Linear2 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear2 32\n",
            "Train Accuracy: 0.968750\n",
            "Test Accuracy: 0.873400\n",
            "Evaluating for Linear2 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 2\n",
            "Train Accuracy: 0.500000\n",
            "Test Accuracy: 0.503200\n",
            "Evaluating for Linear4 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Elapsed time -  520.3875980377197\n",
            "\n",
            "Running with seed 4 out of 5\n",
            "Evaluating for Linear2 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.629700\n",
            "Evaluating for Linear2 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.747800\n",
            "Evaluating for Linear2 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.630900\n",
            "Evaluating for Linear2 16\n",
            "Train Accuracy: 0.812500\n",
            "Test Accuracy: 0.636600\n",
            "Evaluating for Linear2 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear2 64\n",
            "Train Accuracy: 0.718750\n",
            "Test Accuracy: 0.682600\n",
            "Evaluating for Linear3 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Elapsed time -  588.1064412593842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDXAwdvsKrz0",
        "colab_type": "code",
        "outputId": "f8e49d01-300d-4257-aed6-a4bc6f279676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "acc_df = pd.DataFrame.from_dict(acc)\n",
        "plot_data = pd.DataFrame()\n",
        "acc_df.to_csv('acc_mlp_l2.csv', sep=' ')\n",
        "acc_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Linear2</th>\n",
              "      <th>Linear3</th>\n",
              "      <th>Linear4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.6279, 0.6196, 0.6234, 0.6264, 0.6297]</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0, 0.5032, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.6934, 0.6206, 0.7769, 0.6282, 0.7478]</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[0.6201, 0.6275, 0.6225, 0.75, 0.6309]</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[0.9987, 0.6313, 0.6284, 1.0, 0.6366]</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[1.0, 1.0, 1.0, 0.8734, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>[1.0, 0.9934, 0.9766, 1.0, 0.6826]</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     Linear2  ...                       Linear4\n",
              "2   [0.6279, 0.6196, 0.6234, 0.6264, 0.6297]  ...  [1.0, 1.0, 1.0, 0.5032, 1.0]\n",
              "4   [0.6934, 0.6206, 0.7769, 0.6282, 0.7478]  ...     [1.0, 1.0, 1.0, 1.0, 1.0]\n",
              "8     [0.6201, 0.6275, 0.6225, 0.75, 0.6309]  ...     [1.0, 1.0, 1.0, 1.0, 1.0]\n",
              "16     [0.9987, 0.6313, 0.6284, 1.0, 0.6366]  ...     [1.0, 1.0, 1.0, 1.0, 1.0]\n",
              "32              [1.0, 1.0, 1.0, 0.8734, 1.0]  ...     [1.0, 1.0, 1.0, 1.0, 1.0]\n",
              "64        [1.0, 0.9934, 0.9766, 1.0, 0.6826]  ...     [1.0, 1.0, 1.0, 1.0, 1.0]\n",
              "\n",
              "[6 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L2TlkyAgJis",
        "colab_type": "code",
        "outputId": "a02e7354-152c-4e2a-bac2-1b2043dd51fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "mean = lambda x: np.mean(x)\n",
        "std = lambda x: np.std(x)\n",
        "acc_df['Linear4'].apply(mean)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2     0.90064\n",
              "4     1.00000\n",
              "8     1.00000\n",
              "16    1.00000\n",
              "32    1.00000\n",
              "64    1.00000\n",
              "Name: Linear4, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMtPl7e7e1v4",
        "colab_type": "code",
        "outputId": "816c1278-0556-4cbb-9ce9-dcabe99a919e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "pd.DataFrame.from_dict(mi_layers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Linear2</th>\n",
              "      <th>Linear3</th>\n",
              "      <th>Linear4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.838330</td>\n",
              "      <td>2.027251</td>\n",
              "      <td>1.946483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.697114</td>\n",
              "      <td>0.691475</td>\n",
              "      <td>0.689363</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Linear2   Linear3   Linear4\n",
              "0  2.838330  2.027251  1.946483\n",
              "1  0.697114  0.691475  0.689363"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqS3_Be1nDrG",
        "colab_type": "code",
        "outputId": "8023e01b-f7b1-47e2-8539-b5a029377ffa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        }
      },
      "source": [
        "fig1, ax1 = plt.subplots(3, 1, sharex=True)\n",
        "nums = np.array(num_labels_range)\n",
        "colors = ['black', 'blue', 'red']\n",
        "for i in range(len(layers)):\n",
        "    means = acc_df[layers[i]].apply(mean)\n",
        "    stds = acc_df[layers[i]].apply(std)\n",
        "    ax1[i].plot(nums, means, color=colors[i], label=layers[i]+' + L2 (lambda = 0.01)')\n",
        "    ax1[i].fill_between(nums, means - stds, means + stds, facecolor=colors[i], interpolate=True, alpha=0.25)\n",
        "    ax1[i].grid()\n",
        "ax1[-1].set_xlabel('# Labels')\n",
        "ax1[1].set_ylabel('Accuracy')\n",
        "\n",
        "fig1.legend()\n",
        "fig1.set_size_inches(10, 7, forward=True)\n",
        "fig1.savefig('acc_l2.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArEAAAHhCAYAAAB5vOZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x504 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-JjG7v4EVKT",
        "colab_type": "code",
        "outputId": "3c4a9290-134e-4169-9c3e-c66fb710134a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        }
      },
      "source": [
        "mi_df = pd.DataFrame.from_dict(mi_layers)\n",
        "fig2, ax2 = plt.subplots(1, 1, sharex=True)\n",
        "colors = ['black', 'blue', 'red']\n",
        "for i in range(len(layers)):\n",
        "    ax2.scatter(mi_df.loc[0, layers[i]], mi_df.loc[1, layers[i]], color=colors[i], label=layers[i])\n",
        "    \n",
        "    ax2.annotate(layers[i], (mi_df.loc[0, layers[i]], mi_df.loc[1, layers[i]]))\n",
        "    ax2.grid()\n",
        "ax2.set_xlabel('I(X, Z)')\n",
        "ax2.set_ylabel('I(Z, Y)')\n",
        "\n",
        "fig2.legend()\n",
        "fig2.set_size_inches(10, 7, forward=True)\n",
        "fig2.savefig('mi_l2.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArEAAAHhCAYAAAB5vOZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+X9bmSbhdqcoIQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoFtMDUkoLi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}