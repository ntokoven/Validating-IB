{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "03.03 Copy of information_bottleneck.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b2MZ3QFDUwXT"
      },
      "source": [
        "# Information Bottleneck theory for Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xe77ybVGUwXZ"
      },
      "source": [
        "This is a demonstration of the information bottleneck theory for deep learning, introduced by Naftali Tishby. Here I tried to reproduce the main results in their recent paper [Opening the black box of Deep Neural Networks via Information](https://arxiv.org/pdf/1703.00810.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PG-Wfp0DUwXc"
      },
      "source": [
        "## Data generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KNmtaAb7UwXf"
      },
      "source": [
        "First, we will generate a very simple dataset for the demonstration. The inputs are vectors of 10 binaries, and the outputs are just single binaries. The inputs could be represented by integers from 0 to 1023 ($=2^{10}-1$). The 1024 possible inputs are divided into 16 groups (each group has 64 numbers), and each integer input $n\\in[0,1023]$ belongs to group $i$ if $x\\equiv i \\pmod{16}$, where $i \\in [0,15]$. Each group $i$ is then associated with a random binary number - we build kinda of a distribution over space of possible discrete states (output)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "igLHoZPbUwXk",
        "outputId": "a28f039e-86b0-4f52-a5ce-92dac3459d67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "%pylab inline\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "from random import randint, seed\n",
        "\n",
        "# Flag to enable execution on GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['seed', 'randint', 'split']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hTHGDGBxUwXu",
        "outputId": "b000d596-510a-43b4-8476-82e8557ccede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_train_samples = 50000 # number of train samples\n",
        "n_test_samples = 10000 # number of test samples\n",
        "\n",
        "groups = np.append(np.zeros(8),np.ones(8)) # 16 groups\n",
        "print(groups)\n",
        "np.random.seed(1234)\n",
        "torch.manual_seed(1234)\n",
        "np.random.shuffle(groups)\n",
        "\n",
        "# generate samples\n",
        "seed(1234)\n",
        "def generate_samples(n_samples):\n",
        "    x_data = np.zeros((n_samples, 10)) # inputs\n",
        "    x_int = np.zeros(n_samples) # integers representing the inputs\n",
        "    y_data = np.zeros((n_samples, 2)) # outputs\n",
        "    \n",
        "    for i in range(n_samples):\n",
        "        random_int = randint(0, 1023)\n",
        "        x_data[i,:] = [int(b) for b in list(\"{0:b}\".format(random_int).zfill(10))]\n",
        "        x_int[i] = random_int\n",
        "        y_data[i,0] = groups[random_int % 16]\n",
        "        y_data[i,1] = 1 - y_data[i,0]\n",
        "        \n",
        "    return x_data, y_data, x_int\n",
        "\n",
        "x_train, y_train, x_train_int = generate_samples(n_train_samples) # training dataset\n",
        "x_test, y_test, _ = generate_samples(n_test_samples) # testing dataset"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ai6D9irwUwX_",
        "outputId": "7b9e1899-abc6-4fac-97aa-648d8e38df10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "d={}\n",
        "for i in y_train:\n",
        "    d[str(i[0])+', '+str(i[1])] = 0\n",
        "for i in y_train:\n",
        "    d[str(i[0])+', '+str(i[1])] += 1\n",
        "print('Distribution of classes: ', d)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distribution of classes:  {'1.0, 0.0': 24820, '0.0, 1.0': 25180}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N-wDq6HyUwYI"
      },
      "source": [
        "For our dataset, the theoritical mutual information between $X$ and $Y$ would be\n",
        "\\begin{align}\n",
        "I(X;Y) & = \\sum_{x\\in X, y\\in Y}P(x,y)\\log\\Big(\\frac{P(x,y)}{P(x)P(y)}\\Big) \\\\\n",
        "& = \\sum_{x\\in X}\\Big[P(x,y=0)\\log\\Big(\\frac{P(x,y=0)}{P(x)P(y=0)}\\Big) + P(x,y=1)\\log\\Big(\\frac{P(x,y=1)}{P(x)P(y=1)}\\Big)\\Big] \\\\\n",
        "& = 1024 \\Big[ \\frac{1}{1024}\\log\\Big(\\frac{1/1024}{0.5/1024}\\Big) + 0\\Big] \\\\\n",
        "& = 0.693.\n",
        "\\end{align}\n",
        "Note that terms with $P(x,y)=0$ are set to $0$ for entropy calculation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZEzcIfE-UwYP",
        "colab": {}
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, n_inputs, n_hidden, n_classes, neg_slope=0.02):\n",
        "        super(MLP, self).__init__()\n",
        "        self.n_inputs = n_inputs,\n",
        "        self.n_hidden = n_hidden,\n",
        "        self.n_classes = n_classes\n",
        "        \n",
        "        self.layers = []\n",
        "        self.num_neurons = [n_inputs] + n_hidden + [n_classes]\n",
        "        self.models = {}\n",
        "        for i in range(len(self.num_neurons) - 2):\n",
        "            self.layers.append(nn.Linear(self.num_neurons[i], self.num_neurons[i+1]))\n",
        "            self.layers.append(nn.Tanh())\n",
        "            self.models['Linear{}'.format(i)] = nn.Sequential(*self.layers)\n",
        "            \n",
        "\n",
        "        self.layers.append(nn.Linear(self.num_neurons[i+1], self.num_neurons[i+2]))\n",
        "        self.models['Output'] = nn.Sequential(*self.layers)\n",
        "        self.full_model = self.models['Output']\n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self, x, exitLayer=None): \n",
        "        if exitLayer is not None:\n",
        "            out = self.models[exitLayer](x)\n",
        "        else:\n",
        "            out = self.full_model(x)\n",
        "        return out\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, z_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        self.z_dim = z_dim\n",
        "        \n",
        "        # Vanilla MLP\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(10, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, z_dim*2),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0),-1) # Flatten the input\n",
        "        params = self.net(x)\n",
        "        \n",
        "        mu, sigma = params[:,:self.z_dim], params[:,self.z_dim:]\n",
        "        sigma = softplus(sigma) + 1e-7  # Make sigma always positive\n",
        "        \n",
        "        return Independent(Normal(loc=mu, scale=sigma), 1) # Return a factorized Normal distribution"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tfwUDM2_UwYV",
        "colab": {}
      },
      "source": [
        "def get_named_layers(net):\n",
        "    conv2d_idx = 0\n",
        "    convT2d_idx = 0\n",
        "    linear_idx = 0\n",
        "    batchnorm2d_idx = 0\n",
        "    named_layers = {}\n",
        "    for mod in net.modules():\n",
        "        if isinstance(mod, torch.nn.Conv2d):\n",
        "            layer_name = 'Conv2d{}_{}-{}'.format(\n",
        "                conv2d_idx, mod.in_channels, mod.out_channels\n",
        "            )\n",
        "            named_layers[layer_name] = mod\n",
        "            conv2d_idx += 1\n",
        "        elif isinstance(mod, torch.nn.ConvTranspose2d):\n",
        "            layer_name = 'ConvT2d{}_{}-{}'.format(\n",
        "                conv2d_idx, mod.in_channels, mod.out_channels\n",
        "            )\n",
        "            named_layers[layer_name] = mod\n",
        "            convT2d_idx += 1\n",
        "        elif isinstance(mod, torch.nn.BatchNorm2d):\n",
        "            layer_name = 'BatchNorm2D{}_{}'.format(\n",
        "                batchnorm2d_idx, mod.num_features)\n",
        "            named_layers[layer_name] = mod\n",
        "            batchnorm2d_idx += 1\n",
        "        elif isinstance(mod, torch.nn.Linear):\n",
        "            layer_name = 'Linear{}_{}-{}'.format(\n",
        "                linear_idx, mod.in_features, mod.out_features\n",
        "            )\n",
        "            named_layers[layer_name] = mod\n",
        "            linear_idx += 1\n",
        "    return named_layers\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    accuracy = (predictions.argmax(dim=1) == targets.argmax(dim=1)).type(torch.FloatTensor).mean().item()\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GeHMyJCMUwYZ",
        "outputId": "fe480ff9-aa7e-4207-8c85-5b9a928e35c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "num_epochs = 2000\n",
        "dnn_hidden_units = [16, 12, 8, 6, 4]\n",
        "dnn_input_units = x_train.shape[1]\n",
        "dnn_output_units = y_train.shape[1]\n",
        "eval_freq = 100\n",
        "\n",
        "MLP_object = MLP(dnn_input_units, dnn_hidden_units, dnn_output_units).to(device)\n",
        "get_named_layers(MLP_object)\n",
        "#MLP_object.parameters()\n",
        "print(MLP_object.models)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Linear0': Sequential(\n",
            "  (0): Linear(in_features=10, out_features=16, bias=True)\n",
            "  (1): Tanh()\n",
            "), 'Linear1': Sequential(\n",
            "  (0): Linear(in_features=10, out_features=16, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=16, out_features=12, bias=True)\n",
            "  (3): Tanh()\n",
            "), 'Linear2': Sequential(\n",
            "  (0): Linear(in_features=10, out_features=16, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=16, out_features=12, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=12, out_features=8, bias=True)\n",
            "  (5): Tanh()\n",
            "), 'Linear3': Sequential(\n",
            "  (0): Linear(in_features=10, out_features=16, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=16, out_features=12, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=12, out_features=8, bias=True)\n",
            "  (5): Tanh()\n",
            "  (6): Linear(in_features=8, out_features=6, bias=True)\n",
            "  (7): Tanh()\n",
            "), 'Linear4': Sequential(\n",
            "  (0): Linear(in_features=10, out_features=16, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=16, out_features=12, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=12, out_features=8, bias=True)\n",
            "  (5): Tanh()\n",
            "  (6): Linear(in_features=8, out_features=6, bias=True)\n",
            "  (7): Tanh()\n",
            "  (8): Linear(in_features=6, out_features=4, bias=True)\n",
            "  (9): Tanh()\n",
            "), 'Output': Sequential(\n",
            "  (0): Linear(in_features=10, out_features=16, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=16, out_features=12, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=12, out_features=8, bias=True)\n",
            "  (5): Tanh()\n",
            "  (6): Linear(in_features=8, out_features=6, bias=True)\n",
            "  (7): Tanh()\n",
            "  (8): Linear(in_features=6, out_features=4, bias=True)\n",
            "  (9): Tanh()\n",
            "  (10): Linear(in_features=4, out_features=2, bias=True)\n",
            ")}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xr1RbbhZpvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "#Calculate real MI throughout training\n",
        "def calc_mutual_information(hidden):\n",
        "    n_neurons = hidden.shape[-1]\n",
        "  \n",
        "    # discretization \n",
        "    n_bins = 30\n",
        "    bins = np.linspace(-1, 1, n_bins+1)\n",
        "    indices = np.digitize(hidden, bins)\n",
        "    \n",
        "    # initialize pdfs\n",
        "    pdf_x = Counter(); pdf_y = Counter(); pdf_t = Counter(); pdf_xt = Counter(); pdf_yt = Counter()\n",
        "\n",
        "    for i in range(n_train_samples):\n",
        "        pdf_x[x_train_int[i]] += 1/float(n_train_samples)\n",
        "        pdf_y[y_train[i,0]] += 1/float(n_train_samples)      \n",
        "        pdf_xt[(x_train_int[i],)+tuple(indices[i,:])] += 1/float(n_train_samples)\n",
        "        pdf_yt[(y_train[i,0],)+tuple(indices[i,:])] += 1/float(n_train_samples)\n",
        "        pdf_t[tuple(indices[i,:])] += 1/float(n_train_samples)\n",
        "    \n",
        "    # calcuate encoder mutual information I(X;T)\n",
        "    mi_xt = 0\n",
        "    for i in pdf_xt:\n",
        "        # P(x,t), P(x) and P(t)\n",
        "        p_xt = pdf_xt[i]; p_x = pdf_x[i[0]]; p_t = pdf_t[i[1:]]\n",
        "        # I(X;T)\n",
        "        mi_xt += p_xt * np.log(p_xt / p_x / p_t)\n",
        " \n",
        "    # calculate decoder mutual information I(T;Y)\n",
        "    mi_ty = 0\n",
        "    for i in pdf_yt:\n",
        "        # P(t,y), P(t) and P(y)\n",
        "        p_yt = pdf_yt[i]; p_t = pdf_t[i[1:]]; p_y = pdf_y[i[0]]\n",
        "        # I(T;Y)\n",
        "        try:\n",
        "          mi_ty += p_yt * np.log(p_yt / p_t / p_y)\n",
        "        except ZeroDivisionError:\n",
        "          mi_ty += p_yt * np.log(p_yt / (p_t + 1e-5) / (p_y + 1e-5))\n",
        "            \n",
        "    return mi_xt, mi_ty\n",
        "\n",
        "# get mutual information for all hidden layers\n",
        "def get_mutual_information(hidden):\n",
        "    mi_xt_list = []; mi_ty_list = []\n",
        "    # for hidden in hiddens:\n",
        "    if True:\n",
        "        mi_xt, mi_ty = calc_mutual_information(hidden)\n",
        "        mi_xt_list.append(mi_xt)\n",
        "        mi_ty_list.append(mi_ty)\n",
        "    return mi_xt_list, mi_ty_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u_OKUCe-UwYf",
        "outputId": "7413d0a9-82ff-4d61-b571-ae33ce9399f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def train_encoder(enc_type='MLP', layer='Linear4'):\n",
        "  \n",
        "    if enc_type == 'MLP':\n",
        "      Net = MLP(dnn_input_units, dnn_hidden_units, dnn_output_units).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(Net.parameters(), lr=3e-3)#, momentum=0.2)\n",
        "    \n",
        "    X_test, Y_test = torch.tensor(x_test, requires_grad=False).float().to(device), torch.tensor(y_test, requires_grad=False).float().to(device)\n",
        "    accuracy_evaluation = {'train': [], 'test': []}\n",
        "    loss_evaluation = {'train': [], 'test': []}\n",
        "    mi_xt_all = []; mi_ty_all = []; epochs = []\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        X_train, Y_train = torch.from_numpy(x_train).float().to(device), torch.from_numpy(y_train).float().to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        out = Net(X_train)\n",
        "        loss = criterion(out, Y_train.argmax(dim=1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % eval_freq == 0 or epoch == num_epochs - 1:\n",
        "            mi_xt, mi_ty = get_mutual_information(Net.models['Linear4'](X_train).cpu().data.numpy())\n",
        "            mi_xt_all.append(mi_xt)\n",
        "            mi_ty_all.append(mi_ty)\n",
        "            print('#'*30)\n",
        "            print('Step - ', epoch)\n",
        "            print('Train: Accuracy - %0.3f, Loss - %0.3f' % (accuracy(out, Y_train), loss))\n",
        "            print('Test: Accuracy - %0.3f, Loss - %0.3f' % (accuracy(Net(X_test), Y_test), criterion(Net(X_test), Y_test.argmax(dim=1))))\n",
        "            print('I(X, %s) - %s', % (layer, mi_xt))\n",
        "            print('I(%s, Y) - %s', % (layer, mi_ty))\n",
        "            print('Elapse time: ', time.time() - start_time)\n",
        "            print('#'*30,'\\n')\n",
        "\n",
        "    return Net, mi_xt, mi_ty\n",
        "Encoder, true_MI_x, true_MI_y = train_encoder(layer = 'Linear3')\n",
        "print(Encoder)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##############################\n",
            "Step -  0\n",
            "Train: Accuracy - 0.496, Loss - 0.703\n",
            "Test: Accuracy - 0.496, Loss - 0.701\n",
            "I(X, T) -  [1.7959401525079728]\n",
            "I(T, Y) -  [0.008007460799442659]\n",
            "Elapse time:  0.4369790554046631\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  100\n",
            "Train: Accuracy - 0.750, Loss - 0.485\n",
            "Test: Accuracy - 0.751, Loss - 0.483\n",
            "I(X, T) -  [1.9846161172971344]\n",
            "I(T, Y) -  [0.3495621499711857]\n",
            "Elapse time:  1.29341459274292\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  200\n",
            "Train: Accuracy - 0.873, Loss - 0.211\n",
            "Test: Accuracy - 0.874, Loss - 0.206\n",
            "I(X, T) -  [2.1511290522561697]\n",
            "I(T, Y) -  [0.6931212603355825]\n",
            "Elapse time:  2.146254062652588\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  300\n",
            "Train: Accuracy - 1.000, Loss - 0.013\n",
            "Test: Accuracy - 1.000, Loss - 0.013\n",
            "I(X, T) -  [2.0620822028026318]\n",
            "I(T, Y) -  [0.693121260335538]\n",
            "Elapse time:  2.9661104679107666\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  400\n",
            "Train: Accuracy - 1.000, Loss - 0.005\n",
            "Test: Accuracy - 1.000, Loss - 0.005\n",
            "I(X, T) -  [2.0559739312808487]\n",
            "I(T, Y) -  [0.6931212603355791]\n",
            "Elapse time:  3.7917163372039795\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  500\n",
            "Train: Accuracy - 1.000, Loss - 0.003\n",
            "Test: Accuracy - 1.000, Loss - 0.003\n",
            "I(X, T) -  [1.8591951773955915]\n",
            "I(T, Y) -  [0.693121260335567]\n",
            "Elapse time:  4.6477367877960205\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  600\n",
            "Train: Accuracy - 1.000, Loss - 0.002\n",
            "Test: Accuracy - 1.000, Loss - 0.002\n",
            "I(X, T) -  [1.6169308397317417]\n",
            "I(T, Y) -  [0.69312126033554]\n",
            "Elapse time:  5.493772745132446\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  700\n",
            "Train: Accuracy - 1.000, Loss - 0.002\n",
            "Test: Accuracy - 1.000, Loss - 0.002\n",
            "I(X, T) -  [1.601370156913153]\n",
            "I(T, Y) -  [0.6931212603356163]\n",
            "Elapse time:  6.337270259857178\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  800\n",
            "Train: Accuracy - 1.000, Loss - 0.001\n",
            "Test: Accuracy - 1.000, Loss - 0.001\n",
            "I(X, T) -  [1.7122161868101877]\n",
            "I(T, Y) -  [0.6931212603355286]\n",
            "Elapse time:  7.162145137786865\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  900\n",
            "Train: Accuracy - 1.000, Loss - 0.001\n",
            "Test: Accuracy - 1.000, Loss - 0.001\n",
            "I(X, T) -  [1.7411789401599096]\n",
            "I(T, Y) -  [0.6931212603355587]\n",
            "Elapse time:  7.992454528808594\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  1000\n",
            "Train: Accuracy - 1.000, Loss - 0.001\n",
            "Test: Accuracy - 1.000, Loss - 0.001\n",
            "I(X, T) -  [1.6450831577302585]\n",
            "I(T, Y) -  [0.6931212603355597]\n",
            "Elapse time:  8.814082384109497\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  1100\n",
            "Train: Accuracy - 1.000, Loss - 0.001\n",
            "Test: Accuracy - 1.000, Loss - 0.001\n",
            "I(X, T) -  [1.6159392038052338]\n",
            "I(T, Y) -  [0.693121260335565]\n",
            "Elapse time:  9.650123357772827\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  1200\n",
            "Train: Accuracy - 1.000, Loss - 0.001\n",
            "Test: Accuracy - 1.000, Loss - 0.001\n",
            "I(X, T) -  [1.5236723789239168]\n",
            "I(T, Y) -  [0.6931212603355931]\n",
            "Elapse time:  10.495075225830078\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  1300\n",
            "Train: Accuracy - 1.000, Loss - 0.001\n",
            "Test: Accuracy - 1.000, Loss - 0.001\n",
            "I(X, T) -  [1.4602971584956286]\n",
            "I(T, Y) -  [0.6931212603356036]\n",
            "Elapse time:  11.457530975341797\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  1400\n",
            "Train: Accuracy - 1.000, Loss - 0.000\n",
            "Test: Accuracy - 1.000, Loss - 0.000\n",
            "I(X, T) -  [1.5133959094856215]\n",
            "I(T, Y) -  [0.6931212603356072]\n",
            "Elapse time:  12.298899412155151\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  1500\n",
            "Train: Accuracy - 1.000, Loss - 0.000\n",
            "Test: Accuracy - 1.000, Loss - 0.000\n",
            "I(X, T) -  [1.5490937079427536]\n",
            "I(T, Y) -  [0.6931212603356101]\n",
            "Elapse time:  13.12541389465332\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  1600\n",
            "Train: Accuracy - 1.000, Loss - 0.000\n",
            "Test: Accuracy - 1.000, Loss - 0.000\n",
            "I(X, T) -  [1.495155988693814]\n",
            "I(T, Y) -  [0.6931212603356027]\n",
            "Elapse time:  13.957014799118042\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  1700\n",
            "Train: Accuracy - 1.000, Loss - 0.000\n",
            "Test: Accuracy - 1.000, Loss - 0.000\n",
            "I(X, T) -  [1.4420999715232787]\n",
            "I(T, Y) -  [0.6931212603355987]\n",
            "Elapse time:  14.779107332229614\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  1800\n",
            "Train: Accuracy - 1.000, Loss - 0.000\n",
            "Test: Accuracy - 1.000, Loss - 0.000\n",
            "I(X, T) -  [1.3895077608935118]\n",
            "I(T, Y) -  [0.6931212603355933]\n",
            "Elapse time:  15.609607219696045\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  1900\n",
            "Train: Accuracy - 1.000, Loss - 0.000\n",
            "Test: Accuracy - 1.000, Loss - 0.000\n",
            "I(X, T) -  [1.3687280783486704]\n",
            "I(T, Y) -  [0.6931212603355913]\n",
            "Elapse time:  16.464709997177124\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  1999\n",
            "Train: Accuracy - 1.000, Loss - 0.000\n",
            "Test: Accuracy - 1.000, Loss - 0.000\n",
            "I(X, T) -  [1.4833531789107504]\n",
            "I(T, Y) -  [0.6931212603355543]\n",
            "Elapse time:  17.43017601966858\n",
            "############################## \n",
            "\n",
            "MLP(\n",
            "  (full_model): Sequential(\n",
            "    (0): Linear(in_features=10, out_features=16, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=16, out_features=12, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=12, out_features=8, bias=True)\n",
            "    (5): Tanh()\n",
            "    (6): Linear(in_features=8, out_features=6, bias=True)\n",
            "    (7): Tanh()\n",
            "    (8): Linear(in_features=6, out_features=4, bias=True)\n",
            "    (9): Tanh()\n",
            "    (10): Linear(in_features=4, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z3qZ1W8XUwYr",
        "colab": {}
      },
      "source": [
        "from torch.nn.functional import softplus\n",
        "\n",
        "# Neural approximation of MI starts here\n",
        "# Auxiliary network for mutual information estimation\n",
        "class MIEstimator(nn.Module):\n",
        "    def __init__(self, size1, size2):\n",
        "        super(MIEstimator, self).__init__()\n",
        "        \n",
        "        # Vanilla MLP\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(size1 + size2, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, 1),\n",
        "        )\n",
        "    \n",
        "    # Gradient for JSD mutual information estimation and EB-based estimation\n",
        "    def forward(self, x1, x2):\n",
        "        # breakpoint()\n",
        "        pos = self.net(torch.cat([x1, x2], 1)) #Positive Samples \n",
        "        neg = self.net(torch.cat([torch.roll(x1, 1, 0), x2], 1)) #Predictions for shuffled (negative) samples from p(z1)p(z2)\n",
        "        #breakpoint()\n",
        "        return -softplus(-pos).mean() - softplus(neg).mean(), pos.mean() - neg.exp().mean() + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_FkycCh9UwYw"
      },
      "source": [
        "We are now able to estimate the mutual information while training the network. We'll save the mutual information for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4rHCT2r8YuyO",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Subset\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "class Scheduler:\n",
        "    def __call__(self, **kwargs):\n",
        "        raise NotImplemented()\n",
        "\n",
        "class LinearScheduler(Scheduler):\n",
        "    def __init__(self, start_value, end_value, n_iterations, start_iteration=0):\n",
        "        self.start_value = start_value\n",
        "        self.end_value = end_value\n",
        "        self.n_iterations = n_iterations\n",
        "        self.start_iteration = start_iteration\n",
        "        self.m = (end_value - start_value) / n_iterations\n",
        "\n",
        "    def __call__(self, iteration):\n",
        "        if iteration > self.start_iteration + self.n_iterations:\n",
        "            return self.end_value\n",
        "        elif iteration <= self.start_iteration:\n",
        "            return self.start_value\n",
        "        else:\n",
        "            return (iteration - self.start_iteration) * self.m + self.start_value\n",
        "\n",
        "class ExponentialScheduler(LinearScheduler):\n",
        "    def __init__(self, start_value, end_value, n_iterations, start_iteration=0, base=10):\n",
        "        self.base = base\n",
        "\n",
        "        super(ExponentialScheduler, self).__init__(start_value=math.log(start_value, base),\n",
        "                                                   end_value=math.log(end_value, base),\n",
        "                                                   n_iterations=n_iterations,\n",
        "                                                   start_iteration=start_iteration)\n",
        "\n",
        "    def __call__(self, iteration):\n",
        "        linear_value = super(ExponentialScheduler, self).__call__(iteration)\n",
        "        return self.base ** linear_value\n",
        "\n",
        "def split(dataset, size, split_type):\n",
        "    if split_type == 'Random':\n",
        "        data_split, _ = torch.utils.data.random_split(dataset, [size, len(dataset) - size])\n",
        "    elif split_type == 'Balanced':\n",
        "        class_ids = {}\n",
        "        for idx, (_, y) in enumerate(dataset):\n",
        "            try:\n",
        "                y = int(y.item())\n",
        "            except:\n",
        "                pass\n",
        "            if y not in class_ids:\n",
        "                class_ids[y] = []\n",
        "            class_ids[y].append(idx)\n",
        "\n",
        "        ids_per_class = size // len(class_ids)\n",
        "\n",
        "        selected_ids = []\n",
        "\n",
        "        for ids in class_ids.values():\n",
        "            selected_ids += list(np.random.choice(ids, min(ids_per_class, len(ids)), replace=False))\n",
        "        data_split = torch.utils.data.Subset(dataset, selected_ids)\n",
        "\n",
        "    return data_split\n",
        "\n",
        "\n",
        "class EmbeddedDataset:\n",
        "    BLOCK_SIZE = 1\n",
        "\n",
        "    def __init__(self, base_dataset, encoder, cuda=True):\n",
        "        if cuda:\n",
        "            encoder = encoder.cuda()\n",
        "        self.means, self.target = self._embed(encoder, base_dataset, cuda)\n",
        "\n",
        "    def _embed(self, encoder, dataset, cuda):\n",
        "        encoder.eval()\n",
        "\n",
        "        data_loader = torch.utils.data.DataLoader(\n",
        "            dataset,\n",
        "            batch_size=self.BLOCK_SIZE,\n",
        "            shuffle=False)\n",
        "\n",
        "        ys = []\n",
        "        reps = []\n",
        "        with torch.no_grad():\n",
        "            for x, y in data_loader:\n",
        "                if cuda:\n",
        "                    x = x.cuda()\n",
        "                    y = y.cuda()\n",
        "\n",
        "                p_z_given_x = encoder(x)\n",
        "                reps.append(p_z_given_x.detach())\n",
        "                ys.append(y)\n",
        "\n",
        "            ys = torch.cat(ys, 0)\n",
        "\n",
        "        encoder.train()\n",
        "        return reps, ys\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        y = self.target[index]\n",
        "        x = self.means[index][0]# // self.BLOCK_SIZE][index % self.BLOCK_SIZE]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.target.size(0)\n",
        "\n",
        "def train_and_evaluate_linear_model(train_set, test_set, solver='saga', multi_class='multinomial', tol=.1, C=2):\n",
        "    model = LogisticRegression(solver=solver, multi_class=multi_class, tol=tol, C=C)\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    x_train, y_train = build_matrix(train_set)\n",
        "    x_test, y_test = build_matrix(test_set)\n",
        "    x_train = scaler.fit_transform(x_train)\n",
        "    x_test = scaler.transform(x_test)\n",
        "\n",
        "    model.fit(x_train, y_train)\n",
        "    test_accuracy = model.score(x_test, y_test)\n",
        "    train_accuracy = model.score(x_train, y_train)\n",
        "\n",
        "    return train_accuracy, test_accuracy\n",
        "\n",
        "\n",
        "def build_matrix(dataset):\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "    xs = []\n",
        "    ys = []\n",
        "\n",
        "    for x, y in data_loader:\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "\n",
        "    xs = torch.cat(xs, 0)\n",
        "    ys = torch.cat(ys, 0)\n",
        "\n",
        "    if xs.is_cuda:\n",
        "        xs = xs.cpu()\n",
        "    if ys.is_cuda:\n",
        "        ys = ys.cpu()\n",
        "\n",
        "    return xs.data.numpy(), ys.data.numpy()\n",
        "\n",
        "def evaluate(encoder, train_on, test_on, cuda):\n",
        "    embedded_train = EmbeddedDataset(train_on, encoder, cuda=cuda)\n",
        "    embedded_test = EmbeddedDataset(test_on, encoder, cuda=cuda)\n",
        "    return train_and_evaluate_linear_model(embedded_train, embedded_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91duTE0CUrud",
        "colab_type": "code",
        "outputId": "3561add6-df30-4271-e021-d69055217cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def train_MI(encoder, num_epochs=2000, dnn_hidden_units=[]):\n",
        "    \n",
        "    #x_train, y_train, x_train_int = generate_samples(n_train_samples) # training dataset\n",
        "    #x_test, y_test, _ = generate_samples(n_test_samples) # testing dataset\n",
        "    mi_xt_all = []; mi_ty_all = []; epochs = []\n",
        "    mi_xz = []; mi_zy = []\n",
        "\n",
        "    X_test, Y_test = torch.tensor(x_test, requires_grad=False).to(device), torch.tensor(y_test, requires_grad=False).to(device)\n",
        "\n",
        "    z_test = torch.tensor(encoder(X_test.float()), requires_grad=False).to(device)\n",
        "\n",
        "    x_dim, y_dim, z_dim = x_test.shape[-1], y_test.shape[-1], z_test.shape[-1]\n",
        "    print(x_dim, y_dim, z_dim)\n",
        "    mi_estimator_X = MIEstimator(x_dim, z_dim).to(device)\n",
        "    mi_estimator_Y = MIEstimator(z_dim, y_dim).to(device)\n",
        "\n",
        "    optimizer = optim.Adam([\n",
        "    {'params': mi_estimator_X.parameters(), 'lr':1e-3},\n",
        "    {'params': mi_estimator_Y.parameters(), 'lr':1e-3},\n",
        "    ])\n",
        "\n",
        "    beta_scheduler = ExponentialScheduler(start_value=1e-9, end_value=1e-2, n_iterations=num_epochs, start_iteration=10)\n",
        "\n",
        "    accuracy_evaluation = {'train': [], 'test': []}\n",
        "    loss_evaluation = {'train': [], 'test': []}\n",
        "\n",
        "    start_time = time.time()\n",
        "    max_MI_x, max_MI_y = 0, 0\n",
        "    mi_est_all = {'X': [], 'Y': []}\n",
        "    for epoch in range(num_epochs):\n",
        "        beta = beta_scheduler(epoch)\n",
        "\n",
        "        X_train, Y_train = torch.from_numpy(x_train).to(device).float(), torch.from_numpy(y_train).to(device).float()\n",
        "        z_train = encoder(X_train.float())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        mi_gradient_X, mi_estimation_X = mi_estimator_X(X_train, z_train)\n",
        "        mi_gradient_X = mi_gradient_X.mean()\n",
        "        mi_estimation_X = mi_estimation_X.mean()\n",
        "\n",
        "        mi_gradient_Y, mi_estimation_Y = mi_estimator_Y(z_train, Y_train.float())\n",
        "        mi_gradient_Y = mi_gradient_Y.mean()\n",
        "        mi_estimation_Y = mi_estimation_Y.mean()\n",
        "                \n",
        "        loss_mi = - mi_gradient_Y - mi_gradient_X\n",
        "        loss_mi.backward()\n",
        "        optimizer.step()\n",
        "        mi_est_all['X'].append(mi_estimation_X.item())\n",
        "        mi_est_all['Y'].append(mi_estimation_Y.item())\n",
        "        eval_freq = 10\n",
        "        if epoch >= 500:\n",
        "          if mi_estimation_X.item() > max_MI_x:\n",
        "            max_MI_x = mi_estimation_X.item()\n",
        "            max_MI_y = mi_estimation_Y.item()\n",
        "          if np.mean(mi_est_all['X'][-100]) > max_MI_x - 1e-1:\n",
        "            break\n",
        "        if epoch % eval_freq == 0 or epoch == num_epochs - 1:\n",
        "            mi_xt, mi_ty = get_mutual_information(z_train.cpu().data.numpy())\n",
        "            mi_xt_all.append(mi_xt)\n",
        "            mi_ty_all.append(mi_ty)\n",
        "            print('#'*30)\n",
        "            print('Step - ', epoch)\n",
        "            # print('Train: Accuracy - %0.3f, Loss - %0.3f' % (accuracy(out, Y_train), loss))\n",
        "            # print('Test: Accuracy - %0.3f, Loss - %0.3f' % (accuracy(predictor(z_test.float()), Y_test), criterion(predictor(z_test.float()), Y_test.argmax(dim=1))))\n",
        "            print('I(X, %s) - %s' % (layer, mi_xt[0]))\n",
        "            print('I(%s, Y) - %s' % (layer, mi_ty[0]))\n",
        "            print('I_est(X, %s) - %s' % (layer, mi_estimation_X.item()))\n",
        "            #print('Grad I_est(X, T)', mi_gradient_X)\n",
        "            print('I_est(%s, Y) - %s' % (layer, mi_estimation_Y.item()))\n",
        "            #print('Grad I_est(T, Y)', mi_gradient_Y)\n",
        "            print('Elapsed time training MI for %s: %s' % (layer, time.time() - start_time))\n",
        "            print('#'*30,'\\n')\n",
        "            \n",
        "    return max_MI_x, max_MI_y\n",
        "\n",
        "n_train_samples = 50000\n",
        "n_test_samples = 10000\n",
        "\n",
        "\n",
        "num_labels_range = [2**i for i in range(1, int(np.log2(n_train_samples)-8))]\n",
        "\n",
        "acc = {layer:{i:[] for i in num_labels_range} for layer in layers}\n",
        "print(num_labels_range)\n",
        "seeds = [9, 42, 103, 48, 79]\n",
        "layers = ['Linear2', 'Linear3', 'Linear4']\n",
        "mi_layers = {} #probably make for different seeds as well\n",
        "start_time = time.time()\n",
        "for i in range(len(seeds)):\n",
        "\n",
        "    \n",
        "    print('\\nRunning with seed %d out of %d' % (i, len(seeds)))\n",
        "    torch.manual_seed(seeds[i])\n",
        "    np.random.seed(seeds[i])\n",
        "    seed(seeds[i])\n",
        "    \n",
        "    \n",
        "    for layer in layers:\n",
        "\n",
        "        x_train, y_train, x_train_int = generate_samples(n_train_samples) # training dataset\n",
        "        x_test, y_test, _ = generate_samples(10*n_test_samples) # testing dataset\n",
        "        if seed_ == 9:\n",
        "            MI_X, MI_Y = train_MI(Encoder.models[layer], num_epochs=2000)\n",
        "            mi_layers[layer] = (MI_X, MI_Y)\n",
        "            print('MI values for %s - %s, %s' % (layer, MI_X, MI_Y))\n",
        "        y_train = y_train.argmax(axis=1)\n",
        "        y_test = y_test.argmax(axis=1)\n",
        "        train_set = torch.utils.data.TensorDataset(torch.Tensor(x_train).to(device), torch.Tensor(y_train).to(device)) \n",
        "        test_set = torch.utils.data.TensorDataset(torch.Tensor(x_test).to(device), torch.Tensor(y_test).to(device))\n",
        "    \n",
        "        \n",
        "        for num_labels in num_labels_range:\n",
        "            print('Evaluating for %s %s' % (layer, num_labels))\n",
        "            #acc[layer].append(train_MI(num_labels, Encoder, num_epochs=2000))\n",
        "            \n",
        "\n",
        "\n",
        "            train_subset = split(train_set, num_labels, 'Balanced') \n",
        "            test_subset = split(train_set, n_test_samples, 'Random') \n",
        "            train_accuracy, test_accuracy = evaluate(encoder=Encoder.models[layer], train_on=train_subset, test_on=test_subset, cuda=torch.cuda.is_available())\n",
        "            #train_accuracy, test_accuracy = train_and_evaluate_linear_model(train_subset, test_set, C=2)\n",
        "            print('Train Accuracy: %f'% train_accuracy)\n",
        "            print('Test Accuracy: %f'% test_accuracy)\n",
        "            acc[layer][num_labels].append(test_accuracy)\n",
        "    print('Elapsed time - ', time.time() - start_time)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 4, 8, 16, 32, 64]\n",
            "\n",
            "Running with seed  9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10 2 8\n",
            "##############################\n",
            "Step -  0\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(-0.0203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(-0.0058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 0.7322862148284912\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  10\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(0.1403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.4235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 3.173912286758423\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  20\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(0.4866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 5.602099180221558\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  30\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(0.7446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 8.017571687698364\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  40\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(1.0021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 10.437288761138916\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  50\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(1.3780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 12.856486797332764\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  60\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(1.5697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 15.27194595336914\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  70\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(1.6998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 17.70868158340454\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  80\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(1.7946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 20.18118667602539\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  90\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(1.8617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 22.604316234588623\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  100\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(1.9142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 25.037957191467285\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  110\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(1.9710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 27.450430870056152\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  120\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.0153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 29.86507749557495\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  130\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(1.9904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 32.293334007263184\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  140\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.0732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 34.70770311355591\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  150\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.1370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 37.1310498714447\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  160\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.1394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 39.55328679084778\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  170\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.1939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 41.99134826660156\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  180\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.0116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 44.41556739807129\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  190\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(1.4011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 46.94979453086853\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  200\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.0950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 49.37121868133545\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  210\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 51.8001811504364\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  220\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.2455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 54.230536699295044\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  230\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.2660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 56.672800064086914\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  240\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.2896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 59.1036856174469\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  250\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.3101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 61.520373821258545\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  260\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.3281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 63.96981883049011\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  270\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.3470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 66.39871835708618\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  280\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.3548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 68.82351064682007\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  290\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.3746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 71.2777259349823\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  300\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.3669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 73.71280550956726\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  310\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.3902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 76.15158081054688\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  320\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.3238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 78.6019868850708\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  330\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.3613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 81.03323745727539\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  340\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.4317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 83.47245264053345\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  350\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.4389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 85.89658665657043\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  360\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.4533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 88.31590747833252\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  370\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.3923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 90.74291396141052\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  380\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.4596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 93.15346002578735\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  390\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.2631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 95.58096742630005\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  400\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(1.1774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 98.02943706512451\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  410\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.2261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 100.46717667579651\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  420\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(1.9662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 102.89076352119446\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  430\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.3698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 105.30944681167603\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  440\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.4232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 107.77088284492493\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  450\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.4885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 110.1930878162384\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  460\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.5107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 112.735604763031\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  470\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.5126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 115.17068481445312\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  480\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.5241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 117.58001041412354\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  490\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.5350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 120.00903677940369\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  500\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.5486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 122.44780087471008\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  510\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.5538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 124.87595129013062\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  520\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.5490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 127.3070867061615\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  530\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.5734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 129.74754786491394\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  540\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.5755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 132.1844289302826\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  550\n",
            "I(X, Linear2) - [3.48226004319869]\n",
            "I(Linear2, Y) - [0.6931421877511955]\n",
            "I_est(X, Linear2) - tensor(2.5776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear2, Y) - tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear2: 134.61367177963257\n",
            "############################## \n",
            "\n",
            "MI values for Linear2 - 2.6026168, 0.6980356\n",
            "Evaluating for Linear2 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.633100\n",
            "Evaluating for Linear2 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.742800\n",
            "Evaluating for Linear2 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear2 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear2 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear2 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10 2 6\n",
            "##############################\n",
            "Step -  0\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(-0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 0.6725060939788818\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  10\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(0.4532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.5108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 3.071054697036743\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  20\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(0.7729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 5.441533088684082\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  30\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.0872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 7.796995639801025\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  40\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.2954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 10.25820779800415\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  50\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.3528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 12.632757186889648\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  60\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.3792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 15.020549535751343\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  70\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.3983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 17.384674787521362\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  80\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.4223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 19.76730227470398\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  90\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.4295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 22.131070613861084\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  100\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.4401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 24.499903678894043\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  110\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.4542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 26.865442752838135\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  120\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.4245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 29.215961694717407\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  130\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.2841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 31.587295055389404\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  140\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.4455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 33.97750973701477\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  150\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.4733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 36.33772253990173\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  160\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.4978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 38.69957876205444\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  170\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.5180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 41.09059143066406\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  180\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.5307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 43.450196504592896\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  190\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.5310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 45.810067892074585\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  200\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.4943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 48.17605376243591\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  210\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.3599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 50.54000186920166\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  220\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.4920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 52.90446925163269\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  230\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.5436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 55.28338027000427\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  240\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.5590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 57.65997767448425\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  250\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.5845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 60.021374464035034\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  260\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.5862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 62.40993118286133\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  270\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.5942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 64.78385996818542\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  280\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.6315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 67.14536762237549\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  290\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.5730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 69.60636687278748\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  300\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.5974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 71.9870707988739\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  310\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.6136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 74.35164380073547\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  320\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.6310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 76.71482276916504\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  330\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.6633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 79.10669612884521\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  340\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.6508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 81.48571538925171\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  350\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.6487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 83.86357760429382\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  360\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.6486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 86.24334597587585\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  370\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.6481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 88.6194257736206\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  380\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.6438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 90.97775435447693\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  390\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.0348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 93.33907723426819\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  400\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.4235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 95.69179391860962\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  410\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.5264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 98.05314087867737\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  420\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.5868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 100.43593144416809\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  430\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.5890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 102.83414125442505\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  440\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.6311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 105.18935966491699\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  450\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.6461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 107.55084300041199\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  460\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.6608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 109.92159938812256\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  470\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.6736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 112.29655122756958\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  480\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.6813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 114.66156840324402\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  490\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.6898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 117.02700638771057\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  500\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.6995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 119.39273285865784\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  510\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.7116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 121.76338720321655\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  520\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.7046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 124.16721987724304\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  530\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.7278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 126.5350444316864\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  540\n",
            "I(X, Linear3) - [1.8273518805607587]\n",
            "I(Linear3, Y) - [0.6931206811254123]\n",
            "I_est(X, Linear3) - tensor(1.6876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear3, Y) - tensor(0.6911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear3: 128.9156038761139\n",
            "############################## \n",
            "\n",
            "MI values for Linear3 - 1.7390163, 0.69139165\n",
            "Evaluating for Linear3 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.627500\n",
            "Evaluating for Linear3 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.872100\n",
            "Evaluating for Linear3 8\n",
            "Train Accuracy: 0.875000\n",
            "Test Accuracy: 0.754700\n",
            "Evaluating for Linear3 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10 2 4\n",
            "##############################\n",
            "Step -  0\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(-0.0150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 0.6380081176757812\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  10\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(0.3208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 2.9841175079345703\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  20\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(0.5547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 5.351043701171875\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  30\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(0.8010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 7.725739479064941\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  40\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(0.9590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 10.063628435134888\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  50\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.0628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 12.404837846755981\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  60\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.1272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 14.757258892059326\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  70\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.1715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 17.095134735107422\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  80\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.2121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 19.429054737091064\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  90\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.2437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 21.77112627029419\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  100\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.2546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 24.1251220703125\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  110\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.2854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 26.466581344604492\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  120\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 28.82677388191223\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  130\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.2689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 31.16934585571289\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  140\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 33.507323026657104\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  150\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 35.89558386802673\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  160\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 38.247151374816895\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  170\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 40.58428692817688\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  180\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 42.98042130470276\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  190\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.2950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 45.33020758628845\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  200\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 47.67362952232361\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  210\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 50.007925033569336\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  220\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 52.35132932662964\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  230\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 54.6961784362793\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  240\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 57.04445481300354\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  250\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 59.395490884780884\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  260\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 61.740047454833984\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  270\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 64.08340787887573\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  280\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 66.43498849868774\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  290\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 68.8831102848053\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  300\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 71.22935795783997\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  310\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.2983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 73.57939219474792\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  320\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 75.92016363143921\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  330\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 78.26852631568909\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  340\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 80.60654926300049\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  350\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 82.96018815040588\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  360\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 85.33539319038391\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  370\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 87.68849205970764\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  380\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 90.04049038887024\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  390\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 92.38621115684509\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  400\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 94.74549770355225\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  410\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 97.13248753547668\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  420\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 99.4740469455719\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  430\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 101.91782402992249\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  440\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 104.25135970115662\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  450\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 106.58629155158997\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  460\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 108.92925500869751\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  470\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 111.29192399978638\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  480\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 113.62957906723022\n",
            "############################## \n",
            "\n",
            "##############################\n",
            "Step -  490\n",
            "I(X, Linear4) - [1.4823437585010808]\n",
            "I(Linear4, Y) - [0.6931471805595087]\n",
            "I_est(X, Linear4) - tensor(1.3457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "I_est(Linear4, Y) - tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Elapsed time training MI for Linear4: 115.96761560440063\n",
            "############################## \n",
            "\n",
            "MI values for Linear4 - 1.3829925, 0.6892369\n",
            "Evaluating for Linear4 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.762200\n",
            "Evaluating for Linear4 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.752300\n",
            "Evaluating for Linear4 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Elapsed time -  455.1623570919037\n",
            "\n",
            "Running with seed  42\n",
            "Evaluating for Linear2 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.619600\n",
            "Evaluating for Linear2 4\n",
            "Train Accuracy: 0.750000\n",
            "Test Accuracy: 0.491500\n",
            "Evaluating for Linear2 8\n",
            "Train Accuracy: 0.875000\n",
            "Test Accuracy: 0.627500\n",
            "Evaluating for Linear2 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear2 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear2 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.430100\n",
            "Evaluating for Linear3 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.747000\n",
            "Evaluating for Linear3 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 32\n",
            "Train Accuracy: 0.968750\n",
            "Test Accuracy: 0.878600\n",
            "Evaluating for Linear3 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.750300\n",
            "Evaluating for Linear4 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Elapsed time -  526.3568608760834\n",
            "\n",
            "Running with seed  103\n",
            "Evaluating for Linear2 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.623400\n",
            "Evaluating for Linear2 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.876100\n",
            "Evaluating for Linear2 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear2 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.746500\n",
            "Evaluating for Linear2 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear2 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.382900\n",
            "Evaluating for Linear3 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 16\n",
            "Train Accuracy: 0.875000\n",
            "Test Accuracy: 0.873300\n",
            "Evaluating for Linear3 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.752400\n",
            "Evaluating for Linear4 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Elapsed time -  597.3025388717651\n",
            "\n",
            "Running with seed  48\n",
            "Evaluating for Linear2 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.626400\n",
            "Evaluating for Linear2 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.757700\n",
            "Evaluating for Linear2 8\n",
            "Train Accuracy: 0.875000\n",
            "Test Accuracy: 0.750000\n",
            "Evaluating for Linear2 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear2 32\n",
            "Train Accuracy: 0.968750\n",
            "Test Accuracy: 0.873400\n",
            "Evaluating for Linear2 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.498700\n",
            "Evaluating for Linear3 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.623700\n",
            "Evaluating for Linear3 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.686500\n",
            "Evaluating for Linear3 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 2\n",
            "Train Accuracy: 0.500000\n",
            "Test Accuracy: 0.503200\n",
            "Evaluating for Linear4 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Elapsed time -  667.74023604393\n",
            "\n",
            "Running with seed  79\n",
            "Evaluating for Linear2 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.629700\n",
            "Evaluating for Linear2 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.748600\n",
            "Evaluating for Linear2 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.630900\n",
            "Evaluating for Linear2 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear2 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear2 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 2\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.510900\n",
            "Evaluating for Linear3 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 0.871500\n",
            "Evaluating for Linear3 8\n",
            "Train Accuracy: 0.875000\n",
            "Test Accuracy: 0.625300\n",
            "Evaluating for Linear3 16\n",
            "Train Accuracy: 0.937500\n",
            "Test Accuracy: 0.875200\n",
            "Evaluating for Linear3 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear3 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 2\n",
            "Train Accuracy: 0.500000\n",
            "Test Accuracy: 0.496300\n",
            "Evaluating for Linear4 4\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 8\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 16\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 32\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Evaluating for Linear4 64\n",
            "Train Accuracy: 1.000000\n",
            "Test Accuracy: 1.000000\n",
            "Elapsed time -  738.3053665161133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDXAwdvsKrz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "acc_df = pd.DataFrame.from_dict(acc)\n",
        "plot_data = pd.DataFrame()\n",
        "#df.to_csv('acc.csv', sep=' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L2TlkyAgJis",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a4276f9e-41a1-4ee4-ed80-748a3ba81834"
      },
      "source": [
        "mean = lambda x: np.mean(x)\n",
        "std = lambda x: np.std(x)\n",
        "acc_df['Linear4'].apply(mean)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2     0.65288\n",
              "4     0.95046\n",
              "8     1.00000\n",
              "16    1.00000\n",
              "32    1.00000\n",
              "64    1.00000\n",
              "Name: Linear4, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMtPl7e7e1v4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "89c4e3f0-649c-4e10-9c2b-cee647edbbd0"
      },
      "source": [
        "pd.DataFrame.from_dict(mi_layers)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Linear2</th>\n",
              "      <th>Linear3</th>\n",
              "      <th>Linear4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.6026168</td>\n",
              "      <td>1.7390163</td>\n",
              "      <td>1.3829925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.6980356</td>\n",
              "      <td>0.69139165</td>\n",
              "      <td>0.6892369</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Linear2     Linear3    Linear4\n",
              "0  2.6026168   1.7390163  1.3829925\n",
              "1  0.6980356  0.69139165  0.6892369"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqS3_Be1nDrG",
        "colab_type": "code",
        "outputId": "eee66dbd-77bb-4eae-99e4-070cf1caca6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        }
      },
      "source": [
        "fig1, ax1 = plt.subplots(3, 1, sharex=True)\n",
        "nums = np.array(num_labels_range)\n",
        "colors = ['black', 'blue', 'red']\n",
        "for i in range(len(layers)):\n",
        "    means = acc_df[layers[i]].apply(mean)\n",
        "    stds = acc_df[layers[i]].apply(std)\n",
        "    ax1[i].plot(nums, means, color=colors[i], label=layers[i])\n",
        "    ax1[i].fill_between(nums, means - stds, means + stds, facecolor=colors[i], interpolate=True, alpha=0.25)\n",
        "    ax1[i].grid()\n",
        "ax1[-1].set_xlabel('# Labels')\n",
        "ax1[1].set_ylabel('Accuracy')\n",
        "\n",
        "fig1.legend()\n",
        "fig1.set_size_inches(10, 7, forward=True)\n",
        "fig1.savefig('acc.png')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Linear2', 'Linear3', 'Linear4']\n",
            "<memory at 0x7f82f7445648>\n",
            "<memory at 0x7f82f7445648>\n",
            "<memory at 0x7f82f7445648>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: FutureWarning: Series.data is deprecated and will be removed in a future version\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: FutureWarning: Series.data is deprecated and will be removed in a future version\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: FutureWarning: Series.data is deprecated and will be removed in a future version\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqQAAAHhCAYAAAC4O6zrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x504 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-JjG7v4EVKT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "b182c413-87f8-4b79-923b-fa001e168266"
      },
      "source": [
        "mi_df = pd.DataFrame.from_dict(mi_layers)\n",
        "fig2, ax2 = plt.subplots(1, 1, sharex=True)\n",
        "colors = ['black', 'blue', 'red']\n",
        "for i in range(len(layers)):\n",
        "    ax2.scatter(mi_df.loc[0, layers[i]], mi_df.loc[1, layers[i]], color=colors[i], label=layers[i])\n",
        "    \n",
        "    ax2.annotate(layers[i], (mi_df.loc[0, layers[i]], mi_df.loc[1, layers[i]]))\n",
        "    ax2.grid()\n",
        "ax2.set_xlabel('I(X, Z)')\n",
        "ax2.set_ylabel('I(Z, Y)')\n",
        "\n",
        "fig2.legend()\n",
        "fig2.set_size_inches(10, 7, forward=True)\n",
        "fig2.savefig('mi.png')"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArEAAAHhCAYAAAB5vOZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoFtMDUkoLi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}