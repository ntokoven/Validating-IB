{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import torch\n",
    "\n",
    "# Flag to enable execution on GPU\n",
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Loading the MNIST dataset\n",
    "train_set = MNIST('./data/MNIST', download=True, train=True, transform=ToTensor())\n",
    "test_set = MNIST('./data/MNIST', download=True, train=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, RandomAffine, ToTensor\n",
    "from data_utils import PixelCorruption\n",
    "\n",
    "# Defining the augmentations\n",
    "t = Compose([\n",
    "    RandomAffine(degrees=15,\n",
    "                 translate=[0.1, 0.1],\n",
    "                 scale=[0.9, 1.1],\n",
    "                 shear=15), # Small affine transformations\n",
    "    ToTensor(),             # Conversion to torch tensor\n",
    "    PixelCorruption(0.8)    # PixelCorruption with keep probability 80%\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_utils import AugmentedDataset\n",
    "\n",
    "# Creating the multi-view dataset\n",
    "mv_train_set = AugmentedDataset(MNIST('./data/MNIST', train=True), t)\n",
    "\n",
    "# Visualization of one example\n",
    "f, ax = plt.subplots(1,2)\n",
    "\n",
    "idx = 0\n",
    "v_1, v_2, y = mv_train_set[idx]\n",
    "f.suptitle('Label: %d'%y,size=15)\n",
    "ax[0].imshow(v_1[0].data.numpy())\n",
    "ax[1].imshow(v_2[0].data.numpy())\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Initialization of the data loader\n",
    "train_loader = DataLoader(mv_train_set, batch_size=batch_size, shuffle=True, num_workers=8 if cuda else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.distributions import Normal, Independent\n",
    "from torch.nn.functional import softplus\n",
    "\n",
    "# Encoder architecture\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        # Vanilla MLP\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(28*28, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, z_dim*2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0),-1) # Flatten the input\n",
    "        params = self.net(x)\n",
    "        \n",
    "        mu, sigma = params[:,:self.z_dim], params[:,self.z_dim:]\n",
    "        sigma = softplus(sigma) + 1e-7  # Make sigma always positive\n",
    "        \n",
    "        return Independent(Normal(loc=mu, scale=sigma), 1) # Return a factorized Normal distribution\n",
    "\n",
    "# Auxiliary network for mutual information estimation\n",
    "class MIEstimator(nn.Module):\n",
    "    def __init__(self, size1, size2):\n",
    "        super(MIEstimator, self).__init__()\n",
    "        \n",
    "        # Vanilla MLP\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(size1 + size2, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 1),\n",
    "        )\n",
    "    \n",
    "    # Gradient for JSD mutual information estimation and EB-based estimation\n",
    "    def forward(self, x1, x2):\n",
    "        pos = self.net(torch.cat([x1, x2], 1)) #Positive Samples \n",
    "        neg = self.net(torch.cat([torch.roll(x1, 1, 0), x2], 1)) #Predictions for shuffled (negative) samples from p(z1)p(z2)\n",
    "        #breakpoint()\n",
    "        return -softplus(-pos).mean() - softplus(neg).mean(), pos.mean() - neg.exp().mean() + 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the representation\n",
    "z_dim = 64\n",
    "\n",
    "# Intialization of the encoder(s)\n",
    "encoder_v_1 = Encoder(z_dim)\n",
    "encoder_v_2 = encoder_v_1 # Full parameter sharing for the two encoders\n",
    "\n",
    "# Initialization of the mutual information estimation network\n",
    "mi_estimator = MIEstimator(z_dim, z_dim) \n",
    "\n",
    "# Moving the models to the GPU\n",
    "if cuda:\n",
    "    encoder_v_1 = encoder_v_1.cuda()\n",
    "    encoder_v_2 = encoder_v_2.cuda()\n",
    "    mi_estimator = mi_estimator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "# Defining the optimizer\n",
    "opt = Adam([\n",
    "    {'params': encoder_v_1.parameters(), 'lr':1e-4},\n",
    "#     {'params': encoder_v_2.parameters(), 'lr':1e-4}, # There is only one encoder in this example\n",
    "    {'params': mi_estimator.parameters(), 'lr':1e-4},\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import evaluate, split\n",
    "\n",
    "\n",
    "# Select a subset (100 samples per label ~0.17 %) of labeled train points\n",
    "train_subset = split(train_set, 10, 'Balanced') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x1a2d03e278>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_utils import ExponentialScheduler\n",
    "\n",
    "# Defining the schedule for the update of the hyper-parameter over time\n",
    "beta_scheduler = ExponentialScheduler(start_value=1e-3, end_value=1, n_iterations=100, start_iteration=50)\n",
    "# beta_scheduler = ExponentialScheduler(start_value=1e-3, end_value=1, n_iterations=100000, start_iteration=50000)\n",
    "\n",
    "# Visualization of the scheduler behavior\n",
    "iterations = np.arange(250)\n",
    "plt.plot(iterations, [beta_scheduler(iteration) for iteration in iterations])\n",
    "plt.title('$\\\\beta$ Schedule', size=20)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Iteration', size=15)\n",
    "plt.ylabel('$\\\\beta$', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# Training parameters\n",
    "# Increase number of epochs and delay the beta increment for better performances\n",
    "epochs = 300\n",
    "iterations = 0\n",
    "plot_every = 20\n",
    "mi_over_time = []\n",
    "skl_over_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fbec8ead83429c9bd981f2c43c7ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-7-17e78d11dfb8>(49)forward()\n",
      "-> return -softplus(-pos).mean() - softplus(neg).mean(), pos.mean() - neg.exp().mean() + 1\n",
      "(Pdb) pos\n",
      "tensor([[-5.1863e-02],\n",
      "        [ 3.0027e-02],\n",
      "        [ 2.3685e-02],\n",
      "        [ 3.1210e-02],\n",
      "        [-1.1133e-02],\n",
      "        [-5.2478e-02],\n",
      "        [-1.3885e-01],\n",
      "        [-4.1310e-02],\n",
      "        [-5.9979e-02],\n",
      "        [-6.0139e-02],\n",
      "        [-6.9977e-02],\n",
      "        [-6.2791e-02],\n",
      "        [-3.2100e-02],\n",
      "        [-2.3803e-02],\n",
      "        [-6.7242e-02],\n",
      "        [-3.5637e-02],\n",
      "        [-9.3962e-02],\n",
      "        [-1.1038e-01],\n",
      "        [-7.0551e-02],\n",
      "        [-4.6513e-02],\n",
      "        [-3.0850e-02],\n",
      "        [-2.4909e-05],\n",
      "        [-2.2548e-02],\n",
      "        [-1.9792e-02],\n",
      "        [-6.8624e-03],\n",
      "        [ 2.2254e-02],\n",
      "        [-1.0465e-01],\n",
      "        [-7.9801e-02],\n",
      "        [-3.5179e-02],\n",
      "        [-4.7278e-02],\n",
      "        [-1.3955e-01],\n",
      "        [-4.5219e-02],\n",
      "        [-5.9680e-02],\n",
      "        [-3.5988e-02],\n",
      "        [-1.8454e-02],\n",
      "        [-2.3996e-02],\n",
      "        [-1.6494e-02],\n",
      "        [-7.1328e-03],\n",
      "        [ 2.3882e-02],\n",
      "        [ 5.8144e-02],\n",
      "        [-3.6985e-02],\n",
      "        [-1.0879e-01],\n",
      "        [-4.4439e-02],\n",
      "        [ 4.5487e-02],\n",
      "        [-1.0386e-01],\n",
      "        [-4.8489e-02],\n",
      "        [-1.0553e-01],\n",
      "        [-1.1055e-02],\n",
      "        [-3.3809e-02],\n",
      "        [-3.4476e-02],\n",
      "        [-8.3874e-02],\n",
      "        [-4.3526e-02],\n",
      "        [-7.0909e-02],\n",
      "        [-8.3462e-03],\n",
      "        [-5.0569e-02],\n",
      "        [-1.1018e-01],\n",
      "        [-3.1164e-03],\n",
      "        [-2.1787e-02],\n",
      "        [ 3.4362e-02],\n",
      "        [ 8.1521e-03],\n",
      "        [-1.4654e-01],\n",
      "        [ 6.1944e-03],\n",
      "        [-8.2605e-02],\n",
      "        [ 6.1158e-03]], grad_fn=<AddmmBackward>)\n",
      "(Pdb) x1\n",
      "tensor([[ 0.6563,  0.1041, -0.7715,  ...,  1.3631, -0.5683, -0.3231],\n",
      "        [-0.3478,  0.9882, -1.0347,  ...,  0.4932,  0.4601,  0.2376],\n",
      "        [-0.4392,  0.4214,  0.0395,  ..., -0.0733, -0.3598,  0.4407],\n",
      "        ...,\n",
      "        [-0.5852, -0.9428, -0.4444,  ..., -0.6143, -0.2062, -0.5761],\n",
      "        [-0.2694,  0.3437, -0.3904,  ...,  0.0260,  0.6843, -1.2249],\n",
      "        [ 1.3405, -0.9414, -0.9611,  ..., -0.6063,  0.6837, -0.4586]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "(Pdb) x1.size()\n",
      "torch.Size([64, 64])\n",
      "(Pdb) pos.size()\n",
      "torch.Size([64, 1])\n",
      "(Pdb) self.net(torch.cat([x1, x2], 1))\n",
      "tensor([[-5.1863e-02],\n",
      "        [ 3.0027e-02],\n",
      "        [ 2.3685e-02],\n",
      "        [ 3.1210e-02],\n",
      "        [-1.1133e-02],\n",
      "        [-5.2478e-02],\n",
      "        [-1.3885e-01],\n",
      "        [-4.1310e-02],\n",
      "        [-5.9979e-02],\n",
      "        [-6.0139e-02],\n",
      "        [-6.9977e-02],\n",
      "        [-6.2791e-02],\n",
      "        [-3.2100e-02],\n",
      "        [-2.3803e-02],\n",
      "        [-6.7242e-02],\n",
      "        [-3.5637e-02],\n",
      "        [-9.3962e-02],\n",
      "        [-1.1038e-01],\n",
      "        [-7.0551e-02],\n",
      "        [-4.6513e-02],\n",
      "        [-3.0850e-02],\n",
      "        [-2.4909e-05],\n",
      "        [-2.2548e-02],\n",
      "        [-1.9792e-02],\n",
      "        [-6.8624e-03],\n",
      "        [ 2.2254e-02],\n",
      "        [-1.0465e-01],\n",
      "        [-7.9801e-02],\n",
      "        [-3.5179e-02],\n",
      "        [-4.7278e-02],\n",
      "        [-1.3955e-01],\n",
      "        [-4.5219e-02],\n",
      "        [-5.9680e-02],\n",
      "        [-3.5988e-02],\n",
      "        [-1.8454e-02],\n",
      "        [-2.3996e-02],\n",
      "        [-1.6494e-02],\n",
      "        [-7.1328e-03],\n",
      "        [ 2.3882e-02],\n",
      "        [ 5.8144e-02],\n",
      "        [-3.6985e-02],\n",
      "        [-1.0879e-01],\n",
      "        [-4.4439e-02],\n",
      "        [ 4.5487e-02],\n",
      "        [-1.0386e-01],\n",
      "        [-4.8489e-02],\n",
      "        [-1.0553e-01],\n",
      "        [-1.1055e-02],\n",
      "        [-3.3809e-02],\n",
      "        [-3.4476e-02],\n",
      "        [-8.3874e-02],\n",
      "        [-4.3526e-02],\n",
      "        [-7.0909e-02],\n",
      "        [-8.3462e-03],\n",
      "        [-5.0569e-02],\n",
      "        [-1.1018e-01],\n",
      "        [-3.1164e-03],\n",
      "        [-2.1787e-02],\n",
      "        [ 3.4362e-02],\n",
      "        [ 8.1521e-03],\n",
      "        [-1.4654e-01],\n",
      "        [ 6.1944e-03],\n",
      "        [-8.2605e-02],\n",
      "        [ 6.1158e-03]], grad_fn=<AddmmBackward>)\n",
      "(Pdb) torch.cat([x1, x2], 1)\n",
      "tensor([[ 0.6563,  0.1041, -0.7715,  ...,  0.2965, -1.0151,  0.0432],\n",
      "        [-0.3478,  0.9882, -1.0347,  ...,  0.3655,  0.6603,  1.0698],\n",
      "        [-0.4392,  0.4214,  0.0395,  ...,  0.1001,  0.7734, -0.2466],\n",
      "        ...,\n",
      "        [-0.5852, -0.9428, -0.4444,  ..., -0.6447,  0.4414,  0.9029],\n",
      "        [-0.2694,  0.3437, -0.3904,  ...,  0.6813, -0.2377,  0.3516],\n",
      "        [ 1.3405, -0.9414, -0.9611,  ...,  0.9155,  0.7456,  0.0326]],\n",
      "       grad_fn=<CatBackward>)\n",
      "(Pdb) x1\n",
      "tensor([[ 0.6563,  0.1041, -0.7715,  ...,  1.3631, -0.5683, -0.3231],\n",
      "        [-0.3478,  0.9882, -1.0347,  ...,  0.4932,  0.4601,  0.2376],\n",
      "        [-0.4392,  0.4214,  0.0395,  ..., -0.0733, -0.3598,  0.4407],\n",
      "        ...,\n",
      "        [-0.5852, -0.9428, -0.4444,  ..., -0.6143, -0.2062, -0.5761],\n",
      "        [-0.2694,  0.3437, -0.3904,  ...,  0.0260,  0.6843, -1.2249],\n",
      "        [ 1.3405, -0.9414, -0.9611,  ..., -0.6063,  0.6837, -0.4586]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "(Pdb) x2\n",
      "tensor([[-0.6954,  0.1191,  0.4388,  ...,  0.2965, -1.0151,  0.0432],\n",
      "        [ 0.3525,  0.9121,  0.0902,  ...,  0.3655,  0.6603,  1.0698],\n",
      "        [-0.7172,  0.4268, -0.4611,  ...,  0.1001,  0.7734, -0.2466],\n",
      "        ...,\n",
      "        [-0.4902,  0.7248, -0.1541,  ..., -0.6447,  0.4414,  0.9029],\n",
      "        [ 0.4789,  0.4146,  0.9695,  ...,  0.6813, -0.2377,  0.3516],\n",
      "        [ 0.6247,  0.3642,  0.1708,  ...,  0.9155,  0.7456,  0.0326]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "(Pdb) torch.cat([x1, x2], 1).size()\n",
      "torch.Size([64, 128])\n",
      "(Pdb) x1\n",
      "tensor([[ 0.6563,  0.1041, -0.7715,  ...,  1.3631, -0.5683, -0.3231],\n",
      "        [-0.3478,  0.9882, -1.0347,  ...,  0.4932,  0.4601,  0.2376],\n",
      "        [-0.4392,  0.4214,  0.0395,  ..., -0.0733, -0.3598,  0.4407],\n",
      "        ...,\n",
      "        [-0.5852, -0.9428, -0.4444,  ..., -0.6143, -0.2062, -0.5761],\n",
      "        [-0.2694,  0.3437, -0.3904,  ...,  0.0260,  0.6843, -1.2249],\n",
      "        [ 1.3405, -0.9414, -0.9611,  ..., -0.6063,  0.6837, -0.4586]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "(Pdb) torch.roll(x1, 1, 0)\n",
      "tensor([[ 1.3405, -0.9414, -0.9611,  ..., -0.6063,  0.6837, -0.4586],\n",
      "        [ 0.6563,  0.1041, -0.7715,  ...,  1.3631, -0.5683, -0.3231],\n",
      "        [-0.3478,  0.9882, -1.0347,  ...,  0.4932,  0.4601,  0.2376],\n",
      "        ...,\n",
      "        [ 0.8249,  0.2960, -0.6908,  ...,  0.3941,  0.9450,  0.2233],\n",
      "        [-0.5852, -0.9428, -0.4444,  ..., -0.6143, -0.2062, -0.5761],\n",
      "        [-0.2694,  0.3437, -0.3904,  ...,  0.0260,  0.6843, -1.2249]],\n",
      "       grad_fn=<RollBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Training loop (approx 1h on GPU)\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for v_1, v_2, _ in train_loader:\n",
    "        \n",
    "        if cuda:\n",
    "            v_1 = v_1.cuda()\n",
    "            v_2 = v_2.cuda()\n",
    "        \n",
    "        # Encode a batch of data\n",
    "        p_z_1_given_v_1 = encoder_v_1(v_1)\n",
    "        p_z_2_given_v_2 = encoder_v_2(v_2)\n",
    "        \n",
    "        # Sample from the posteriors with reparametrization\n",
    "        z_1 = p_z_1_given_v_1.rsample()\n",
    "        z_2 = p_z_2_given_v_2.rsample()\n",
    "        \n",
    "        # Mutual information estimation\n",
    "        mi_gradient, mi_estimation = mi_estimator(z_1,z_2)\n",
    "        mi_gradient = mi_gradient.mean()\n",
    "        mi_estimation = mi_estimation.mean()\n",
    "        print(mi_estimation)\n",
    "        # Symmetrized Kullback-Leibler divergence\n",
    "        kl_1_2 = p_z_1_given_v_1.log_prob(z_1) - p_z_2_given_v_2.log_prob(z_1)\n",
    "        kl_2_1 = p_z_2_given_v_2.log_prob(z_2) - p_z_1_given_v_1.log_prob(z_2)\n",
    "        skl = (kl_1_2 + kl_2_1).mean()/ 2.\n",
    "\n",
    "        # Update the value of beta according to the policy\n",
    "        beta = beta_scheduler(iterations)\n",
    "        iterations +=1\n",
    "        \n",
    "        # Computing the loss function\n",
    "        loss = - mi_gradient + beta * skl\n",
    "        \n",
    "        # Logging\n",
    "        mi_over_time.append(mi_estimation.item())\n",
    "        skl_over_time.append(skl.item())\n",
    "        \n",
    "        # Backward pass and update\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()   \n",
    "    \n",
    "    # Plot the loss components every 5 epochs\n",
    "    if epoch % plot_every == 0:\n",
    "        f, ax = plt.subplots(1,2, figsize=(8,3))\n",
    "        ax[0].set_title('$I(z_1;z_2)$')\n",
    "        ax[1].set_title('$D_{SKL}(p(z_1|v_1)||p(z_2|v_2))$')\n",
    "        ax[1].set_yscale('log')\n",
    "        ax[0].plot(mi_over_time, '.', alpha=0.1)\n",
    "        ax[1].plot(skl_over_time, '.r', alpha=0.1)\n",
    "        ax[0].set_ylim(0,8)\n",
    "        ax[1].set_ylim(1e-3)\n",
    "        \n",
    "        f.suptitle('Epoch: %d'%epoch, fontsize=15)\n",
    "        plt.show()\n",
    "        \n",
    "        # Compute train and test_accuracy of a logistic regression\n",
    "        train_accuracy, test_accuracy = evaluate(encoder=encoder_v_1, train_on=train_subset, test_on=test_set, cuda=cuda)\n",
    "        print('Train Accuracy: %f'% train_accuracy)\n",
    "        print('Test Accuracy: %f'% test_accuracy)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.Subset object at 0x1a36bbeeb8>\n",
      "Train Accuracy: 1.000000\n",
      "Test Accuracy: 0.235450\n"
     ]
    }
   ],
   "source": [
    "# Testing with 1 sample per label (~0.0017 % of labeled train points)\n",
    "train_smallest_subset = split(train_set, 10, 'Balanced') \n",
    "print(train_smallest_subset)\n",
    "train_accuracy, test_accuracy = evaluate(encoder=encoder_v_1, train_on=train_smallest_subset, test_on=test_set, cuda=cuda)\n",
    "print('Train Accuracy: %f'% train_accuracy)\n",
    "print('Test Accuracy: %f'% test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
